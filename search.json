[{"path":"https://niehs.github.io/amadeus/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2024 Spatiotemporal Exposures Toxicology Group Permission hereby granted, free charge, person obtaining copy software associated documentation files (‚ÄúSoftware‚Äù), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED ‚Äú‚Äù, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://niehs.github.io/amadeus/articles/download_functions.html","id":"motivation","dir":"Articles","previous_headings":"","what":"Motivation","title":"download_data Function","text":"download_data function developed improve researchers‚Äô access publicly available environmental data. Although data already available online, using web browser manually download hundreds thousands data files slow, arduous, efficiently repeatable. Additionally, users may familiar creating download recipes Bash (Unix shell), download_data allows researchers download data directly R, common coding language field environmental health research. Finally, function-izing data downloads useful repeated code automated analysis pipelines.","code":""},{"path":"https://niehs.github.io/amadeus/articles/download_functions.html","id":"download_data","dir":"Articles","previous_headings":"","what":"download_data","title":"download_data Function","text":"download_data acccesses downloads environmental datasets, collections, variables variety sources. wrapper function calls source-specific data download functions, utilizing unique combination input parameters, host URL, naming convention, data formats. Source-specific download functions data sources important note download_data calls source-specific function based dataset_name parameter. Using source-specific function directly return data parameters , error messages produced differ slightly.","code":""},{"path":"https://niehs.github.io/amadeus/articles/download_functions.html","id":"parameters","dir":"Articles","previous_headings":"download_data","what":"Parameters","title":"download_data Function","text":"User-defined parameters differ based data source. Required parameters source can checked names(formals()). two functions different required parameters download_hms uses daily temporal resolution download_narr uses yearly, share common, standard parameters.","code":"names(formals(download_hms)) #> [1] \"data_format\"       \"date\"              \"directory_to_save\" #> [4] \"acknowledgement\"   \"download\"          \"remove_command\"    #> [7] \"unzip\"             \"remove_zip\"        \"hash\" names(formals(download_narr)) #> [1] \"variables\"         \"year\"              \"directory_to_save\" #> [4] \"acknowledgement\"   \"download\"          \"remove_command\"    #> [7] \"hash\""},{"path":"https://niehs.github.io/amadeus/articles/download_functions.html","id":"standard-parameters","dir":"Articles","previous_headings":"download_data > Parameters","what":"Standard parameters","title":"download_data Function","text":"Four parameters included data download functions. Additionally, dataset_name parameter must specified using download_data, assumed using source-specific download function.","code":""},{"path":"https://niehs.github.io/amadeus/articles/download_functions.html","id":"function-structure","dir":"Articles","previous_headings":"download_data","what":"Function Structure","title":"download_data Function","text":"Although source-specific download function unique, follow general structure. following chunks code adopted download_hms demonstrate functions‚Äô structure. 1. Clean Parameters 2. Generate Download URLs 3. Generate download file names 4. Initiate ‚Äú‚Ä¶commands.txt‚Äù 5. Concatenate download commands 6. Finalize ‚Äú‚Ä¶commands.txt‚Äù 7. Run commands ‚Äú‚Ä¶commands.txt‚Äù 8. Zip files (applicable)","code":""},{"path":"https://niehs.github.io/amadeus/articles/download_functions.html","id":"clean-parameters","dir":"Articles","previous_headings":"download_data > Function Structure","what":"1. Clean parameters","title":"download_data Function","text":"Cleaning user-defined parameters highly dependent parameters desired URL created. common parameter cleaning step creating date-time sequence based given temporal range required format, case YYYYMMDD.","code":"# user defined parameters dates <- c(\"2023-12-28\", \"2024-01-02\") date_sequence <- seq(   as.Date(dates[1], format = \"%Y-%m-%d\"),   as.Date(dates[2], format = \"%Y-%m-%d\"),   \"day\" ) date_sequence <- gsub(\"-\", \"\", as.character(date_sequence)) date_sequence #> [1] \"20231228\" \"20231229\" \"20231230\" \"20231231\" \"20240101\" \"20240102\""},{"path":"https://niehs.github.io/amadeus/articles/download_functions.html","id":"generate-download-urls","dir":"Articles","previous_headings":"download_data > Function Structure","what":"2. Generate download URLs","title":"download_data Function","text":"URL base pattern identified manually inspecting download link source-specific web page. download_hms utilizes year, month, date, data format generate download url. download URL created date date_sequence based fixed pattern.","code":"# user defined parameters data_format <- \"Shapefile\" suffix <- \".zip\" urls <- NULL for (d in seq_along(date_sequence)) {   year <- substr(date_sequence[d], 1, 4)   month <- substr(date_sequence[d], 5, 6)   base <- \"https://satepsanone.nesdis.noaa.gov/pub/FIRE/web/HMS/Smoke_Polygons/\"   url <- paste0(     base,     data_format,     \"/\",     year,     \"/\",     month,     \"/hms_smoke\",     date_sequence[d],     suffix   )   urls <- c(urls, url) } urls #> [1] \"https://satepsanone.nesdis.noaa.gov/pub/FIRE/web/HMS/Smoke_Polygons/Shapefile/2023/12/hms_smoke20231228.zip\" #> [2] \"https://satepsanone.nesdis.noaa.gov/pub/FIRE/web/HMS/Smoke_Polygons/Shapefile/2023/12/hms_smoke20231229.zip\" #> [3] \"https://satepsanone.nesdis.noaa.gov/pub/FIRE/web/HMS/Smoke_Polygons/Shapefile/2023/12/hms_smoke20231230.zip\" #> [4] \"https://satepsanone.nesdis.noaa.gov/pub/FIRE/web/HMS/Smoke_Polygons/Shapefile/2023/12/hms_smoke20231231.zip\" #> [5] \"https://satepsanone.nesdis.noaa.gov/pub/FIRE/web/HMS/Smoke_Polygons/Shapefile/2024/01/hms_smoke20240101.zip\" #> [6] \"https://satepsanone.nesdis.noaa.gov/pub/FIRE/web/HMS/Smoke_Polygons/Shapefile/2024/01/hms_smoke20240102.zip\""},{"path":"https://niehs.github.io/amadeus/articles/download_functions.html","id":"generate-download-file-names","dir":"Articles","previous_headings":"download_data > Function Structure","what":"3. Generate download file names","title":"download_data Function","text":"generation download file names also follows fixed pattern, typically combination user-defined download directory, dataset name, spatiotemporal characteristic, data type, , applicable, specific variable name. Unlike download URLs, download file names can defined way writer function, using previously defined characteristics useful identification. download URL created date date_sequence based fixed pattern.","code":"# user defined parameters directory_to_download <- \"./data/\" download_file_names <- NULL for (d in seq_along(date_sequence)) {   download_file_name <- paste0(     directory_to_download,     \"hms_smoke_\",     data_format,     \"_\",     date_sequence[d],     suffix   )   download_file_names <- c(download_file_names, download_file_name) } download_file_names #> [1] \"./data/hms_smoke_Shapefile_20231228.zip\" #> [2] \"./data/hms_smoke_Shapefile_20231229.zip\" #> [3] \"./data/hms_smoke_Shapefile_20231230.zip\" #> [4] \"./data/hms_smoke_Shapefile_20231231.zip\" #> [5] \"./data/hms_smoke_Shapefile_20240101.zip\" #> [6] \"./data/hms_smoke_Shapefile_20240102.zip\""},{"path":"https://niehs.github.io/amadeus/articles/download_functions.html","id":"initiate-commands-txt","dir":"Articles","previous_headings":"download_data > Function Structure","what":"4. Initiate ‚Äú‚Ä¶commands.txt‚Äù","title":"download_data Function","text":"important aspect data download function sink...cat...sink structure. Rather using utils::download.file function, text file created store download commands generated URLs file names. structure utilized several reasons: Consistent structure source-specific download functions. download.file function accept vectors URLs destination files downloading. additional loop download data increase function complexity may reduce performance. Writing commands Bash (Unix shell) script allows specific arguments flags. Storing download URLs without immediately running download allows unit testing URL checking (Unit Tests). text file containing download commands named based dataset, temporal range, data transfer method. Create sink text file.","code":"commands_txt <- paste0(   directory_to_download,   \"hms_smoke_\",   head(date_sequence, n = 1),   \"_\",   tail(date_sequence, n = 1),   \"_curl_commands.txt\" ) sink(commands_txt)"},{"path":"https://niehs.github.io/amadeus/articles/download_functions.html","id":"concatenate-download-commands","dir":"Articles","previous_headings":"download_data > Function Structure","what":"5. Concatenate download commands","title":"download_data Function","text":"Linux-based download commands written according data transfer method, download URL, download file name, additional arguments. additional arguments included, order, depend data transfer method URL type. information curl wget, two data transfer methods utilized data download functions, see curl.1 man page GNU Wget 1.21.1-dirty Manual (latest version January 8, 2024). cat() function store download commands written loop previously sunk commands text file (commands_txt).","code":"for (d in seq_along(date_sequence)) {   download_comamnd <- paste0(     \"curl -s -o \",     download_file_names[d],     \" --url \",     urls[d],     \"\\n\"   )   cat(download_comamnd) }"},{"path":"https://niehs.github.io/amadeus/articles/download_functions.html","id":"finalize-commands-txt","dir":"Articles","previous_headings":"download_data > Function Structure","what":"6. Finalize ‚Äú‚Ä¶commands.txt‚Äù","title":"download_data Function","text":"download commands concatenated commands text file, second sink command run finalize file stop appending R output.","code":"sink()"},{"path":"https://niehs.github.io/amadeus/articles/download_functions.html","id":"run-commands-in-commands-txt","dir":"Articles","previous_headings":"download_data > Function Structure","what":"7. Run commands in ‚Äú‚Ä¶commands.txt‚Äù","title":"download_data Function","text":"‚Äúsystem command‚Äù must created run download commands stored commands text file. bash script, . indicates run commands within given script. case, run commands within commands text file. Running system_command deploys ‚Äúauxiliary‚Äù function, download_run, function created reduce repeated code across source-specific download functions. function takes two parameters, system_command, indicates command run, download, user-defined logical parameter. data download initiated running download_run system command identified download = TRUE. Checking download directory shows requested files downloaded.","code":"system_command <- paste0(   \". \",   commands_txt,   \"\\n\" ) system_command #> [1] \". ./data/hms_smoke_20231228_20240102_curl_commands.txt\\n\" download_run <- function(     download = FALSE,     system_command = NULL) {   if (download == TRUE) {     cat(paste0(\"Downloading requested files...\\n\"))     system(command = system_command)     cat(paste0(\"Requested files have been downloaded.\\n\"))   } else {     cat(paste0(\"Skipping data download.\\n\"))     return(NULL)   } } download_run(   download = TRUE,   system_command = system_command ) list.files(path = directory_to_download) #> [1] \"hms_smoke_Shapefile_20231228.zip\" \"hms_smoke_Shapefile_20231229.zip\" #> [3] \"hms_smoke_Shapefile_20231230.zip\" \"hms_smoke_Shapefile_20231231.zip\" #> [5] \"hms_smoke_Shapefile_20240101.zip\" \"hms_smoke_Shapefile_20240102.zip\""},{"path":"https://niehs.github.io/amadeus/articles/download_functions.html","id":"zip-files-if-applicable","dir":"Articles","previous_headings":"download_data > Function Structure","what":"8. Zip files (if applicable)","title":"download_data Function","text":"source-specific data download functions follow general pattern, functions download zip files require additional steps inflate remove downloaded zip files, desired. two steps run helper functions, run user-defined unzip remove_zip parameters download_data. download_unzip inflates zip files unzip = TRUE, skips inflation unzip = FALSE. download_remove_zips removes downloaded zip files remove = TRUE, skips removal remove = FALSE. demonstration unzip (inflate) downloaded zip files delete . Listing files shows contents zip files inflated zip files retained. download function structured successfully.","code":"download_unzip <-   function(file_name,            directory_to_unzip,            unzip = TRUE) {     if (!unzip) {       cat(paste0(\"Downloaded files will not be unzipped.\\n\"))       return(NULL)     }     cat(paste0(\"Unzipping files...\\n\"))     unzip(file_name,       exdir = directory_to_unzip     )     cat(paste0(       \"Files unzipped and saved in \",       directory_to_unzip,       \".\\n\"     ))   } download_remove_zips <-   function(remove = FALSE,            download_name) {     if (remove) {       cat(paste0(\"Removing download files...\\n\"))       file.remove(download_name)       cat(paste0(\"Download files removed.\\n\"))     }   } for (f in seq_along(download_file_names)) {   download_unzip(     file_name = download_file_names[f],     directory_to_unzip = directory_to_download,     unzip = TRUE   ) } download_remove_zips(   download_name = download_file_names,   remove = FALSE ) #> Unzipping files... #> Files unzipped and saved in ./data/. #> Unzipping files... #> Files unzipped and saved in ./data/. #> Unzipping files... #> Files unzipped and saved in ./data/. #> Unzipping files... #> Files unzipped and saved in ./data/. #> Unzipping files... #> Files unzipped and saved in ./data/. #> Unzipping files... #> Files unzipped and saved in ./data/. list.files(path = directory_to_download) #>  [1] \"hms_smoke_Shapefile_20231228.zip\" \"hms_smoke_Shapefile_20231229.zip\" #>  [3] \"hms_smoke_Shapefile_20231230.zip\" \"hms_smoke_Shapefile_20231231.zip\" #>  [5] \"hms_smoke_Shapefile_20240101.zip\" \"hms_smoke_Shapefile_20240102.zip\" #>  [7] \"hms_smoke20231228.dbf\"            \"hms_smoke20231228.prj\"            #>  [9] \"hms_smoke20231228.shp\"            \"hms_smoke20231228.shx\"            #> [11] \"hms_smoke20231229.dbf\"            \"hms_smoke20231229.prj\"            #> [13] \"hms_smoke20231229.shp\"            \"hms_smoke20231229.shx\"            #> [15] \"hms_smoke20231230.dbf\"            \"hms_smoke20231230.prj\"            #> [17] \"hms_smoke20231230.shp\"            \"hms_smoke20231230.shx\"            #> [19] \"hms_smoke20231231.dbf\"            \"hms_smoke20231231.prj\"            #> [21] \"hms_smoke20231231.shp\"            \"hms_smoke20231231.shx\"            #> [23] \"hms_smoke20240101.dbf\"            \"hms_smoke20240101.prj\"            #> [25] \"hms_smoke20240101.shp\"            \"hms_smoke20240101.shx\"            #> [27] \"hms_smoke20240102.dbf\"            \"hms_smoke20240102.prj\"            #> [29] \"hms_smoke20240102.shp\"            \"hms_smoke20240102.shx\""},{"path":"https://niehs.github.io/amadeus/articles/download_functions.html","id":"unit-tests","dir":"Articles","previous_headings":"","what":"Unit Tests","title":"download_data Function","text":"previous outline successfully cleaned parameters, generated URLs, downloaded data, can sure continue work different temporal ranges data types? end, unit tests implemented ensure data download function runs properly URLs produced 2. Generate download URLs valid accessible. Like download functions, unit tests rely ‚Äúhelper‚Äù functions reduce repeated code across tests.","code":""},{"path":"https://niehs.github.io/amadeus/articles/download_functions.html","id":"helper-functions","dir":"Articles","previous_headings":"Unit Tests","what":"Helper functions","title":"download_data Function","text":"read_commands imports commands text file converts data frame vector. extract_urls extracts download URL vector commands. position URL within download command determined 5. Concatenate download commands. check_url_status important download test ‚Äúhelper‚Äù functions. function utilizes httr::HEAD httr::GET check HTTP response status given URL. desired HTTP response status 200, means URL valid accessible. check_url_status returns logical value indicate whether URL returns HTTP status 200 (TRUE) (FALSE). information HTTP status‚Äô, see HTTP response status codes. check_urls applies check_url_status random sample URLs extracted extract_urls. sample size vary based dataset spatio-temporal parameters tested. function returns logical vector containing output check_url_status.","code":"read_commands <- function(     commands_path = commands_path) {   commands <- utils::read.csv(commands_path, header = FALSE)   commands <- commands[seq_len(nrow(commands)), ]   return(commands) } # function to extract URLs from vector extract_urls <- function(     commands = commands,     position = NULL) {   if (is.null(position)) {     cat(paste0(\"URL position in command is not defined.\\n\"))     return(NULL)   }   url_list <- NULL   for (c in seq_along(commands)) {     url <- stringr::str_split_i(commands[c], \" \", position)     url_list <- c(url_list, url)   }   return(url_list) } check_url_status <- function(     url,     method = \"HEAD\") {   http_status_ok <- 200   if (method == \"HEAD\") {     hd <- httr::HEAD(url)   } else if (method == \"GET\") {     hd <- httr::GET(url)   }   status <- hd$status_code   return(status == http_status_ok) } check_urls <- function(     urls = urls,     size = NULL,     method = \"HEAD\") {   if (is.null(size)) {     cat(paste0(\"URL sample size is not defined.\\n\"))     return(NULL)   }   if (length(urls) < size) {     size <- length(urls)   }   url_sample <- sample(urls, size, replace = FALSE)   url_status <- sapply(url_sample,     check_url_status,     method = method   )   return(url_status) }"},{"path":"https://niehs.github.io/amadeus/articles/download_functions.html","id":"testthat","dir":"Articles","previous_headings":"Unit Tests","what":"testthat","title":"download_data Function","text":"demonstrate test action, test URLs generated download_data NOAA HMS Smoke dataset. information see testthat. Although testthat::test_that(...) chunk contains 32 lines code, unit test performed expect_true((url_status)). words, line expecting (expect_true) () sampled URLs return HTTP response status 200 (url_status). Since expectation met, test passed! alternate example, can use start end date known data. URLs associated dates exist, expect function fail. test utilizes expect_error() download_data wrapper function returns error message underlying source-specific download function returns error. test utilizes testthat::expect_error download_data wrapper function returns error message underlying source-specific download function returns error. directly used download_hms function, expect receive error. expected, test passes NOAA HMS Smoke dataset contain data January 1-2, 1800. unit tests just two many implemented download_data accompanying source-specific download functions, demonstrate unit testing helps build stable code.","code":"library(testthat) testthat::test_that(   \"Valid dates return HTTP response status = 200.\",   {     # parameters     test_start <- \"2023-12-28\"     test_end <- \"2024-01-02\"     test_directory <- \"./data/\"     # download     download_data(       dataset_name = \"hms\",       date = c(test_start, test_end),       data_format = \"Shapefile\",       directory_to_save = test_directory,       acknowledgement = TRUE,       download = FALSE,       remove_command = FALSE,       unzip = FALSE,       remove_zip = FALSE     )     commands_path <- paste0(       test_directory,       \"hms_smoke_\",       gsub(\"-\", \"\", test_start),       \"_\",       gsub(\"-\", \"\", test_end),       \"_curl_commands.txt\"     )     # helpers     commands <- read_commands(commands_path = commands_path)     urls <- extract_urls(commands = commands, position = 6)     url_status <- check_urls(urls = urls, size = 6, method = \"HEAD\")     # test for true     expect_true(all(url_status))   } ) #> Test passed üéä testthat::test_that(   \"Invalid dates cause function to fail.\",   {     # parameters     test_start <- \"1800-01-01\"     test_end <- \"1800-01-02\"     test_directory <- \"../inst/extdata/\"     # test for error     testthat::expect_error(       download_data(         dataset_name = \"hms\",         date = c(test_start, test_end),         data_format = \"Shapefile\",         directory_to_download = test_directory,         directory_to_save = test_directory,         acknowledgement = TRUE,         download = FALSE,         remove_command = FALSE,         unzip = FALSE,         remove_zip = FALSE       )     )   } ) #> Test passed üéä testthat::test_that(   \"Invalid dates cause function to fail.\",   {     # parameters     test_start <- \"1800-01-01\"     test_end <- \"1800-01-02\"     test_directory <- \"../inst/extdata/\"     # test for error     testthat::expect_error(       download_hms(         date = c(test_start, test_end),         data_format = \"Shapefile\",         directory_to_download = test_directory,         directory_to_save = test_directory,         acknowledgement = TRUE,         download = FALSE,         remove_command = FALSE,         unzip = FALSE,         remove_zip = FALSE       )     )   } ) #> Test passed üåà"},{"path":"https://niehs.github.io/amadeus/articles/download_functions.html","id":"download-example","dir":"Articles","previous_headings":"","what":"Download Example","title":"download_data Function","text":"function structure outlined unit tests place, can now perform data download. begin, check parameters required source-specific data download function. Define parameters. Download data. Checking directory shows desired data downloaded inflated, original zip files retained.","code":"names(formals(download_hms)) #> [1] \"data_format\"       \"date\"              \"directory_to_save\" #> [4] \"acknowledgement\"   \"download\"          \"remove_command\"    #> [7] \"unzip\"             \"remove_zip\"        \"hash\" dates <- c(\"2023-12-28\", \"2024-01-02\") data_format <- \"Shapefile\" data_directory <- \"./download_example/\" acknowledgement <- TRUE download <- TRUE # run data download remove_command <- TRUE # delete \"...commands.txt\" file unzip <- TRUE # inflate (unzip) downloaded zip files remove_zip <- FALSE # retain downloaded zip files download_data(   dataset_name = \"hms\",   date = dates,   directory_to_save = data_directory,   acknowledgement = acknowledgement,   download = download,   remove_command = remove_command,   unzip = unzip,   remove_zip = remove_zip ) #> Downloading requested files... #> Requested files have been downloaded. #> Unzipping files... #> Files unzipped and saved in ./download_example/. #> Unzipping files... #> Files unzipped and saved in ./download_example/. #> Unzipping files... #> Files unzipped and saved in ./download_example/. #> Unzipping files... #> Files unzipped and saved in ./download_example/. #> Unzipping files... #> Files unzipped and saved in ./download_example/. #> Unzipping files... #> Files unzipped and saved in ./download_example/. list.files(data_directory) #>  [1] \"hms_smoke_Shapefile_20231228.zip\" \"hms_smoke_Shapefile_20231229.zip\" #>  [3] \"hms_smoke_Shapefile_20231230.zip\" \"hms_smoke_Shapefile_20231231.zip\" #>  [5] \"hms_smoke_Shapefile_20240101.zip\" \"hms_smoke_Shapefile_20240102.zip\" #>  [7] \"hms_smoke20231228.dbf\"            \"hms_smoke20231228.prj\"            #>  [9] \"hms_smoke20231228.shp\"            \"hms_smoke20231228.shx\"            #> [11] \"hms_smoke20231229.dbf\"            \"hms_smoke20231229.prj\"            #> [13] \"hms_smoke20231229.shp\"            \"hms_smoke20231229.shx\"            #> [15] \"hms_smoke20231230.dbf\"            \"hms_smoke20231230.prj\"            #> [17] \"hms_smoke20231230.shp\"            \"hms_smoke20231230.shx\"            #> [19] \"hms_smoke20231231.dbf\"            \"hms_smoke20231231.prj\"            #> [21] \"hms_smoke20231231.shp\"            \"hms_smoke20231231.shx\"            #> [23] \"hms_smoke20240101.dbf\"            \"hms_smoke20240101.prj\"            #> [25] \"hms_smoke20240101.shp\"            \"hms_smoke20240101.shx\"            #> [27] \"hms_smoke20240102.dbf\"            \"hms_smoke20240102.prj\"            #> [29] \"hms_smoke20240102.shp\"            \"hms_smoke20240102.shx\""},{"path":"https://niehs.github.io/amadeus/articles/download_functions.html","id":"download_hms-function-code","dir":"Articles","previous_headings":"","what":"download_hms function code","title":"download_data Function","text":"following entire R code used create download_hms.","code":"download_hms #> function (data_format = \"Shapefile\", date = c(\"2018-01-01\", \"2018-01-01\"),  #>     directory_to_save = NULL, acknowledgement = FALSE, download = FALSE,  #>     remove_command = FALSE, unzip = TRUE, remove_zip = FALSE,  #>     hash = FALSE)  #> { #>     amadeus::download_permit(acknowledgement = acknowledgement) #>     amadeus::check_for_null_parameters(mget(ls())) #>     if (length(date) == 1) { #>         date <- c(date, date) #>     } #>     stopifnot(length(date) == 2) #>     date <- date[order(as.Date(date))] #>     if (as.Date(date[1]) < as.Date(\"2005-08-05\")) { #>         stop(\"NOAA HMS wildfire smoke data begins at August 05, 2005.\") #>     } #>     directory_original <- amadeus::download_sanitize_path(directory_to_save) #>     directories <- amadeus::download_setup_dir(directory_original,  #>         zip = TRUE) #>     directory_to_download <- directories[1] #>     directory_to_save <- directories[2] #>     if (unzip == FALSE && remove_zip == TRUE) { #>         stop(paste0(\"Arguments unzip = FALSE and remove_zip = TRUE are not \",  #>             \"acceptable together. Please change one.\\n\")) #>     } #>     date_sequence <- amadeus::generate_date_sequence(date[1],  #>         date[2], sub_hyphen = TRUE) #>     base <- \"https://satepsanone.nesdis.noaa.gov/pub/FIRE/web/HMS/Smoke_Polygons/\" #>     commands_txt <- paste0(directory_original, \"hms_smoke_\",  #>         utils::head(date_sequence, n = 1), \"_\", utils::tail(date_sequence,  #>             n = 1), \"_curl_commands.txt\") #>     amadeus::download_sink(commands_txt) #>     download_names <- NULL #>     for (f in seq_along(date_sequence)) { #>         year <- substr(date_sequence[f], 1, 4) #>         month <- substr(date_sequence[f], 5, 6) #>         if (tolower(data_format) == \"shapefile\") { #>             data_format <- \"Shapefile\" #>             suffix <- \".zip\" #>             directory_to_cat <- directory_to_download #>         } #>         else if (tolower(data_format) == \"kml\") { #>             data_format <- \"KML\" #>             suffix <- \".kml\" #>             directory_to_cat <- directory_to_save #>         } #>         url <- paste0(base, data_format, \"/\", year, \"/\", month,  #>             \"/hms_smoke\", date_sequence[f], suffix) #>         if (f == 1) { #>             if (!(amadeus::check_url_status(url))) { #>                 sink() #>                 file.remove(commands_txt) #>                 stop(paste0(\"Invalid date returns HTTP code 404. \",  #>                   \"Check `date` parameter.\\n\")) #>             } #>         } #>         destfile <- paste0(directory_to_cat, \"hms_smoke_\", data_format,  #>             \"_\", date_sequence[f], suffix) #>         download_names <- c(download_names, destfile) #>         command <- paste0(\"curl -s -o \", destfile, \" --url \",  #>             url, \"\\n\") #>         if (amadeus::check_destfile(destfile)) { #>             cat(command) #>         } #>     } #>     sink() #>     amadeus::download_run(download = download, commands_txt = commands_txt,  #>         remove = remove_command) #>     if (data_format == \"KML\") { #>         unlink(directory_to_download, recursive = TRUE) #>         message(paste0(\"KML files cannot be unzipped.\\n\")) #>         return(TRUE) #>     } #>     for (d in seq_along(download_names)) { #>         amadeus::download_unzip(file_name = download_names[d],  #>             directory_to_unzip = directory_to_save, unzip = unzip) #>     } #>     amadeus::download_remove_zips(remove = remove_zip, download_name = download_names) #>     return(amadeus::download_hash(hash, directory_to_save)) #> } #> <bytecode: 0x560c1bb4df80> #> <environment: namespace:amadeus>"},{"path":"https://niehs.github.io/amadeus/articles/epa_download.html","id":"downloading-and-pre-processing-pre-generated-epa-aqs-data-from-their-website","dir":"Articles","previous_headings":"","what":"Downloading and pre-processing pre-generated EPA AQS data from their website","title":"Downloading EPA Daily Data","text":"script downloads pre-processed data EPA‚Äôs AQS data desired variable, year(s), temporal resolution. script also joins multiple years‚Äô data single data frame, downloads file metadata monitors included dataset. first version script (August 2023) written download daily PM2.5 data period 2018-2022. Available datasets can found website https://aqs.epa.gov/aqsweb/airdata/download_files.html.","code":""},{"path":"https://niehs.github.io/amadeus/articles/epa_download.html","id":"setting-up-for-data-download","dir":"Articles","previous_headings":"Downloading and pre-processing pre-generated EPA AQS data from their website","what":"1. Setting up for data download","title":"Downloading EPA Daily Data","text":"Specifying temporal resolution, parameter interest, year Create list file URLs Specify download folder desired name downloaded zip files","code":"resolution <- \"daily\" parameter_code <- 88101 # Parameter Code for PM2.5 local conditions startyear <- 2018 endyear <- 2022 file_urls <- sprintf(   paste(\"https://aqs.epa.gov/aqsweb/airdata/\", resolution,     \"_\", parameter_code, \"_%.0f.zip\",     sep = \"\"   ),   startyear:endyear ) file_urls ## [1] \"https://aqs.epa.gov/aqsweb/airdata/daily_88101_2018.zip\" ## [2] \"https://aqs.epa.gov/aqsweb/airdata/daily_88101_2019.zip\" ## [3] \"https://aqs.epa.gov/aqsweb/airdata/daily_88101_2020.zip\" ## [4] \"https://aqs.epa.gov/aqsweb/airdata/daily_88101_2021.zip\" ## [5] \"https://aqs.epa.gov/aqsweb/airdata/daily_88101_2022.zip\" download_dir <- \"../input/aqs/\" download_names <- sprintf(   paste(download_dir,     \"download_output_%.0f.zip\",     sep = \"\"   ),   startyear:endyear ) download_names ## [1] \"../input/aqs/download_output_2018.zip\" ## [2] \"../input/aqs/download_output_2019.zip\" ## [3] \"../input/aqs/download_output_2020.zip\" ## [4] \"../input/aqs/download_output_2021.zip\" ## [5] \"../input/aqs/download_output_2022.zip\""},{"path":"https://niehs.github.io/amadeus/articles/epa_download.html","id":"downloading-data","dir":"Articles","previous_headings":"Downloading and pre-processing pre-generated EPA AQS data from their website","what":"2. Downloading data","title":"Downloading EPA Daily Data","text":"Download zip files website Construct string unzipped file names","code":"download.file(file_urls, download_names, method = \"libcurl\") csv_names <- sprintf(   paste(download_dir, resolution, \"_\",     parameter_code, \"_%.0f.csv\",     sep = \"\"   ),   startyear:endyear )"},{"path":"https://niehs.github.io/amadeus/articles/epa_download.html","id":"processing-data","dir":"Articles","previous_headings":"Downloading and pre-processing pre-generated EPA AQS data from their website","what":"3. Processing data","title":"Downloading EPA Daily Data","text":"Unzip read .csv files, process join one dataframe. unique site identifier ‚ÄúID.Code‚Äù string structure State-County-Site-Parameter-POC","code":"for (n in seq_along(file_urls)) {   # Unzips file to same folder it was downloaded to   unzip(download_names[n], exdir = download_dir)    # Read in dataframe   print(paste(\"reading and processing file:\", csv_names[n], \"...\"))   data <- read.csv(csv_names[n], stringsAsFactors = FALSE)    # Make unique site identifier: State-County-Site-Parameter-POC   data$ID.Code <- paste(data$State.Code, data$County.Code,     data$Site.Num, data$Parameter.Code,     data$POC,     sep = \"-\"   )    # Concatenate with other years   if (n == 1) {     data_all <- data   } else {     data_all <- rbind(data_all, data)   } } ## [1] \"reading and processing file:../input/aqs/daily_88101_2018.csv...\" ## [1] \"reading and processing file:../input/aqs/daily_88101_2019.csv...\" ## [1] \"reading and processing file:../input/aqs/daily_88101_2020.csv...\" ## [1] \"reading and processing file:../input/aqs/daily_88101_2021.csv...\" ## [1] \"reading and processing file:../input/aqs/daily_88101_2022.csv...\""},{"path":"https://niehs.github.io/amadeus/articles/epa_download.html","id":"downloading-monitor-metadata-file-and-filter-for-relevant-sites","dir":"Articles","previous_headings":"Downloading and pre-processing pre-generated EPA AQS data from their website","what":"4. Downloading monitor metadata file and filter for relevant sites","title":"Downloading EPA Daily Data","text":"Download monitors file Unzip read Create site identifier Filter monitors file include monitors csv","code":"destfile <- paste(download_dir, \"aqs_monitors.zip\", sep = \"\") download.file(\"https://aqs.epa.gov/aqsweb/airdata/aqs_monitors.zip\", destfile) unzip(destfile, exdir = download_dir) monitors <- read.csv(\"../input/aqs/aqs_monitors.csv\", stringsAsFactors = FALSE) # Convert from string to numeric to get rid of leading zeros, # the NAs introduced are from monitors in Canada with site number=\"CC\" monitors$State.Code <- as.numeric(monitors$State.Code) monitors$ID.Code <- paste(monitors$State.Code, monitors$County.Code,   monitors$Site.Num, monitors$Parameter.Code,   monitors$POC,   sep = \"-\" ) monitors <- read.csv(\"../input/aqs/aqs_monitors.csv\",   stringsAsFactors = FALSE ) monitors_filter <- monitors[which(monitors$ID.Code %in% data_all$ID.Code), ]"},{"path":"https://niehs.github.io/amadeus/articles/epa_download.html","id":"uploading-data-to-desired-folder","dir":"Articles","previous_headings":"Downloading and pre-processing pre-generated EPA AQS data from their website","what":"5. Uploading data to desired folder","title":"Downloading EPA Daily Data","text":"","code":"savepath <- \"../input/aqs/\"  write.csv(data_all, paste(savepath, resolution, \"_\", parameter_code, \"_\",   startyear, \"-\", endyear, \".csv\",   sep = \"\" )) write.csv(monitors_filter, paste(savepath, \"monitors_\", parameter_code, \"_\",   startyear, \"-\", endyear, \".csv\",   sep = \"\" ))"},{"path":"https://niehs.github.io/amadeus/articles/gridmet_workflow.html","id":"download","dir":"Articles","previous_headings":"","what":"Download","title":"Climatology Lab gridMET","text":"Start downloading netCDF data files download_data. dataset_name = \"gridmet\": gridMET dataset name. variable = \"Near-Surface Specific Humidity\": specific humidity variable name. year = c(2019, 2020): years interest. directory_to_save = dir: directory save downloaded files. acknowledgement = TRUE: acknowledge raw data files large may consume lots local storage. download = TRUE: download data files. remove_command = TRUE: remove temporary command file used download data. hash = TRUE: generate unique SHA-1 hash downloaded files. Check downloaded netCDF files.","code":"dir <- tempdir() amadeus::download_data(   dataset_name = \"gridmet\",   variable = \"Near-Surface Specific Humidity\",   year = c(2019, 2020),   directory_to_save = dir,   acknowledgement = TRUE,   download = TRUE,   remove_command = TRUE,   hash = TRUE ) [1] \"aa5116525468299d1fc483b108b3e841fc40d7e5\" list.files(dir, recursive = TRUE, pattern = \"sph\") [1] \"sph/sph_2019.nc\" \"sph/sph_2020.nc\""},{"path":"https://niehs.github.io/amadeus/articles/gridmet_workflow.html","id":"process","dir":"Articles","previous_headings":"","what":"Process","title":"Climatology Lab gridMET","text":"Import process downloaded netCDF files process_covariates. covariate = \"gridmet\": gridMET dataset name. variable = \"Near-Surface Specific Humidity\": specific humidity variable name. date = c(\"2019-12-13\", \"2022-01-10\"): date range interest. path = paste0(dir, \"/sph\"): directory containing downloaded files. Check processed SpatRaster object.","code":"sph_process <- amadeus::process_covariates(   covariate = \"gridmet\",   variable = \"Near-Surface Specific Humidity\",   date = c(\"2019-12-18\", \"2020-01-10\"),   path = file.path(dir, \"/sph\") ) sph_process class       : SpatRaster  dimensions  : 585, 1386, 24  (nrow, ncol, nlyr) resolution  : 0.04166667, 0.04166667  (x, y) extent      : -124.7875, -67.0375, 25.04583, 49.42083  (xmin, xmax, ymin, ymax) coord. ref. : lon/lat WGS 84 (EPSG:4326)  sources     : sph_2019.nc  (14 layers)                sph_2020.nc  (10 layers)  varnames    : sph (near-surface specific humidity)                sph (near-surface specific humidity)  names       : sph_20191218, sph_20191219, sph_20191220, sph_20191221, sph_20191222, sph_20191223, ...  unit        :        kg/kg,        kg/kg,        kg/kg,        kg/kg,        kg/kg,        kg/kg, ...  time (days) : 2019-12-18 to 2020-01-10 terra::plot(sph_process[[1]])"},{"path":"https://niehs.github.io/amadeus/articles/gridmet_workflow.html","id":"calculate-covariates","dir":"Articles","previous_headings":"","what":"Calculate covariates","title":"Climatology Lab gridMET","text":"Calculate covariates California county boundaries calculate_covariates. County boundaries accessed tigris::counties function. covariate = \"gridmet\": gridMET dataset name. = sph_process: processed SpatRaster object. locs = tigris::counties(\"CA\", year = 2019): California county boundaries. locs_id = \"NAME\": county name identifier. radius = 0: size buffer radius around county. geom = \"sf\": return covariates sf object. Check calculated covariates sf object.","code":"library(tigris) sph_covar <- amadeus::calculate_covariates(   covariate = \"gridmet\",   from = sph_process,   locs = tigris::counties(\"CA\", year = 2019),   locs_id = \"NAME\",   radius = 0,   geom = \"terra\" ) sph_covar class       : SpatVector  geometry    : polygons  dimensions  : 1392, 3  (geometries, attributes) extent      : -124.482, -114.1312, 32.52883, 42.0095  (xmin, xmax, ymin, ymax) coord. ref. : lon/lat WGS 84 (EPSG:4326)  names       :          NAME       time    sph_0 type        :         <chr>   <POSIXt>    <num> values      :        Sierra 2019-12-18 0.003101                  Sacramento 2019-12-18 0.005791               Santa Barbara 2019-12-18 0.004594"},{"path":"https://niehs.github.io/amadeus/articles/modis_workflow.html","id":"modis-grids","dir":"Articles","previous_headings":"","what":"MODIS Grids","title":"NASA Moderate Resolution Imaging Spectroradiometer (MODIS)","text":"MODIS product data files separated based tile grid numbers. download data specific geographic area, users must first identify tile grids correspond area interest. area interest vignettes contiguous United States, corresponding horizontal tiles 7 13 vertical tiles 3 6. See MODIS Grids details.","code":""},{"path":"https://niehs.github.io/amadeus/articles/modis_workflow.html","id":"nasa-earthdata-token","dir":"Articles","previous_headings":"","what":"NASA Earthdata Token","title":"NASA Moderate Resolution Imaging Spectroradiometer (MODIS)","text":"download NASA MODIS files, users must first register NASA EarthData account generate user-specific token. instructions, see Protected Data Sources vignette.","code":""},{"path":"https://niehs.github.io/amadeus/articles/modis_workflow.html","id":"mod11a1---land-surface-temperature-lst","dir":"Articles","previous_headings":"","what":"MOD11A1 - Land Surface Temperature (LST)","title":"NASA Moderate Resolution Imaging Spectroradiometer (MODIS)","text":"MOD11A1 - MODIS/Terra Land Surface Temperature/Emissivity Daily L3 Global 1km SIN Grid V061 product provides daily, global land surface temperature (LST) estimates 1km resolution. Downloaded data files Hierarchical Data Format (HDF), extension .hdf dataset_name = \"modis\": MODIS dataset name. product = \"MOD11A1\": MODIS product name. version =  \"61\": Version 6.1 (recent release 08/07/2025). horizontal_tiles = c(7, 13): Horizontal sinusoidal tiles. vertical_tiles = c(3, 6): Vertical sinusoidal tiles. date = c(\"2019-09-01\", \"2019-09-02\"): Dates interest. nasa_earth_data_token = Sys.getenv(\"EARTHDATA_TOKEN\"): User-specific NASA credentials. directory_to_save = dir_mod11a1: directory save downloaded files. acknowledgement = TRUE: acknowledge raw data files large may consume lots local storage. download = TRUE: download data files. remove_command = TRUE: remove temporary command file used download data. hash = TRUE: generate unique SHA-1 hash downloaded files. Check downloaded files correspond requested tiles dates. Unlike amadeus-supported datasets, users need directly call process_modis_merge function. function passed calculate_covariates function based preprocess parameter. Within calculate_covariates, process_modis_merge function imports downloaded files merges according tile position. Check available layers product. first file used identify available layers. example, interested LST_Day_1km variable daytime land surface temperature. Process, inspect, plot LST data August 15, 2019. Note, calling process_modis_merge directly, users can process one day per function call.  mentioned , processing part amadeus workflow MODIS products. calculate covariates MODIS products, preprocess function layer selections passed parameters calculate_covariates. following code calculate mean LST Connecticut‚Äôs counties August 15 16, 2019. dataset_name = \"modis\": MODIS dataset name. = list.files(dir_mod11a1, full.names = TRUE, recursive = TRUE): MOD11A1 file paths. dates data available file paths determine dates output. locs = tigris::counties(\"CT\", year = 2019, cb = TRUE): Connecticut county polygons. locs_id = \"NAME\": Use NAME column unique county identifiers. radius = 0L: Apply 0m buffer plygons. preprocess = amadeus::process_modis_merge: Preprocess .hdf files merging function. subdataset = \"LST_Day_1km\": Daytime LST variable code. name_covariates = \"LST_\": Prefix column name calculated covariates. fun_summary = \"mean\": Calculate mean LST value. geom = FALSE: return spatial geometries (ie. return data.frame). scale = \"* 0.02 - 273.15\": Multiply values 0.02 subtract 273.15. scale parameter crucial scales values stored .hdf files scientifically interpretable values. scale factor MODIS product can found technical documentation (also called User Guide). scale factor MOD11A1 0.02 (see https://lpdaac.usgs.gov/documents/715/MOD11_User_Guide_V61.pdf Table 3. SDSs MOD11_L2 product). scale factor converts values Kelvin, converted Celsius additional - 273.15 expression. data.frame, mean LST values county calculated August 15 16, 2019, dates originally passed download_data. column containing mean LST variables LST_00000, reflects manually set name_covariates = \"LST_\" prefix buffer radius (padded 5 digits). LST_00000 column contains LST values Celsius, per scale parameter. calculate mean LST centroid Connecticut county 100m buffer, covariate column name LST_00100.","code":"dir_mod11a1 <- file.path(tempdir(), \"mod11a1\") amadeus::download_data(   dataset_name = \"modis\",   product = \"MOD11A1\",   version = \"61\",   horizontal_tiles = c(7, 13),   vertical_tiles = c(3, 6),   date = c(\"2019-08-15\", \"2019-08-16\"),   nasa_earth_data_token = Sys.getenv(\"EARTHDATA_TOKEN\"),   directory_to_save = dir_mod11a1,   acknowledge = TRUE,   download = TRUE,   remove_command = TRUE,   hash = TRUE ) 2 / 2 days of data available in the queried dates.  Downloading requested files...  [`wget` DOWNLOAD OUTPUT OMITTED]  Requested files have been downloaded.  Requests were processed.  [1] \"bbbd6812cf686d9dac059a6aab27293d\" list.files(dir_mod11a1, recursive = TRUE) [1] \"2019/244/MOD11A1.A2019244.h07v03.061.2020359040222.hdf\"  [2] \"2019/244/MOD11A1.A2019244.h07v05.061.2020359040223.hdf\"  [3] \"2019/244/MOD11A1.A2019244.h07v06.061.2020359040210.hdf\"  [4] \"2019/244/MOD11A1.A2019244.h08v03.061.2020359040215.hdf\"  [5] \"2019/244/MOD11A1.A2019244.h08v04.061.2020359040147.hdf\"  [6] \"2019/244/MOD11A1.A2019244.h08v05.061.2020359040228.hdf\"  [7] \"2019/244/MOD11A1.A2019244.h08v06.061.2020359040221.hdf\"  [8] \"2019/244/MOD11A1.A2019244.h09v03.061.2020359040130.hdf\"  [9] \"2019/244/MOD11A1.A2019244.h09v04.061.2020359040211.hdf\" [10] \"2019/244/MOD11A1.A2019244.h09v05.061.2020359040208.hdf\" [11] \"2019/244/MOD11A1.A2019244.h09v06.061.2020359040116.hdf\" [12] \"2019/244/MOD11A1.A2019244.h10v03.061.2020359040202.hdf\" [13] \"2019/244/MOD11A1.A2019244.h10v04.061.2020359040203.hdf\" [14] \"2019/244/MOD11A1.A2019244.h10v05.061.2020359040223.hdf\" [15] \"2019/244/MOD11A1.A2019244.h10v06.061.2020359040146.hdf\" [16] \"2019/244/MOD11A1.A2019244.h11v03.061.2020359040221.hdf\" [17] \"2019/244/MOD11A1.A2019244.h11v04.061.2020359040244.hdf\" [18] \"2019/244/MOD11A1.A2019244.h11v05.061.2020359040135.hdf\" [19] \"2019/244/MOD11A1.A2019244.h11v06.061.2020359040057.hdf\" [20] \"2019/244/MOD11A1.A2019244.h12v03.061.2020359040138.hdf\" [21] \"2019/244/MOD11A1.A2019244.h12v04.061.2020359040148.hdf\" [22] \"2019/244/MOD11A1.A2019244.h12v05.061.2020359040131.hdf\" [23] \"2019/244/MOD11A1.A2019244.h13v03.061.2020359040116.hdf\" [24] \"2019/244/MOD11A1.A2019244.h13v04.061.2020359040145.hdf\" [25] \"2019/245/MOD11A1.A2019245.h07v03.061.2020359055441.hdf\" [26] \"2019/245/MOD11A1.A2019245.h07v05.061.2020359055458.hdf\" [27] \"2019/245/MOD11A1.A2019245.h07v06.061.2020359055458.hdf\" [28] \"2019/245/MOD11A1.A2019245.h08v03.061.2020359055537.hdf\" [29] \"2019/245/MOD11A1.A2019245.h08v04.061.2020359055634.hdf\" [30] \"2019/245/MOD11A1.A2019245.h08v05.061.2020359055658.hdf\" [31] \"2019/245/MOD11A1.A2019245.h08v06.061.2020359055704.hdf\" [32] \"2019/245/MOD11A1.A2019245.h09v03.061.2020359055648.hdf\" [33] \"2019/245/MOD11A1.A2019245.h09v04.061.2020359055602.hdf\" [34] \"2019/245/MOD11A1.A2019245.h09v05.061.2020359055715.hdf\" [35] \"2019/245/MOD11A1.A2019245.h09v06.061.2020359055649.hdf\" [36] \"2019/245/MOD11A1.A2019245.h10v03.061.2020359055611.hdf\" [37] \"2019/245/MOD11A1.A2019245.h10v04.061.2020359055559.hdf\" [38] \"2019/245/MOD11A1.A2019245.h10v05.061.2020359055531.hdf\" [39] \"2019/245/MOD11A1.A2019245.h10v06.061.2020359055702.hdf\" [40] \"2019/245/MOD11A1.A2019245.h11v03.061.2020359055542.hdf\" [41] \"2019/245/MOD11A1.A2019245.h11v04.061.2020359055542.hdf\" [42] \"2019/245/MOD11A1.A2019245.h11v05.061.2020359055613.hdf\" [43] \"2019/245/MOD11A1.A2019245.h11v06.061.2020359055445.hdf\" [44] \"2019/245/MOD11A1.A2019245.h12v03.061.2020359055532.hdf\" [45] \"2019/245/MOD11A1.A2019245.h12v04.061.2020359055524.hdf\" [46] \"2019/245/MOD11A1.A2019245.h12v05.061.2020359055454.hdf\" [47] \"2019/245/MOD11A1.A2019245.h13v03.061.2020359055516.hdf\" [48] \"2019/245/MOD11A1.A2019245.h13v04.061.2020359055521.hdf\" terra::describe(   list.files(dir_mod11a1, full.names = TRUE, recursive = TRUE)[1],   sds = TRUE )$var [1] \"LST_Day_1km\"     \"QC_Day\"          \"Day_view_time\"   \"Day_view_angl\"  [5] \"LST_Night_1km\"   \"QC_Night\"        \"Night_view_time\" \"Night_view_angl\"  [9] \"Emis_31\"         \"Emis_32\"         \"Clear_day_cov\"   \"Clear_night_cov\" rast_mod11a1 <- amadeus::process_modis_merge(   path = list.files(dir_mod11a1, full.names = TRUE, recursive = TRUE),   date = \"2019-08-15\",   subdataset = \"LST_Day_1km\" ) rast_mod11a1 class       : SpatRaster size        : 4800, 8400, 1  (nrow, ncol, nlyr) resolution  : 926.6254, 926.6254  (x, y) extent      : -12231456, -4447802, 2223901, 6671703  (xmin, xmax, ymin, ymax) coord. ref. : +proj=sinu +lon_0=0 +x_0=0 +y_0=0 +R=6371007.181 +units=m +no_defs source(s)   : memory varname     : MOD11A1.A2019244.h07v03.061.2020359040222 name        : LST_Day_1km min value   :       12609 max value   :       16886 terra::plot(rast_mod11a1$LST_Day_1km) df_mod11a1 <- amadeus::calculate_covariates(   dataset_name = \"modis\",   from = list.files(dir_mod11a1, full.names = TRUE, recursive = TRUE),   locs = tigris::counties(\"CT\", year = 2019),   locs_id = \"NAME\",   radius = 0L,   preprocess = amadeus::process_modis_merge,   subdataset = \"LST_Day_1km\",   name_covariates = \"LST_\",   fun_summary = \"mean\",   geom = FALSE,   scale = \"* 0.02 - 273.15\" ) df_mod11a1 NAME LST_00000       time 1   Middlesex  28.06504 2019-08-15 2  New London  27.04361 2019-08-15 3   New Haven  28.30738 2019-08-15 4     Tolland  27.73284 2019-08-15 5    Hartford  28.19241 2019-08-15 6     Windham  26.81317 2019-08-15 7   Fairfield  27.98380 2019-08-15 8  Litchfield  26.95756 2019-08-15 9   Middlesex  24.12254 2019-08-16 10 New London  24.15377 2019-08-16 11  New Haven  25.04651 2019-08-16 12    Tolland  24.82655 2019-08-16 13   Hartford  26.15234 2019-08-16 14    Windham  22.61115 2019-08-16 15  Fairfield  24.45862 2019-08-16 16 Litchfield  24.06681 2019-08-16 df_mod11a1_centroids <- amadeus::calculate_covariates(   dataset_name = \"modis\",   from = list.files(dir_mod11a1, full.names = TRUE, recursive = TRUE),   locs = sf::st_centroid( # centroids of each county     tigris::counties(\"CT\", year = 2019)   ),   locs_id = \"NAME\",   radius = 100L, # 100 meter circular buffer   preprocess = amadeus::process_modis_merge,   subdataset = \"LST_Day_1km\",   name_covariates = \"LST_\",   fun_summary = \"mean\",   geom = FALSE,   scale = \"* 0.02 - 273.15\" ) df_mod11a1_centroids NAME LST_00100       time 1   Middlesex  26.19000 2019-08-15 2  New London  27.40616 2019-08-15 3   New Haven  32.71462 2019-08-15 4     Tolland  27.31000 2019-08-15 5    Hartford  32.75000 2019-08-15 6     Windham  26.47000 2019-08-15 7   Fairfield  28.18088 2019-08-15 8  Litchfield  22.83000 2019-08-15 9   Middlesex  23.51000 2019-08-16 10 New London  23.73023 2019-08-16 11  New Haven  28.45154 2019-08-16 12    Tolland  25.13000 2019-08-16 13   Hartford  29.47000 2019-08-16 14    Windham  24.43000 2019-08-16 15  Fairfield  22.41000 2019-08-16 16 Litchfield  21.07516 2019-08-16"},{"path":"https://niehs.github.io/amadeus/articles/modis_workflow.html","id":"vnp46a2---nighttime-lights-ntl","dir":"Articles","previous_headings":"","what":"VNP46A2 - Nighttime Lights (NTL)","title":"NASA Moderate Resolution Imaging Spectroradiometer (MODIS)","text":"VNP46A2 - VIIRS/NPP Gap-Filled Lunar BRDF-Adjusted Nighttime Lights Daily L3 Global 500m Linear Lat Lon Grid product provides ‚Äúglobal, daily measurements nocturnal visible near-infrared (NIR) light suitable Earth system science applications‚Äù. Downloaded data files Hierarchical Data Format version 5 (HDF5), extension .h5 dataset_name = \"modis\": MODIS dataset name. product = \"VNP46A2\": MODIS product name. version =  \"61\": Version 6.1 (recent release 08/07/2025). horizontal_tiles = c(7, 13): Horizontal sinusoidal tiles. vertical_tiles = c(3, 6): Vertical sinusoidal tiles. date = c(\"2019-09-01\", \"2019-09-02\"): Dates interest. nasa_earth_data_token = Sys.getenv(\"EARTHDATA_TOKEN\"): User-specific NASA credentials. directory_to_save = dir_vnp46a2: directory save downloaded files. acknowledgement = TRUE: acknowledge raw data files large may consume lots local storage. download = TRUE: download data files. remove_command = TRUE: remove temporary command file used download data. hash = TRUE: generate unique SHA-1 hash downloaded files. Check downloaded files correspond requested tiles dates. processing function associated VNP46A2 product process_blackmarble, designed accomodate .h5 file type. , users need directly call process_modis_merge function., function passed calculate_covariates function based preprocess parameter. following ‚Äúprocessing‚Äù steps demonstration . Check available layers product. first file used identify available layers. interested subdataset //HDFEOS/GRIDS/VNP_Grid_DNB/Data_Fields/Gap_Filled_DNB_BRDF-Corrected_NTL, contains gap-filled Day-Night Band, Corrected Nighttime Lights data. variable string associated .h5 file type long complex, can identify subset interest index value. case, subdataset = 3L Gap_Filled_DNB_BRDF-Corrected_NTL third subdataset file. tile_df parameter unique process_blackmarble processing function, set output process_blackmarble_corners function. process_blackmarble_corners generates data.frame corner coordinates based sinuosidal grid tiles HDF5 format read without georeference.  following code calculate maximum NTL values Connecticut‚Äôs counties August 15 16, 2019. dataset_name = \"modis\": MODIS dataset name. = list.files(dir_mod11a1, full.names = TRUE, recursive = TRUE): MOD11A1 file paths. dates data available file paths determine dates output. locs = tigris::counties(\"CT\", year = 2019, cb = TRUE): Connecticut county polygons. locs_id = \"NAME\": Use NAME column unique county identifiers. radius = 0L: Apply 0m buffer plygons. preprocess = amadeus::process_blackmarble: Preprocess .h5 files merging function. tile_df = amadeus::process_blackmarble_corners(hrange = c(7, 13), vrange = c(3, 6))): Process combination horizontal tiles 7 13 vertical tiles 3 6. subdataset = 3L: Third subdataset NTL variable (Gap_Filled_DNB_BRDF-Corrected_NTL). name_covariates = \"NTL_\": Prefix column name calculated covariates. fun_summary = \"max\": Calculate maximum NTL value. geom = \"terra\": Return terra SpatVector object. scale = \"* 1.0: Multiply values 1.0. scale factor VNP46A2 1.0 (see https://ladsweb.modaps.eosdis.nasa.gov/api/v2/content/archives/Document%20Archive/Science%20Data%20Product%20Documentation/Black-Marble_v2.0_UG_2024.pdf Table 8. Scientific datasets included VNP46A2/VJI46A2 daily moonlight-adjusted NTL product). function returns SpatVector, spatially-enabled tabular data form terra package. column names data values returned data.frame, row associated polygon(s) define county boundary. SpatVector, maximum NTL values county calculated August 15 16, 2019, dates originally passed download_data. column containing NTL variables NTL_00000, reflects manually set name_covariates = \"NTL_\" prefix buffer radius (padded 5 digits).","code":"dir_vnp46a2 <- file.path(tempdir(), \"vnp46a2\") amadeus::download_data(   dataset_name = \"modis\",   product = \"VNP46A2\",   version = \"61\",   horizontal_tiles = c(7, 13),   vertical_tiles = c(3, 6),   date = c(\"2019-08-15\", \"2019-08-16\"),   nasa_earth_data_token = Sys.getenv(\"EARTHDATA_TOKEN\"),   directory_to_save = dir_vnp46a2,   acknowledge = TRUE,   download = TRUE,   remove_command = TRUE,   hash = TRUE ) 2 / 2 days of data available in the queried dates.  Downloading requested files...  [`wget` DOWNLOAD OUTPUT OMITTED]  Requested files have been downloaded.  Requests were processed.  [1] \"c7ada546dd471eedcce3266fd860c8fe\" list.files(dir_vnp46a2, recursive = TRUE) [1] \"2019/227/VNP46A2.A2019227.h07v03.001.2021028023053.h5\"  [2] \"2019/227/VNP46A2.A2019227.h07v04.001.2021034095643.h5\"  [3] \"2019/227/VNP46A2.A2019227.h07v05.001.2021034103316.h5\"  [4] \"2019/227/VNP46A2.A2019227.h07v06.001.2021034065004.h5\"  [5] \"2019/227/VNP46A2.A2019227.h08v03.001.2021028011018.h5\"  [6] \"2019/227/VNP46A2.A2019227.h08v04.001.2021034074618.h5\"  [7] \"2019/227/VNP46A2.A2019227.h08v05.001.2021034053658.h5\"  [8] \"2019/227/VNP46A2.A2019227.h08v06.001.2021033195730.h5\"  [9] \"2019/227/VNP46A2.A2019227.h09v03.001.2021027223658.h5\" [10] \"2019/227/VNP46A2.A2019227.h09v04.001.2021034071039.h5\" [11] \"2019/227/VNP46A2.A2019227.h09v05.001.2021034063949.h5\" [12] \"2019/227/VNP46A2.A2019227.h09v06.001.2021033151848.h5\" [13] \"2019/227/VNP46A2.A2019227.h10v03.001.2021028020730.h5\" [14] \"2019/227/VNP46A2.A2019227.h10v04.001.2021034051503.h5\" [15] \"2019/227/VNP46A2.A2019227.h10v05.001.2021033165400.h5\" [16] \"2019/227/VNP46A2.A2019227.h10v06.001.2021033140014.h5\" [17] \"2019/227/VNP46A2.A2019227.h11v03.001.2021028020226.h5\" [18] \"2019/227/VNP46A2.A2019227.h11v04.001.2021033204459.h5\" [19] \"2019/227/VNP46A2.A2019227.h11v05.001.2021033095716.h5\" [20] \"2019/227/VNP46A2.A2019227.h12v03.001.2021027174719.h5\" [21] \"2019/227/VNP46A2.A2019227.h12v04.001.2021033162849.h5\" [22] \"2019/228/VNP46A2.A2019228.h07v03.001.2021028030331.h5\" [23] \"2019/228/VNP46A2.A2019228.h07v04.001.2021034113626.h5\" [24] \"2019/228/VNP46A2.A2019228.h07v05.001.2021034115815.h5\" [25] \"2019/228/VNP46A2.A2019228.h07v06.001.2021034080708.h5\" [26] \"2019/228/VNP46A2.A2019228.h08v03.001.2021028014406.h5\" [27] \"2019/228/VNP46A2.A2019228.h08v04.001.2021034092243.h5\" [28] \"2019/228/VNP46A2.A2019228.h08v05.001.2021034065601.h5\" [29] \"2019/228/VNP46A2.A2019228.h08v06.001.2021033202639.h5\" [30] \"2019/228/VNP46A2.A2019228.h09v03.001.2021027230113.h5\" [31] \"2019/228/VNP46A2.A2019228.h09v04.001.2021034083500.h5\" [32] \"2019/228/VNP46A2.A2019228.h09v05.001.2021034075715.h5\" [33] \"2019/228/VNP46A2.A2019228.h09v06.001.2021033154608.h5\" [34] \"2019/228/VNP46A2.A2019228.h10v03.001.2021028024419.h5\" [35] \"2019/228/VNP46A2.A2019228.h10v04.001.2021034064406.h5\" [36] \"2019/228/VNP46A2.A2019228.h10v05.001.2021033174505.h5\" [37] \"2019/228/VNP46A2.A2019228.h10v06.001.2021033144003.h5\" [38] \"2019/228/VNP46A2.A2019228.h11v03.001.2021028023944.h5\" [39] \"2019/228/VNP46A2.A2019228.h11v04.001.2021033213449.h5\" [40] \"2019/228/VNP46A2.A2019228.h11v05.001.2021033101041.h5\" [41] \"2019/228/VNP46A2.A2019228.h12v03.001.2021027180253.h5\" [42] \"2019/228/VNP46A2.A2019228.h12v04.001.2021033170017.h5\" terra::describe(   list.files(dir_vnp46a2, full.names = TRUE, recursive = TRUE)[1],   sds = TRUE )$var [1] \"//HDFEOS/GRIDS/VNP_Grid_DNB/Data_Fields/DNB_BRDF-Corrected_NTL\" [2] \"//HDFEOS/GRIDS/VNP_Grid_DNB/Data_Fields/DNB_Lunar_Irradiance\" [3] \"//HDFEOS/GRIDS/VNP_Grid_DNB/Data_Fields/Gap_Filled_DNB_BRDF-Corrected_NTL\" [4] \"//HDFEOS/GRIDS/VNP_Grid_DNB/Data_Fields/Latest_High_Quality_Retrieval\" [5] \"//HDFEOS/GRIDS/VNP_Grid_DNB/Data_Fields/Mandatory_Quality_Flag\" [6] \"//HDFEOS/GRIDS/VNP_Grid_DNB/Data_Fields/QF_Cloud_Mask\" [7] \"//HDFEOS/GRIDS/VNP_Grid_DNB/Data_Fields/Snow_Flag\" rast_vnp46a2 <- amadeus::process_blackmarble(   path = list.files(dir_vnp46a2, full.names = TRUE, recursive = TRUE),   date = \"2019-08-15\",   tile_df = amadeus::process_blackmarble_corners(     hrange = c(7, 13),     vrange = c(3, 6)   ),   subdataset = 3L ) rast_vnp46a2 class       : SpatRaster size        : 9600, 14400, 1  (nrow, ncol, nlyr) resolution  : 0.004166667, 0.004166667  (x, y) extent      : -110, -50, 20, 60  (xmin, xmax, ymin, ymax) coord. ref. : lon/lat WGS 84 (EPSG:4326) source(s)   : memory varname     : Gap_Filled_DNB_BRDF-Corrected_NTL name        : DNB_BRDF-Corrected_NTL min value   :                      0 max value   :                  49993 terra::plot(rast_vnp46a2) vect_vnp46a2 <- amadeus::calculate_covariates(   covariate = \"modis\",   from = list.files(dir_vnp46a2, full.names = TRUE, recursive = TRUE),   locs = tigris::counties(\"CT\", year = 2019),   locs_id = \"NAME\",   radius = 0L,   preprocess = amadeus::process_blackmarble,   tile_df = amadeus::process_blackmarble_corners(     hrange = c(7, 13), vrange = c(3, 6)   ),   subdataset = 3L,   name_covariates = \"NTL_\",   fun_summary = \"max\",   geom = \"terra\",   scale = \"* 1.0\" ) vect_vnp46a2 class       : SpatVector  geometry    : polygons  dimensions  : 16, 3  (geometries, attributes)  extent      : -73.72777, -71.78724, 40.95094, 42.05051  (xmin, xmax, ymin, ymax)  coord. ref. : lon/lat NAD83 (EPSG:4269)  names       :      NAME NTL_00000       time  type        :     <chr>     <num>   <POSIXt>  values      : Fairfield       855 2019-08-15                Fairfield       670 2019-08-16                 Hartford       380 2019-08-15"},{"path":"https://niehs.github.io/amadeus/articles/modis_workflow.html","id":"mod06_l2---cloud-coverage","dir":"Articles","previous_headings":"","what":"MOD06_L2 - Cloud Coverage","title":"NASA Moderate Resolution Imaging Spectroradiometer (MODIS)","text":"MOD06_L2 - MODIS/Terra Clouds 5-Min L2 Swath 1km 5km product contains ‚Äúcloud optical physical parameters‚Äù. download MOD06_L2 product files, users must manually generate .csv file containing download links NASA‚Äôs Level-1 Atmosphere Archive & Distribution System (LAADS) Distributed Active Archive Center (DAAC) portal. .csv file must saved directory accessible current working session. Generate .csv file dates previous two examples, August 15 16, 2019, ‚ÄúDay‚Äù coverage. example, custom bounding box drawn around contiguous United States.  Selecting ‚ÄúNext‚Äù list available .hdf files associated spatial temporal selections. , selecting ‚Äúcsv‚Äù generate .csv file contains necessary download links.  file manually moved vignettes/data/ folder. dataset_name = \"modis\": MODIS dataset name. product = \"MOD06_L2\": MODIS product name. version =  \"61\": Version 6.1 (recent release 08/07/2025). horizontal_tiles = c(7, 13): Horizontal sinusoidal tiles. vertical_tiles = c(3, 6): Vertical sinusoidal tiles. date = c(\"2019-09-01\", \"2019-09-02\"): Dates interest. nasa_earth_data_token = Sys.getenv(\"EARTHDATA_TOKEN\"): User-specific NASA credentials. mod06_links = \"vignettes/data/LAADS_query.2025-08-12T14_29.csv\": Manually downloaded CSV file MOD06_L2 links. directory_to_save = dir_mod06l2: directory save downloaded files. acknowledgement = TRUE: acknowledge raw data files large may consume lots local storage. download = TRUE: download data files. remove_command = TRUE: remove temporary command file used download data. hash = TRUE: generate unique SHA-1 hash downloaded files. Check downloaded files correspond requested tiles dates. processing function associated MOD06_L2 product process_modis_merge. , users need directly call process_modis_merge function., function passed calculate_covariates function based preprocess parameter. following ‚Äúprocessing‚Äù steps demonstration . Check available layers product. first file used identify available layers. L2 (level 2) product lots subdatasets undergone fewer processing steps level 3 (L3) product like MOD11A1 VNP46A2 examples. interested Cloud_Fraction_Day subdataset, contains daytime cloud fraction coverage. processing function MODIS swath products process_modis_swath. function internally warps inputs mosaics warped images one SpatRaster.  following code calculate median daytime cloud fraction coverage Connecticut‚Äôs counties August 15 16, 2019. dataset_name = \"modis\": MODIS dataset name. = list.files(dir_mod06l2, full.names = TRUE, recursive = TRUE): MOD06_L2 file paths. dates data available file paths determine dates output. locs = tigris::counties(\"CT\", year = 2019, cb = TRUE): Connecticut county polygons. locs_id = \"NAME\": Use NAME column unique county identifiers. radius = 0L: Apply 0m buffer plygons. preprocess = amadeus::process_modis_swath: Preprocess swath datasets mosaiac. subdataset = \"Cloud_Fraction_Day\": Daytime cloud fraction coverage variable. name_covariates = \"CLFRD_\": Prefix column name calculated covariates. fun_summary = \"median\": Calculate median daytime cloud fraction coverage value. geom = \"sf\": Return sf object. scale = \"* 1.0: Multiply values 1.0. scale factor MOD06_L2 0.009999999776482582 (see https://atmosphere-imager.gsfc.nasa.gov/sites/default/files/ModAtmo/MOD06_L2_CDL_fs.txt). function returns sf object, spatially-enabled tabular data form sf package. column names data values returned data.frame, row associated polygon(s) define county boundary. sf object, median daytime cloud fraction coverage values county calculated August 15 16, 2019, dates originally passed download_data. column containing cloud variables CLFRD_00000, reflects manually set name_covariates = \"CLFRD_\" prefix buffer radius (padded 5 digits).","code":"list.files(file.path(\"vignettes\", \"data\"), full.names = TRUE) [1] \"vignettes/data/LAADS_query.2025-08-12T14_29.csv\" dir_mod06l2 <- file.path(tempdir(), \"mod06l2\") amadeus::download_data(   dataset_name = \"modis\",   product = \"MOD06_L2\",   version = \"61\",   horizontal_tiles = c(7, 13),   vertical_tiles = c(3, 6),   mod06_links = \"vignettes/data/LAADS_query.2025-08-12T14_29.csv\",   date = c(\"2019-08-15\", \"2019-08-16\"),   nasa_earth_data_token = Sys.getenv(\"EARTHDATA_TOKEN\"),   directory_to_save = dir_mod06l2,   acknowledge = TRUE,   download = TRUE,   remove_command = TRUE,   hash = TRUE ) 2 / 2 days of data available in the queried dates.  Downloading requested files...  [`wget` DOWNLOAD OUTPUT OMITTED]  Requested files have been downloaded.  Requests were processed.  [1] \"f43bdc3f850a734d5263a274762379e9\" list.files(dir_mod06l2, recursive = TRUE) [1] \"2019/227/MOD06_L2.A2019227.1355.061.2019228034420.hdf\"  [2] \"2019/227/MOD06_L2.A2019227.1400.061.2019228034841.hdf\"  [3] \"2019/227/MOD06_L2.A2019227.1405.061.2019228031931.hdf\"  [4] \"2019/227/MOD06_L2.A2019227.1410.061.2019228034018.hdf\"  [5] \"2019/227/MOD06_L2.A2019227.1535.061.2019228040729.hdf\"  [6] \"2019/227/MOD06_L2.A2019227.1540.061.2019228042901.hdf\"  [7] \"2019/227/MOD06_L2.A2019227.1545.061.2019228041453.hdf\"  [8] \"2019/227/MOD06_L2.A2019227.1550.061.2019228034852.hdf\"  [9] \"2019/227/MOD06_L2.A2019227.1715.061.2019228034600.hdf\" [10] \"2019/227/MOD06_L2.A2019227.1720.061.2019228032806.hdf\" [11] \"2019/227/MOD06_L2.A2019227.1725.061.2019228033727.hdf\" [12] \"2019/227/MOD06_L2.A2019227.1855.061.2019228093012.hdf\" [13] \"2019/227/MOD06_L2.A2019227.1900.061.2019228095925.hdf\" [14] \"2019/227/MOD06_L2.A2019227.1905.061.2019228093102.hdf\" [15] \"2019/227/MOD06_L2.A2019227.2030.061.2019228100212.hdf\" [16] \"2019/227/MOD06_L2.A2019227.2035.061.2019228100208.hdf\" [17] \"2019/227/MOD06_L2.A2019227.2040.061.2019228102930.hdf\" [18] \"2019/227/MOD06_L2.A2019227.2210.061.2019228100421.hdf\" [19] \"2019/228/MOD06_L2.A2019228.1440.061.2019229013924.hdf\" [20] \"2019/228/MOD06_L2.A2019228.1445.061.2019229014222.hdf\" [21] \"2019/228/MOD06_L2.A2019228.1450.061.2019229013756.hdf\" [22] \"2019/228/MOD06_L2.A2019228.1455.061.2019229013623.hdf\" [23] \"2019/228/MOD06_L2.A2019228.1620.061.2019229013909.hdf\" [24] \"2019/228/MOD06_L2.A2019228.1625.061.2019229014711.hdf\" [25] \"2019/228/MOD06_L2.A2019228.1630.061.2019229013623.hdf\" [26] \"2019/228/MOD06_L2.A2019228.1800.061.2019229074055.hdf\" [27] \"2019/228/MOD06_L2.A2019228.1805.061.2019229073242.hdf\" [28] \"2019/228/MOD06_L2.A2019228.1810.061.2019229073728.hdf\" [29] \"2019/228/MOD06_L2.A2019228.1935.061.2019229074033.hdf\" [30] \"2019/228/MOD06_L2.A2019228.1940.061.2019229074120.hdf\" [31] \"2019/228/MOD06_L2.A2019228.1945.061.2019229074028.hdf\" [32] \"2019/228/MOD06_L2.A2019228.1950.061.2019229074707.hdf\" [33] \"2019/228/MOD06_L2.A2019228.2115.061.2019229074046.hdf\" [34] \"2019/228/MOD06_L2.A2019228.2120.061.2019229074147.hdf\" terra::describe(   list.files(dir_mod06l2, full.names = TRUE, recursive = TRUE)[1],   sds = TRUE )$var [1] \"Scan_Start_Time\"   [2] \"Solar_Zenith\"   [3] \"Solar_Zenith_Day\"   [4] \"Solar_Zenith_Night\"   [5] \"Solar_Azimuth\"   [6] \"Solar_Azimuth_Day\"   [7] \"Solar_Azimuth_Night\"   [8] \"Sensor_Zenith\"   [9] \"Sensor_Zenith_Day\"  [10] \"Sensor_Zenith_Night\"  [11] \"Sensor_Azimuth\"  [12] \"Sensor_Azimuth_Day\"  [13] \"Sensor_Azimuth_Night\"  [14] \"Brightness_Temperature\"  [15] \"Surface_Temperature\"  [16] \"Surface_Pressure\"  [17] \"Cloud_Height_Method\"  [18] \"Cloud_Top_Height\"  [19] \"Cloud_Top_Height_Nadir\"  [20] \"Cloud_Top_Height_Nadir_Day\"  [21] \"Cloud_Top_Height_Nadir_Night\"  [22] \"Cloud_Top_Pressure\"  [23] \"Cloud_Top_Pressure_Nadir\"  [24] \"Cloud_Top_Pressure_Night\"  [25] \"Cloud_Top_Pressure_Nadir_Night\"  [26] \"Cloud_Top_Pressure_Day\"  [27] \"Cloud_Top_Pressure_Nadir_Day\"  [28] \"Cloud_Top_Temperature\"  [29] \"Cloud_Top_Temperature_Nadir\"  [30] \"Cloud_Top_Temperature_Night\"  [31] \"Cloud_Top_Temperature_Nadir_Night\"  [32] \"Cloud_Top_Temperature_Day\"  [33] \"Cloud_Top_Temperature_Nadir_Day\"  [34] \"Tropopause_Height\"  [35] \"Cloud_Fraction\"  [36] \"Cloud_Fraction_Nadir\"  [37] \"Cloud_Fraction_Night\"  [38] \"Cloud_Fraction_Nadir_Night\"  [39] \"Cloud_Fraction_Day\"  [40] \"Cloud_Fraction_Nadir_Day\"  [41] \"Cloud_Effective_Emissivity\"  [42] \"Cloud_Effective_Emissivity_Nadir\"  [43] \"Cloud_Effective_Emissivity_Night\"  [44] \"Cloud_Effective_Emissivity_Nadir_Night\"  [45] \"Cloud_Effective_Emissivity_Day\"  [46] \"Cloud_Effective_Emissivity_Nadir_Day\"  [47] \"Cloud_Top_Pressure_Infrared\"  [48] \"Spectral_Cloud_Forcing\"  [49] \"Cloud_Top_Pressure_From_Ratios\"  [50] \"Radiance_Variance\"  [51] \"Cloud_Phase_Infrared\"  [52] \"Cloud_Phase_Infrared_Night\"  [53] \"Cloud_Phase_Infrared_Day\"  [54] \"Cloud_Phase_Infrared_1km\"  [55] \"IRP_CTH_Consistency_Flag_1km\"  [56] \"os_top_flag_1km\"  [57] \"cloud_top_pressure_1km\"  [58] \"cloud_top_height_1km\"  [59] \"cloud_top_temperature_1km\"  [60] \"cloud_emissivity_1km\"  [61] \"cloud_top_method_1km\"  [62] \"surface_temperature_1km\"  [63] \"cloud_emiss11_1km\"  [64] \"cloud_emiss12_1km\"  [65] \"cloud_emiss13_1km\"  [66] \"cloud_emiss85_1km\"  [67] \"Cloud_Effective_Radius\"  [68] \"Cloud_Effective_Radius_PCL\"  [69] \"Cloud_Effective_Radius_16\"  [70] \"Cloud_Effective_Radius_16_PCL\"  [71] \"Cloud_Effective_Radius_37\"  [72] \"Cloud_Effective_Radius_37_PCL\"  [73] \"Cloud_Optical_Thickness\"  [74] \"Cloud_Optical_Thickness_PCL\"  [75] \"Cloud_Optical_Thickness_16\"  [76] \"Cloud_Optical_Thickness_16_PCL\"  [77] \"Cloud_Optical_Thickness_37\"  [78] \"Cloud_Optical_Thickness_37_PCL\"  [79] \"Cloud_Effective_Radius_1621\"  [80] \"Cloud_Effective_Radius_1621_PCL\"  [81] \"Cloud_Optical_Thickness_1621\"  [82] \"Cloud_Optical_Thickness_1621_PCL\"  [83] \"Cloud_Water_Path\"  [84] \"Cloud_Water_Path_PCL\"  [85] \"Cloud_Water_Path_1621\"  [86] \"Cloud_Water_Path_1621_PCL\"  [87] \"Cloud_Water_Path_16\"  [88] \"Cloud_Water_Path_16_PCL\"  [89] \"Cloud_Water_Path_37\"  [90] \"Cloud_Water_Path_37_PCL\"  [91] \"Cloud_Effective_Radius_Uncertainty\"  [92] \"Cloud_Effective_Radius_Uncertainty_16\"  [93] \"Cloud_Effective_Radius_Uncertainty_37\"  [94] \"Cloud_Optical_Thickness_Uncertainty\"  [95] \"Cloud_Optical_Thickness_Uncertainty_16\"  [96] \"Cloud_Optical_Thickness_Uncertainty_37\"  [97] \"Cloud_Water_Path_Uncertainty\"  [98] \"Cloud_Effective_Radius_Uncertainty_1621\"  [99] \"Cloud_Optical_Thickness_Uncertainty_1621\" [100] \"Cloud_Water_Path_Uncertainty_1621\" [101] \"Cloud_Water_Path_Uncertainty_16\" [102] \"Cloud_Water_Path_Uncertainty_37\" [103] \"Above_Cloud_Water_Vapor_094\" [104] \"IRW_Low_Cloud_Temperature_From_COP\" [105] \"Cloud_Phase_Optical_Properties\" [106] \"Cloud_Multi_Layer_Flag\" [107] \"Cirrus_Reflectance\" [108] \"Cirrus_Reflectance_Flag\" [109] \"Cloud_Mask_5km\" [110] \"Quality_Assurance_5km\" [111] \"Cloud_Mask_1km\" [112] \"Extinction_Efficiency_Ice\" [113] \"Asymmetry_Parameter_Ice\" [114] \"Single_Scatter_Albedo_Ice\" [115] \"Extinction_Efficiency_Liq\" [116] \"Asymmetry_Parameter_Liq\" [117] \"Single_Scatter_Albedo_Liq\" [118] \"Cloud_Mask_SPI\" [119] \"Retrieval_Failure_Metric\" [120] \"Retrieval_Failure_Metric_16\" [121] \"Retrieval_Failure_Metric_37\" [122] \"Retrieval_Failure_Metric_1621\" [123] \"Atm_Corr_Refl\" [124] \"Quality_Assurance_1km\" rast_mod06l2 <- amadeus::process_modis_swath(   path = list.files(dir_mod06l2, full.names = TRUE, recursive = TRUE),   date = \"2019-08-15\",   subdataset = \"Cloud_Fraction_Day\",   suffix = \":mod06:\" ) rast_mod06l2 class       : SpatRaster size        : 640, 1280, 1  (nrow, ncol, nlyr) resolution  : 0.05, 0.05  (x, y) extent      : -127.9999, -63.99994, 20.00654, 52.00654  (xmin, xmax, ymin, ymax) coord. ref. : lon/lat WGS 84 (EPSG:4326) source(s)   : memory name        : Cloud_Fraction_Day min value   :                  0 max value   :                  1 terra::plot(rast_mod06l2$Cloud_Fraction_Day) sf_mod06l2 <- amadeus::calculate_covariates(   covariate = \"modis\",   from = list.files(dir_mod06l2, full.names = TRUE, recursive = TRUE),   locs = tigris::counties(\"CT\", year = 2019),   locs_id = \"NAME\",   radius = 0L,   preprocess = amadeus::process_modis_swath,   subdataset = \"Cloud_Fraction_Day\",   name_covariates = \"CLFRD_\",   fun_summary = \"median\",   geom = \"sf\",   scale = \"* 0.009999999776482582\" ) sf_mod06l2 Simple feature collection with 16 features and 3 fields Geometry type: MULTIPOLYGON Dimension:     XY Bounding box:  xmin: -73.72777 ymin: 40.95094 xmax: -71.78724 ymax: 42.05051 Geodetic CRS:  NAD83 First 10 features:          NAME  CLFRD_00000       time                       geometry 1   Fairfield 0.0002085408 2019-08-15 MULTIPOLYGON (((-73.54362 4... 2   Fairfield 0.0019240546 2019-08-16 MULTIPOLYGON (((-73.54362 4... 3    Hartford 0.0002000000 2019-08-15 MULTIPOLYGON (((-72.94902 4... 4    Hartford 0.0002125713 2019-08-16 MULTIPOLYGON (((-72.94902 4... 5  Litchfield 0.0002936930 2019-08-15 MULTIPOLYGON (((-73.50793 4... 6  Litchfield 0.0004076930 2019-08-16 MULTIPOLYGON (((-73.50793 4... 7   Middlesex 0.0002000000 2019-08-15 MULTIPOLYGON (((-72.65367 4... 8   Middlesex 0.0018688483 2019-08-16 MULTIPOLYGON (((-72.65367 4... 9   New Haven 0.0002000000 2019-08-15 MULTIPOLYGON (((-73.14755 4... 10  New Haven 0.0006629100 2019-08-16 MULTIPOLYGON (((-73.14755 4..."},{"path":"https://niehs.github.io/amadeus/articles/narr_workflow.html","id":"download","dir":"Articles","previous_headings":"","what":"Download","title":"NOAA North American Regional Reanalysis (NARR)","text":"Start downloading netCDF data files download_data. dataset_name = \"narr\": NARR dataset acronym. variable = \"air.2m\": air temperature 2m height variable code. year = c(2021, 2022): years interest. directory_to_save = dir: directory save downloaded files. acknowledgement = TRUE: acknowledge raw data files large may consume lots local storage. download = TRUE: download data files. remove_command = TRUE: remove temporary command file used download data. hash = TRUE: generate unique SHA-1 hash downloaded files. Check downloaded netCDF files.","code":"dir <- tempdir() amadeus::download_data(   dataset_name = \"narr\",   variable = \"air.2m\",   year = c(2021, 2022),   directory_to_save = dir,   acknowledgement = TRUE,   download = TRUE,   remove_command = TRUE,   hash = TRUE ) [1] \"3a382ac1c383c1d048f4044214cb450f\" list.files(dir, recursive = TRUE, pattern = \"air.2m\") [1] \"air.2m/air.2m.2021.nc\" \"air.2m/air.2m.2022.nc\""},{"path":"https://niehs.github.io/amadeus/articles/narr_workflow.html","id":"process","dir":"Articles","previous_headings":"","what":"Process","title":"NOAA North American Regional Reanalysis (NARR)","text":"Import process downloaded netCDF files process_covariates. covariate = \"narr\": NARR dataset acronym. variable = \"air.2m\": air temperature 2m height variable code. date = c(\"2021-12-28\", \"2022-01-03\"): date range interest. path = paste0(dir, \"/air.2m\"): directory containing downloaded files. Check processed SpatRaster object.","code":"air2m_process <- amadeus::process_covariates(   covariate = \"narr\",   variable = \"air.2m\",   date = c(\"2021-12-28\", \"2022-01-03\"),   path = file.path(dir, \"/air.2m\") ) air2m_process class       : SpatRaster dimensions  : 277, 349, 7  (nrow, ncol, nlyr) resolution  : 32462.99, 32463  (x, y) extent      : -16231.49, 11313351, -16231.5, 8976020  (xmin, xmax, ymin, ymax) coord. ref. : +proj=lcc +lat_0=50 +lon_0=-107 +lat_1=50 +lat_2=50 +x_0=5632642.22547 +y_0=4612545.65137 +datum=WGS84 +units=m +no_defs sources     : air.2m.2021.nc:air  (4 layers)               air.2m.2022.nc:air  (3 layers) varnames    : air (Daily Air Temperature at 2 m)               air (Daily Air Temperature at 2 m) names       : air.2~11228, air.2~11229, air.2~11230, air.2~11231, air.2~20101, air.2~20102, ... unit        :           K,           K,           K,           K,           K,           K, ... time        : 2021-12-28 to 2022-01-03 UTC terra::plot(air2m_process[[1]])"},{"path":"https://niehs.github.io/amadeus/articles/narr_workflow.html","id":"calculate-covariates","dir":"Articles","previous_headings":"","what":"Calculate covariates","title":"NOAA North American Regional Reanalysis (NARR)","text":"Calculate covariates North Carolina county boundaries calculate_covariates. County boundaries accessed tigris::counties function. covariate = \"narr\": NARR dataset acronym. = air2m_process: processed SpatRaster object. locs = tigris::counties(\"NC\", year = 2021): North Carolina county boundaries. locs_id = \"NAME\": county name identifier. radius = 0: size buffer radius around county. geom = \"terra\": return covariates SpatVector object. Check calculated covariates SpatVector object.","code":"library(tigris) air2m_covar <- amadeus::calculate_covariates(   covariate = \"narr\",   from = air2m_process,   locs = tigris::counties(\"NC\", year = 2021),   locs_id = \"NAME\",   radius = 0,   geom = \"terra\" ) air2m_covar class       : SpatVector geometry    : polygons dimensions  : 700, 3  (geometries, attributes) extent      : 7731783, 8506154, 3248490, 3694532  (xmin, xmax, ymin, ymax) coord. ref. : +proj=lcc +lat_0=50 +lon_0=-107 +lat_1=50 +lat_2=50 +x_0=5632642.22547 +y_0=4612545.65137 +datum=WGS84 +units=m +no_defs names       :     NAME       time air.2m_0 type        :    <chr>   <POSIXt>    <num> values      :  Chatham 2021-12-28    289.3               Alamance 2021-12-28    288.8               Davidson 2021-12-28    289.1"},{"path":"https://niehs.github.io/amadeus/articles/narr_workflow.html","id":"temporal-summaries","dir":"Articles","previous_headings":"","what":"Temporal summaries","title":"NOAA North American Regional Reanalysis (NARR)","text":"aggregate function can used calculate summary statistic unique spatial point polygon. following example, average air.2m_0 calculated county time period December 28, 2021 January 3, 2022. air.2m_0 ~ NAME directs function summarize air.2m_0 values per unique NAME. FUN = mean directs function take mean value. head() function applied show first entries, entire data.frame 100 rows long.","code":"head(aggregate(air.2m_0 ~ NAME, data = air2m_covar, FUN = mean)) NAME air.2m_0 1  Alamance 289.5930 2 Alexander 289.1961 3 Alleghany 286.9486 4     Anson 290.5306 5      Ashe 285.5771 6     Avery 285.2288"},{"path":"https://niehs.github.io/amadeus/articles/protected_datasets.html","id":"motivation","dir":"Articles","previous_headings":"","what":"Motivation","title":"Protected Data Sources","text":"vignette demonstrate create log NASA EarthData Account, generate prerequisite files R code.","code":""},{"path":"https://niehs.github.io/amadeus/articles/protected_datasets.html","id":"nasa-earthdata-account","dir":"Articles","previous_headings":"","what":"NASA EarthData Account","title":"Protected Data Sources","text":"Visit https://urs.earthdata.nasa.gov/ register log NASA EarthData account. Account registration provides access NASA‚Äôs Earth Observing System Data Information System (EOSDIS) twelve Distributed Active Archive Centers (DAAC), including: Alaska Satellite Facility (ASF) DAAC Atmospheric Science Data Center (ASDC) Crustal Dynamics Data Information System (CDDIS) Global Hydrometeorology Resource Center (GHRC) Goddard Earth Sciences Data Information Services Center (GES DISC) Land Processes DAAC (LP DAAC) Level 1 Atmosphere Archive Distribution System (LAADS) DAAC National Snow Ice Data Center (NSIDC) DAAC Oak Ridge National Laboratory (ORNL) DAAC Ocean Biology DAAC (OB.DAAC) Physical Oceanography DAAC (PO.DAAC) Socioeconomic Data Applications Center (SEDAC) See https://www.earthdata.nasa.gov/eosdis/daacs information.","code":""},{"path":"https://niehs.github.io/amadeus/articles/protected_datasets.html","id":"approved-applications","dir":"Articles","previous_headings":"NASA EarthData Account","what":"Approved applications","title":"Protected Data Sources","text":"creating account, navigate ‚ÄúProfile‚Äù(https://urs.earthdata.nasa.gov/profile), ‚ÄúApplications > Authorized Apps‚Äù. ‚ÄúAuthorized Apps‚Äù page specifies NASA EarthData applications can use login credentials. example, ensure authorization enabled ‚ÄúSEDAC Website‚Äù, ‚ÄúSEDAC Website (Alpha)‚Äù, ‚ÄúSEDAC Website (Beta)‚Äù.","code":""},{"path":"https://niehs.github.io/amadeus/articles/protected_datasets.html","id":"prerequisite-files","dir":"Articles","previous_headings":"","what":"Prerequisite files","title":"Protected Data Sources","text":"NASA EarthData Account required applications authorized use credentials, time create prerequisite files. following examples utilize UN WPP-Adjusted population density data NASA Socioeconomic Data Applications Center (SEDAC). generating prerequisite, try download population data download_data. error message indicates, downloaded file unzipped data file accessed properly. able download protected NASA data download_data, .netrc, .urs_cookies, .dodsrc must generated. Note following code adopted Generate Earthdata Prerequisite Files NASA GES DISC‚Äôs ‚Äú-‚Äôs‚Äù webpage. folowing steps assume Mac Linux operating system. Instructions generating prerequisite files Windows operating system R developed.","code":"download_data(   dataset_name = \"sedac_population\",   year = \"2020\",   data_format = \"GeoTIFF\",   data_resolution = \"60 minute\",   directory_to_save = \"./sedac_population\",   acknowledgement = TRUE,   download = TRUE,   unzip = TRUE,   remove_zip = FALSE,   remove_command = TRUE ) ## Downloading requested files... ## Requested files have been downloaded. ## Unzipping files... ##  ## Warning in unzip(file_name, exdir = directory_to_unzip): error 1 in extracting from zip file ##  ## Files unzipped and saved in ./sedac_population/."},{"path":"https://niehs.github.io/amadeus/articles/protected_datasets.html","id":"netrc","dir":"Articles","previous_headings":"Prerequisite files","what":".netrc","title":"Protected Data Sources","text":"following commands create .netrc file, contains NASA EarthData Account credentials. First, set working directory home directory. Create file named .netrc file.create. Open connection .netrc sink. Write line machine urs... replacing YOUR_USERNAME YOUR_PASSWORD NASA EarthData username password, respectively. writing line, close connection sink . Edit settings , owner file, can read write .netrc. , check ensure file created properly.","code":"setwd(\"~/\") file.create(\".netrc\") sink(\".netrc\") writeLines(   \"machine urs.earthdata.nasa.gov login YOUR_USERNAME password YOUR_PASSWORD\" ) sink() system(\"chmod 0600 .netrc\") file.exists(\".netrc\") ## [1] TRUE readLines(\".netrc\") ## [1] \"machine urs.earthdata.nasa.gov login YOUR_USERNAME password YOUR_PASSWORD\""},{"path":"https://niehs.github.io/amadeus/articles/protected_datasets.html","id":"urs_cookies","dir":"Articles","previous_headings":"Prerequisite files","what":".urs_cookies","title":"Protected Data Sources","text":"following commands create .urs_cookies file. First, set working directory home directory. Create file named .netrc file.create. , check ensure file created properly.","code":"setwd(\"~/\") file.create(\".urs_cookies\") file.exists(\".urs_cookies\") ## [1] TRUE"},{"path":"https://niehs.github.io/amadeus/articles/protected_datasets.html","id":"dodsrc","dir":"Articles","previous_headings":"Prerequisite files","what":".dodsrc","title":"Protected Data Sources","text":"following commands create .urs_cookies file. First, set working directory home directory. Create file named ‚Äú.dodsrc‚Äù file.create. Open connection .dodsrc sink. Write lines beginning HTTP., replacing YOUR_USERNAME YOUR_PASSWORD NASA EarthData username password, respectively. writing line, close connection sink . , check ensure file created properly. important ensure commands, well username, password, home directory, typed without error, single problem files result failed download. files created correctly, UN WPP-Adjusted population density data NASA Socioeconomic Data Applications Center (SEDAC) downloaded unzipped without returning error. Check downloaded data files. indicated files ./sedac_population, data files downloaded properly.","code":"setwd(\"~/\") file.create(\".dodsrc\") sink(\".dodsrc\") writeLines(   paste0(     \"HTTP.NETRC=YOUR_HOME_DIRECTORY/.netrc\\n\",     \"HTTP.COOKIE.JAR=YOUR_HOME_DIRECTORY/.urs_cookies\"   ) ) sink() file.exists(\".dodsrc\") ## [1] TRUE readLines(\".dodsrc\") ## [1] \"HTTP.NETRC=YOUR_HOME_DIRECTORY/.netrc\"            ## [2] \"HTTP.COOKIE.JAR=YOUR_HOME_DIRECTORY/.urs_cookies\" download_data(   dataset_name = \"sedac_population\",   year = \"2020\",   data_format = \"GeoTIFF\",   data_resolution = \"60 minute\",   directory_to_save = \"./sedac_population\",   acknowledgement = TRUE,   download = TRUE,   unzip = TRUE,   remove_zip = FALSE,   remove_command = TRUE ) ## Downloading requested files... ## Requested files have been downloaded. ## Unzipping files... ## Files unzipped and saved in ./sedac_population/. list.files(\"./sedac_population\") ## [1] \"gpw_v4_population_density_adjusted_to_2015_unwpp_country_totals_rev11_2020_1_deg_tif_readme.txt\" ## [2] \"gpw_v4_population_density_adjusted_to_2015_unwpp_country_totals_rev11_2020_1_deg_tif.zip\"        ## [3] \"gpw_v4_population_density_adjusted_to_2015_unwpp_country_totals_rev11_2020_1_deg.tif\""},{"path":"https://niehs.github.io/amadeus/articles/protected_datasets.html","id":"references","dir":"Articles","previous_headings":"","what":"References","title":"Protected Data Sources","text":"EOSDIS Distributed Active Archive Centers (DAAC). National Aeronautics Space Administration (NASA). Date accessed: January 3, 2024. https://www.earthdata.nasa.gov/eosdis/daacs. Generate Earthdata Prerequisite Files. National Aeronautics Space Administration (NASA). Date accessed: January 3, 2024. https://disc.gsfc.nasa.gov/information/howto?title=%20to%20Generate%20Earthdata%20Prerequisite%20Files.","code":""},{"path":"https://niehs.github.io/amadeus/articles/terraclimate_workflow.html","id":"download","dir":"Articles","previous_headings":"","what":"Download","title":"Climatology Lab TerraClimate","text":"Start downloading netCDF data files download_data. dataset_name = \"terraclimate\": TerraClimate dataset name. variable = \"Wind Speed\": wind speed variable name. year = c(2021, 2022): years interest. directory_to_save = dir: directory save downloaded files. acknowledgement = TRUE: acknowledge raw data files large may consume lots local storage. download = TRUE: download data files. remove_command = TRUE: remove temporary command file used download data. hash = TRUE: generate unique SHA-1 hash downloaded files. Check downloaded netCDF files.","code":"dir <- tempdir() amadeus::download_data(   dataset_name = \"terraclimate\",   variable = \"Wind Speed\",   year = c(2021, 2022),   directory_to_save = dir,   acknowledgement = TRUE,   download = TRUE,   remove_command = TRUE,   hash = TRUE ) [1] \"344cddba906371b701f661ccebeef3f427b2d8ec\" list.files(dir, recursive = TRUE, pattern = \"ws\") [1] \"ws/ws_2021.nc\" \"ws/ws_2022.nc\""},{"path":"https://niehs.github.io/amadeus/articles/terraclimate_workflow.html","id":"process","dir":"Articles","previous_headings":"","what":"Process","title":"Climatology Lab TerraClimate","text":"Import process downloaded netCDF files process_covariates. Parameters: covariate = \"terraclimate\": TerraClimate dataset name. variable = \"Wind Speed\": wind speed variable name. date = c(\"2021-12-28\", \"2022-01-03\"): date range interest. path = paste0(dir, \"/ws\"): directory containing downloaded files. Check processed SpatRaster object. Note Climatology Lab TerraClimate monthly dataset, SpatRaster contains two layers December 2021 January 2022.","code":"ws_process <- amadeus::process_covariates(   covariate = \"terraclimate\",   variable = \"Wind Speed\",   date = c(\"2021-12-28\", \"2022-01-03\"),   path = file.path(dir, \"/ws\") ) ws_process class       : SpatRaster  dimensions  : 4320, 8640, 2  (nrow, ncol, nlyr) resolution  : 0.04166667, 0.04166667  (x, y) extent      : -180, 180, -90, 90  (xmin, xmax, ymin, ymax) coord. ref. : +proj=longlat +ellps=WGS84 +no_defs  sources     : ws_2021.nc                 ws_2022.nc   varnames    : ws (wind speed)                ws (wind speed)  names       : ws_202112, ws_202201  unit        :       m/s,       m/s  time (days) : 2021-12-01 to 2022-01-01 terra::plot(ws_process[[1]])"},{"path":"https://niehs.github.io/amadeus/articles/terraclimate_workflow.html","id":"calculate-covariates","dir":"Articles","previous_headings":"","what":"Calculate covariates","title":"Climatology Lab TerraClimate","text":"Covariate calculation Climatology Lab TerraClimate data undergoing updates.","code":""},{"path":"https://niehs.github.io/amadeus/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Mitchell Manware. Author, contributor. Insang Song. Author, contributor. Eva Marques. Author, contributor. Mariana Alifa Kassien. Author, contributor. Elizabeth Scholl. Contributor. Kyle Messier. Author, maintainer. Spatiotemporal Exposures Toxicology Group. Copyright holder.","code":""},{"path":"https://niehs.github.io/amadeus/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Manware M, Song , Marques E, Alifa Kassien M, Messier K (2025). amadeus: Accessing Analyzing Large-Scale Environmental Data. R package version 1.2.4.9, https://niehs.github.io/amadeus/.","code":"@Manual{,   title = {amadeus: Accessing and Analyzing Large-Scale Environmental Data},   author = {Mitchell Manware and Insang Song and Eva Marques and Mariana {Alifa Kassien} and Kyle Messier},   year = {2025},   note = {R package version 1.2.4.9},   url = {https://niehs.github.io/amadeus/}, }"},{"path":"https://niehs.github.io/amadeus/index.html","id":"amadeus-","dir":"","previous_headings":"","what":"Accessing and Analyzing Large-Scale Environmental Data","title":"Accessing and Analyzing Large-Scale Environmental Data","text":"amadeus mechanism data, environments, user setup common environmental climate health datasets R. amadeus developed improve access utility large scale, publicly available environmental data R. See peer-reviewed publication, Amadeus: Accessing analyzing large scale environmental data R, full description details. Cite amadeus : > Manware, M., Song, ., Marques, E. S., Kassien, M. ., Clark, L. P., & Messier, K. P. (2025). Amadeus: Accessing analyzing large scale environmental data R. Environmental Modelling & Software, 186, 106352.","code":""},{"path":"https://niehs.github.io/amadeus/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Accessing and Analyzing Large-Scale Environmental Data","text":"amadeus can installed CRAN install.packages GitHub pak.","code":"install.packages(\"amadeus\") pak::pak(\"NIEHS/amadeus\")"},{"path":"https://niehs.github.io/amadeus/index.html","id":"download","dir":"","previous_headings":"","what":"Download","title":"Accessing and Analyzing Large-Scale Environmental Data","text":"download_data accesses downloads raw geospatial data variety open source data repositories. function wrapper calls source-specific download functions, account source‚Äôs unique combination URL, file naming conventions, data types. Download functions cover following sources: See ‚Äúdownload_data‚Äù vignette detailed description source-specific download functions. Example use download_data using NOAA NCEP North American Regional Reanalysis‚Äôs (NARR) ‚Äúweasd‚Äù (Daily Accumulated Snow Surface) variable.","code":"directory <- \"/  EXAMPLE  /  FILE  /  PATH  /\" download_data(   dataset_name = \"narr\",   year = 2022,   variable = \"weasd\",   directory_to_save = directory,   acknowledgement = TRUE,   download = TRUE,   hash = TRUE ) Downloading requested files... Requested files have been downloaded. [1] \"5655d4281b76f4d4d5bee234c2938f720cfec879\" list.files(file.path(directory, \"weasd\")) [1] \"weasd.2022.nc\""},{"path":"https://niehs.github.io/amadeus/index.html","id":"process","dir":"","previous_headings":"","what":"Process","title":"Accessing and Analyzing Large-Scale Environmental Data","text":"process_covariates imports cleans raw geospatial data (downloaded download_data), returns single SpatRaster SpatVector user‚Äôs R environment. process_covariates ‚Äúcleans‚Äù data defining interpretable layer names, ensuring coordinate reference system present, managing `timedata (applicable). avoid errors using process_covariates, edit raw downloaded data files. Passing user-generated edited data process_covariates may result errors underlying functions adapted sources‚Äô raw data file type. Example use process_covariates using downloaded ‚Äúweasd‚Äù data.","code":"weasd_process <- process_covariates(   covariate = \"narr\",   date = c(\"2022-01-01\", \"2022-01-05\"),   variable = \"weasd\",   path = file.path(directory, \"weasd\"),   extent = NULL ) Detected monolevel data... Cleaning weasd data for 2022... Returning daily weasd data from 2022-01-01 to 2022-01-05. weasd_process class       : SpatRaster dimensions  : 277, 349, 5  (nrow, ncol, nlyr) resolution  : 32462.99, 32463  (x, y) extent      : -16231.49, 11313351, -16231.5, 8976020  (xmin, xmax, ymin, ymax) coord. ref. : +proj=lcc +lat_0=50 +lon_0=-107 +lat_1=50 +lat_2=50 +x_0=5632642.22547 +y_0=4612545.65137 +datum=WGS84 +units=m +no_defs source      : weasd.2022.nc:weasd varname     : weasd (Daily Accumulated Snow at Surface) names       : weasd_20220101, weasd_20220102, weasd_20220103, weasd_20220104, weasd_20220105 unit        :         kg/m^2,         kg/m^2,         kg/m^2,         kg/m^2,         kg/m^2 time        : 2022-01-01 to 2022-01-05 UTC"},{"path":"https://niehs.github.io/amadeus/index.html","id":"calculate-covariates","dir":"","previous_headings":"","what":"Calculate Covariates","title":"Accessing and Analyzing Large-Scale Environmental Data","text":"calculate_covariates stems beethoven project‚Äôs need various types data extracted precise locations. calculate_covariates, therefore, extracts data ‚Äúcleaned‚Äù SpatRaster SpatVector object user defined locations. Users can choose buffer locations. function returns data.frame, sf, SpatVector data extracted locations layer row SpatRaster SpatVector object, respectively. Example calculate_covariates using processed ‚Äúweasd‚Äù data.","code":"locs <- data.frame(id = \"001\", lon = -78.8277, lat = 35.95013) weasd_covar <- calculate_covariates(   covariate = \"narr\",   from = weasd_process,   locs = locs,   locs_id = \"id\",   radius = 0,   geom = \"sf\" ) Detected `data.frame` extraction locations... Calculating weasd covariates for 2022-01-01... Calculating weasd covariates for 2022-01-02... Calculating weasd covariates for 2022-01-03... Calculating weasd covariates for 2022-01-04... Calculating weasd covariates for 2022-01-05... Returning extracted covariates. weasd_covar Simple feature collection with 5 features and 3 fields Geometry type: POINT Dimension:     XY Bounding box:  xmin: 8184606 ymin: 3523283 xmax: 8184606 ymax: 3523283 Projected CRS: unnamed    id       time     weasd_0                geometry 1 001 2022-01-01 0.000000000 POINT (8184606 3523283) 2 001 2022-01-02 0.000000000 POINT (8184606 3523283) 3 001 2022-01-03 0.000000000 POINT (8184606 3523283) 4 001 2022-01-04 0.000000000 POINT (8184606 3523283) 5 001 2022-01-05 0.001953125 POINT (8184606 3523283)"},{"path":"https://niehs.github.io/amadeus/index.html","id":"connecting-health-outcomes-research-data-systems","dir":"","previous_headings":"","what":"Connecting Health Outcomes Research Data Systems","title":"Accessing and Analyzing Large-Scale Environmental Data","text":"amadeus package developed part National Institute Environmental Health Science‚Äôs (NIEHS) Connecting Health Outcomes Research Data Systems (CHORDS) program. CHORDS aims ‚Äúbuild strengthen data infrastructure patient-centered outcomes research environment health‚Äù providing curated data, analysis tools, educational resources.","code":""},{"path":"https://niehs.github.io/amadeus/index.html","id":"additional-resources","dir":"","previous_headings":"","what":"Additional Resources","title":"Accessing and Analyzing Large-Scale Environmental Data","text":"following R packages can also used access climate weather data R, differs amadeus data sources covered type functionality provided.","code":""},{"path":"https://niehs.github.io/amadeus/index.html","id":"contribution","dir":"","previous_headings":"","what":"Contribution","title":"Accessing and Analyzing Large-Scale Environmental Data","text":"add edit functionality new data sources datasets, open Pull request main branch detailed description proposed changes. Pull requests must pass status checks, approved rejected amadeus‚Äôs authors. Utilize Issues notify authors bugs, questions, recommendations. Identify issue appropriate label help ensure timely response.","code":""},{"path":"https://niehs.github.io/amadeus/reference/apply_extent.html","id":null,"dir":"Reference","previous_headings":"","what":"Apply extent to the processed data ‚Äî apply_extent","title":"Apply extent to the processed data ‚Äî apply_extent","text":"User-defined extent used filter data.","code":""},{"path":"https://niehs.github.io/amadeus/reference/apply_extent.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Apply extent to the processed data ‚Äî apply_extent","text":"","code":"apply_extent(data, extent, geom)"},{"path":"https://niehs.github.io/amadeus/reference/apply_extent.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Apply extent to the processed data ‚Äî apply_extent","text":"data sf/terra object. extent numeric(4). Extent filter data. ordered c(xmin, xmax, ymin, ymax). geom character(1 2). Geometry type data data.frame. One \"geometry\" c(\"lon\", \"lat\").","code":""},{"path":"https://niehs.github.io/amadeus/reference/apply_extent.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Apply extent to the processed data ‚Äî apply_extent","text":"sf/terra object extent applied.","code":""},{"path":"https://niehs.github.io/amadeus/reference/as_mysftime.html","id":null,"dir":"Reference","previous_headings":"","what":"Create an sftime object ‚Äî as_mysftime","title":"Create an sftime object ‚Äî as_mysftime","text":"Create sftime object one data.frame, data.table, sf, sftime, SpatRaster, SpatRasterDataset, SpatVector","code":""},{"path":"https://niehs.github.io/amadeus/reference/as_mysftime.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create an sftime object ‚Äî as_mysftime","text":"","code":"as_mysftime(x, ...)"},{"path":"https://niehs.github.io/amadeus/reference/as_mysftime.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create an sftime object ‚Äî as_mysftime","text":"x object class data.frame, data.table, sf, sftime, SpatRaster, SpatRasterDataset SpatVector ... x data.frame data.table: lonname, latname, timename crs arguments required. x sf sftime, timename argument required. x terra::SpatRaster, varname argument required.","code":""},{"path":"https://niehs.github.io/amadeus/reference/as_mysftime.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create an sftime object ‚Äî as_mysftime","text":"sftime object constrained time column name","code":""},{"path":[]},{"path":"https://niehs.github.io/amadeus/reference/as_mysftime.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Create an sftime object ‚Äî as_mysftime","text":"Eva Marques","code":""},{"path":"https://niehs.github.io/amadeus/reference/calc_check_time.html","id":null,"dir":"Reference","previous_headings":"","what":"Check time values ‚Äî calc_check_time","title":"Check time values ‚Äî calc_check_time","text":"Check time values within calculated covariates data.frame","code":""},{"path":"https://niehs.github.io/amadeus/reference/calc_check_time.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check time values ‚Äî calc_check_time","text":"","code":"calc_check_time(covar, POSIXt = TRUE)"},{"path":"https://niehs.github.io/amadeus/reference/calc_check_time.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check time values ‚Äî calc_check_time","text":"covar data.frame(1). Calculated covariates data.frame. POSIXt logical(1). time values covar class POSIXt? FALSE, time values checked integer class (year year-month).","code":""},{"path":"https://niehs.github.io/amadeus/reference/calc_check_time.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check time values ‚Äî calc_check_time","text":"NULL; returns stop error time wrong class","code":""},{"path":"https://niehs.github.io/amadeus/reference/calc_message.html","id":null,"dir":"Reference","previous_headings":"","what":"Send progress messages ‚Äî calc_message","title":"Send progress messages ‚Äî calc_message","text":"Send messages updating covariate extraction progress.","code":""},{"path":"https://niehs.github.io/amadeus/reference/calc_message.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Send progress messages ‚Äî calc_message","text":"","code":"calc_message(dataset, variable, time, time_type, level)"},{"path":"https://niehs.github.io/amadeus/reference/calc_message.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Send progress messages ‚Äî calc_message","text":"dataset character(1). Data source. variable placeholder time placeholder time_type placeholder level placeholder","code":""},{"path":"https://niehs.github.io/amadeus/reference/calc_message.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Send progress messages ‚Äî calc_message","text":"NULL; provides progress messages R console.","code":""},{"path":"https://niehs.github.io/amadeus/reference/calc_prepare_locs.html","id":null,"dir":"Reference","previous_headings":"","what":"Prepare extraction locations ‚Äî calc_prepare_locs","title":"Prepare extraction locations ‚Äî calc_prepare_locs","text":"Prepare point locations extracting data transforming locs SpatVector, projecting coordinate reference system , creating data.frame containing locs_id retaining extracted values.","code":""},{"path":"https://niehs.github.io/amadeus/reference/calc_prepare_locs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Prepare extraction locations ‚Äî calc_prepare_locs","text":"","code":"calc_prepare_locs(from, locs, locs_id, radius, geom = FALSE)"},{"path":"https://niehs.github.io/amadeus/reference/calc_prepare_locs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Prepare extraction locations ‚Äî calc_prepare_locs","text":"SpatRaster(1) SpatVector(1). Output process_\\*(). Passed calc_\\*(). locs data.frame. character file path, SpatVector, sf object. Passed calc_\\*(). locs_id character(1). Column within locations CSV file containing identifier unique coordinate location. Passed calc_\\*(). radius integer(1). Circular buffer distance around site locations. (Default = 0). Passed calc_\\*(). geom logical(1). geometry locs returned data.frame? Default FALSE, options \"sf\" \"terra\" preserve geometry, use terra extraction.","code":""},{"path":"https://niehs.github.io/amadeus/reference/calc_prepare_locs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Prepare extraction locations ‚Äî calc_prepare_locs","text":"list containing SpatVector data.frame objects","code":""},{"path":[]},{"path":"https://niehs.github.io/amadeus/reference/calc_return_locs.html","id":null,"dir":"Reference","previous_headings":"","what":"Prepare covariates for return ‚Äî calc_return_locs","title":"Prepare covariates for return ‚Äî calc_return_locs","text":"Check time column proper class , geom = TRUE, transform data.frame SpatVector object.","code":""},{"path":"https://niehs.github.io/amadeus/reference/calc_return_locs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Prepare covariates for return ‚Äî calc_return_locs","text":"","code":"calc_return_locs(covar, POSIXt = TRUE, geom, crs)"},{"path":"https://niehs.github.io/amadeus/reference/calc_return_locs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Prepare covariates for return ‚Äî calc_return_locs","text":"covar data.frame(1). Calculated covariates data.frame. POSIXt logical(1). time values covar class POSIXt? FALSE, time values checked integer class (year year-month). geom FALSE/\"sf\"/\"terra\". covar returned data.frame? Default FALSE, options geometry \"sf\" \"terra\". crs terra::crs(1). Coordinate reference system (inherited ).","code":""},{"path":"https://niehs.github.io/amadeus/reference/calc_return_locs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Prepare covariates for return ‚Äî calc_return_locs","text":"data.frame SpatVector object (depending geom paramter)","code":""},{"path":"https://niehs.github.io/amadeus/reference/calc_return_locs.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Prepare covariates for return ‚Äî calc_return_locs","text":"Mitchell Manware","code":""},{"path":"https://niehs.github.io/amadeus/reference/calc_setcolumns.html","id":null,"dir":"Reference","previous_headings":"","what":"Set column names ‚Äî calc_setcolumns","title":"Set column names ‚Äî calc_setcolumns","text":"Apply standard column names calculated covariates consistent requirements beethoven package. Column names follow fixed format 3 character data genre, 2 - 15 character variable code, 1 digit temporal lag, 5 digit buffer radius (meters). Variable code character range required retain interpretable column names across datasets.","code":""},{"path":"https://niehs.github.io/amadeus/reference/calc_setcolumns.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Set column names ‚Äî calc_setcolumns","text":"","code":"calc_setcolumns(from, lag, dataset, locs_id)"},{"path":"https://niehs.github.io/amadeus/reference/calc_setcolumns.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Set column names ‚Äî calc_setcolumns","text":"data.frame(1) SpatVector(1). Calculated covariates returned calc_covariates() source specific covariate function. lag integer(1). Temporal lag. dataset character(1). Covariate parent dataset. locs_id character(1). Column containing identifier unique coordinate location.","code":""},{"path":"https://niehs.github.io/amadeus/reference/calc_setcolumns.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Set column names ‚Äî calc_setcolumns","text":"data.frame SpatVector object (depending )","code":""},{"path":"https://niehs.github.io/amadeus/reference/calc_setcolumns.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Set column names ‚Äî calc_setcolumns","text":"beethoven utilizes point, 1km, 10km radius buffer distance covariate calculation, therefore buffer radius column padded 5 digits. provided buffer radius greater 5 digits, calc_setcolumns() expand number digits. (ie. buffer radius 100km = CCC_CCCCC_I_100000).","code":""},{"path":"https://niehs.github.io/amadeus/reference/calc_time.html","id":null,"dir":"Reference","previous_headings":"","what":"Prepare time values ‚Äî calc_time","title":"Prepare time values ‚Äî calc_time","text":"Prepare time values covariate calculation based type time value.","code":""},{"path":"https://niehs.github.io/amadeus/reference/calc_time.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Prepare time values ‚Äî calc_time","text":"","code":"calc_time(time, format)"},{"path":"https://niehs.github.io/amadeus/reference/calc_time.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Prepare time values ‚Äî calc_time","text":"time Time value format Type time return $time column. Can \"timeless\" (ie. Ecoregions data), \"date\" (ie. NARR data), \"hour\" (ie. GEOS data), \"year\" (ie. SEDAC population data), \"yearmonth\" (ie. TerraClimate data).","code":""},{"path":"https://niehs.github.io/amadeus/reference/calc_time.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Prepare time values ‚Äî calc_time","text":"Date, POSIXt, integer object based format =","code":""},{"path":"https://niehs.github.io/amadeus/reference/calc_worker.html","id":null,"dir":"Reference","previous_headings":"","what":"Perform covariate extraction ‚Äî calc_worker","title":"Perform covariate extraction ‚Äî calc_worker","text":"Extract covariate values SpatRaster object passed process_*().","code":""},{"path":"https://niehs.github.io/amadeus/reference/calc_worker.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Perform covariate extraction ‚Äî calc_worker","text":"","code":"calc_worker(   dataset,   from,   locs_vector,   locs_df,   fun,   variable = 1,   time,   time_type = c(\"date\", \"hour\", \"year\", \"yearmonth\", \"timeless\"),   radius,   level = NULL,   max_cells = 1e+08,   ... )"},{"path":"https://niehs.github.io/amadeus/reference/calc_worker.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Perform covariate extraction ‚Äî calc_worker","text":"dataset character(1). Dataset name. SpatRaster(1). Cleaned SpatRaster object. locs_vector SpatVector(1). Cleaned SpatVector object passed calc_prepare_locs(). Contains location point/polygon values. locs_df data.frame(1). Cleaned data.frame object passed calc_prepare_locs(). Contains location identifiers. fun character(1). Summary function. Passed terra::extract(). variable integer. Position within layer name containing variable name/code. time integer. Position within layer name containing time value(s). time_type character(1). Type time observation. One \"date\", \"hour\", \"year\", \"yearmonth\", \"timeless\". radius integer(1). Buffer distance (m). Passed calc_prepare_locs(). Used column naming. level integer. Position within layer name containing vertical pressure level value (applicable). Default = NULL. max_cells integer(1). Maximum number cells read . Higher values expedite processing, increase memory usage. Maximum possible value 2^31 - 1. See exactextractr::exact_extract details. ... Placeholders.","code":""},{"path":"https://niehs.github.io/amadeus/reference/calc_worker.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Perform covariate extraction ‚Äî calc_worker","text":"data.frame object","code":""},{"path":"https://niehs.github.io/amadeus/reference/calculate_covariates.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate covariates wrapper function ‚Äî calculate_covariates","title":"Calculate covariates wrapper function ‚Äî calculate_covariates","text":"calculate_covariates() function extracts values point locations SpatRaster SpatVector object returned process_covariates(). calculate_covariates() underlying source-specific covariate functions designed operate processed objects. avoid errors, edit processed SpatRaster SpatVector objects passing calculate_covariates().","code":""},{"path":"https://niehs.github.io/amadeus/reference/calculate_covariates.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate covariates wrapper function ‚Äî calculate_covariates","text":"","code":"calculate_covariates(   covariate = c(\"modis\", \"koppen-geiger\", \"koeppen-geiger\", \"koppen\", \"koeppen\", \"geos\",     \"dummies\", \"gmted\", \"sedac_groads\", \"groads\", \"roads\", \"ecoregions\", \"ecoregion\",     \"hms\", \"smoke\", \"gmted\", \"narr\", \"geos\", \"sedac_population\", \"population\", \"nlcd\",     \"merra\", \"merra2\", \"gridmet\", \"terraclimate\", \"tri\", \"nei\"),   from,   locs,   locs_id = \"site_id\",   ... )"},{"path":"https://niehs.github.io/amadeus/reference/calculate_covariates.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate covariates wrapper function ‚Äî calculate_covariates","text":"covariate character(1). Covariate type. character. Single multiple strings. locs sf/SpatVector. Unique locations. include unique identifier field named locs_id locs_id character(1). Name unique identifier. Default \"site_id\". ... Arguments passed covariate calculation function.","code":""},{"path":"https://niehs.github.io/amadeus/reference/calculate_covariates.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate covariates wrapper function ‚Äî calculate_covariates","text":"Calculated covariates data.frame SpatVector object","code":""},{"path":"https://niehs.github.io/amadeus/reference/calculate_covariates.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Calculate covariates wrapper function ‚Äî calculate_covariates","text":"covariate argument value converted lowercase.","code":""},{"path":[]},{"path":"https://niehs.github.io/amadeus/reference/calculate_covariates.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Calculate covariates wrapper function ‚Äî calculate_covariates","text":"Insang Song","code":""},{"path":"https://niehs.github.io/amadeus/reference/calculate_covariates.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate covariates wrapper function ‚Äî calculate_covariates","text":"","code":"## NOTE: Example is wrapped in `\\dontrun{}` as function requires a large ##       amount of data which is not included in the package. if (FALSE) { # \\dontrun{ loc <- data.frame(id = \"001\", lon = -78.90, lat = 35.97) calculate_covariates(   covariate = \"narr\",   from = narr, # derived from process_covariates() example   locs = loc,   locs_id = \"id\",   geom = FALSE ) } # }"},{"path":"https://niehs.github.io/amadeus/reference/calculate_ecoregion.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate ecoregions covariates ‚Äî calculate_ecoregion","title":"Calculate ecoregions covariates ‚Äî calculate_ecoregion","text":"Extract ecoregions covariates (U.S. EPA Ecoregions Level 2/3) point locations. Returns data.frame object containing locs_id binary (0 = point ecoregion; 1 = point ecoregion) variables ecoregion.","code":""},{"path":"https://niehs.github.io/amadeus/reference/calculate_ecoregion.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate ecoregions covariates ‚Äî calculate_ecoregion","text":"","code":"calculate_ecoregion(from = NULL, locs, locs_id = \"site_id\", geom = FALSE, ...)"},{"path":"https://niehs.github.io/amadeus/reference/calculate_ecoregion.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate ecoregions covariates ‚Äî calculate_ecoregion","text":"SpatVector(1). Output process_ecoregion. locs sf/SpatVector. Unique locs. include unique identifier field named locs_id locs_id character(1). Name unique identifier. geom FALSE/\"sf\"/\"terra\".. function return geometry? Default FALSE, options geometry \"sf\" \"terra\". coordinate reference system sf SpatVector . ... Placeholders.","code":""},{"path":"https://niehs.github.io/amadeus/reference/calculate_ecoregion.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate ecoregions covariates ‚Äî calculate_ecoregion","text":"data.frame SpatVector object object dummy variables attributes : attr(., \"ecoregion2_code\"): Ecoregion lv.2 code key attr(., \"ecoregion3_code\"): Ecoregion lv.3 code key","code":""},{"path":[]},{"path":"https://niehs.github.io/amadeus/reference/calculate_ecoregion.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Calculate ecoregions covariates ‚Äî calculate_ecoregion","text":"Insang Song","code":""},{"path":"https://niehs.github.io/amadeus/reference/calculate_ecoregion.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate ecoregions covariates ‚Äî calculate_ecoregion","text":"","code":"## NOTE: Example is wrapped in `\\dontrun{}` as function requires a large ##       amount of data which is not included in the package. if (FALSE) { # \\dontrun{ loc <- data.frame(id = \"001\", lon = -78.90, lat = 35.97) calculate_ecoregion(   from = ecoregion, # derived from process_ecoregion() example   locs = loc,   locs_id = \"id\",   geom = FALSE ) } # }"},{"path":"https://niehs.github.io/amadeus/reference/calculate_geos.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate atmospheric composition covariates ‚Äî calculate_geos","title":"Calculate atmospheric composition covariates ‚Äî calculate_geos","text":"Extract atmospheric composition values point locations. Returns data.frame object containing locs_id, date hour, vertical pressure level, atmospheric composition variable. Atmospheric composition variable column name reflects variable circular buffer radius.","code":""},{"path":"https://niehs.github.io/amadeus/reference/calculate_geos.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate atmospheric composition covariates ‚Äî calculate_geos","text":"","code":"calculate_geos(   from,   locs,   locs_id = NULL,   radius = 0,   fun = \"mean\",   geom = FALSE,   ... )"},{"path":"https://niehs.github.io/amadeus/reference/calculate_geos.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate atmospheric composition covariates ‚Äî calculate_geos","text":"SpatRaster(1). Output process_geos(). locs data.frame, characater file path, SpatVector, sf object. locs_id character(1). Column within locations CSV file containing identifier unique coordinate location. radius integer(1). Circular buffer distance around site locations. (Default = 0). fun character(1). Function used summarize multiple raster cells within sites location buffer (Default = mean). geom FALSE/\"sf\"/\"terra\".. function return geometry? Default FALSE, options geometry \"sf\" \"terra\". coordinate reference system sf SpatVector . ... Placeholders.","code":""},{"path":"https://niehs.github.io/amadeus/reference/calculate_geos.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate atmospheric composition covariates ‚Äî calculate_geos","text":"data.frame SpatVector object","code":""},{"path":[]},{"path":"https://niehs.github.io/amadeus/reference/calculate_geos.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Calculate atmospheric composition covariates ‚Äî calculate_geos","text":"Mitchell Manware","code":""},{"path":"https://niehs.github.io/amadeus/reference/calculate_geos.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate atmospheric composition covariates ‚Äî calculate_geos","text":"","code":"## NOTE: Example is wrapped in `\\dontrun{}` as function requires a large ##       amount of data which is not included in the package. if (FALSE) { # \\dontrun{ loc <- data.frame(id = \"001\", lon = -78.90, lat = 35.97) calculate_geos(   from = geos, # derived from process_geos() example   locs = loc,   locs_id = \"id\",   radius = 0,   fun = \"mean\",   geom = FALSE ) } # }"},{"path":"https://niehs.github.io/amadeus/reference/calculate_gmted.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate elevation covariates ‚Äî calculate_gmted","title":"Calculate elevation covariates ‚Äî calculate_gmted","text":"Extract elevation values point locations. Returns data.frame object containing locs_id, year release, elevation variable. Elevation variable column name reflects elevation statistic, spatial resolution , circular buffer radius (ie. Breakline Emphasis 7.5 arc-second resolution 0 meter buffer: breakline_emphasis_r75_0).","code":""},{"path":"https://niehs.github.io/amadeus/reference/calculate_gmted.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate elevation covariates ‚Äî calculate_gmted","text":"","code":"calculate_gmted(   from,   locs,   locs_id = NULL,   radius = 0,   fun = \"mean\",   geom = FALSE,   ... )"},{"path":"https://niehs.github.io/amadeus/reference/calculate_gmted.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate elevation covariates ‚Äî calculate_gmted","text":"SpatRaster(1). Output process_gmted(). locs data.frame. character file path, SpatVector, sf object. locs_id character(1). Column within locations CSV file containing identifier unique coordinate location. radius integer(1). Circular buffer distance around site locations. (Default = 0). fun character(1). Function used summarize multiple raster cells within sites location buffer (Default = mean). geom FALSE/\"sf\"/\"terra\".. function return geometry? Default FALSE, options geometry \"sf\" \"terra\". coordinate reference system sf SpatVector . ... Placeholders","code":""},{"path":"https://niehs.github.io/amadeus/reference/calculate_gmted.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate elevation covariates ‚Äî calculate_gmted","text":"data.frame SpatVector object","code":""},{"path":[]},{"path":"https://niehs.github.io/amadeus/reference/calculate_gmted.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Calculate elevation covariates ‚Äî calculate_gmted","text":"Mitchell Manware","code":""},{"path":"https://niehs.github.io/amadeus/reference/calculate_gmted.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate elevation covariates ‚Äî calculate_gmted","text":"","code":"## NOTE: Example is wrapped in `\\dontrun{}` as function requires a large ##       amount of data which is not included in the package. if (FALSE) { # \\dontrun{ loc <- data.frame(id = \"001\", lon = -78.90, lat = 35.97) calculate_gmted(   from = gmted, # derived from process_gmted() example   locs = loc,   locs_id = \"id\",   radius = 0,   fun = \"mean\",   geom = FALSE ) } # }"},{"path":"https://niehs.github.io/amadeus/reference/calculate_gridmet.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate gridMET covariates ‚Äî calculate_gridmet","title":"Calculate gridMET covariates ‚Äî calculate_gridmet","text":"Extract gridMET values point locations. Returns data.frame object containing locs_id gridMET variable. gridMET variable column name reflects gridMET variable circular buffer radius.","code":""},{"path":"https://niehs.github.io/amadeus/reference/calculate_gridmet.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate gridMET covariates ‚Äî calculate_gridmet","text":"","code":"calculate_gridmet(   from,   locs,   locs_id = NULL,   radius = 0,   fun = \"mean\",   geom = FALSE,   ... )"},{"path":"https://niehs.github.io/amadeus/reference/calculate_gridmet.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate gridMET covariates ‚Äî calculate_gridmet","text":"SpatRaster(1). Output process_gridmet(). locs data.frame. character file path, SpatVector, sf object. locs_id character(1). Column within locations CSV file containing identifier unique coordinate location. radius integer(1). Circular buffer distance around site locations. (Default = 0). fun character(1). Function used summarize multiple raster cells within sites location buffer (Default = mean). geom FALSE/\"sf\"/\"terra\".. function return geometry? Default FALSE, options geometry \"sf\" \"terra\". coordinate reference system sf SpatVector . ... Placeholders.","code":""},{"path":"https://niehs.github.io/amadeus/reference/calculate_gridmet.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate gridMET covariates ‚Äî calculate_gridmet","text":"data.frame SpatVector object","code":""},{"path":[]},{"path":"https://niehs.github.io/amadeus/reference/calculate_gridmet.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Calculate gridMET covariates ‚Äî calculate_gridmet","text":"Mitchell Manware","code":""},{"path":"https://niehs.github.io/amadeus/reference/calculate_gridmet.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate gridMET covariates ‚Äî calculate_gridmet","text":"","code":"## NOTE: Example is wrapped in `\\dontrun{}` as function requires a large ##       amount of data which is not included in the package. if (FALSE) { # \\dontrun{ loc <- data.frame(id = \"001\", lon = -78.90, lat = 35.97) calculate_gridmet(   from = gridmet, # derived from process_gridmet() example   locs = loc,   locs_id = \"id\",   radius = 0,   fun = \"mean\",   geom = FALSE ) } # }"},{"path":"https://niehs.github.io/amadeus/reference/calculate_groads.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate roads covariates ‚Äî calculate_groads","title":"Calculate roads covariates ‚Äî calculate_groads","text":"Prepared groads data clipped buffer polygons radius. total length roads calculated. density roads calculated dividing total length area buffer. terra::linearUnits() used convert unit length meters.","code":""},{"path":"https://niehs.github.io/amadeus/reference/calculate_groads.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate roads covariates ‚Äî calculate_groads","text":"","code":"calculate_groads(   from = NULL,   locs = NULL,   locs_id = NULL,   radius = 1000,   fun = \"sum\",   geom = FALSE,   ... )"},{"path":"https://niehs.github.io/amadeus/reference/calculate_groads.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate roads covariates ‚Äî calculate_groads","text":"SpatVector(1). Output process_groads. locs data.frame, characater file path, SpatVector, sf object. locs_id character(1). Column within locations CSV file containing identifier unique coordinate location. radius integer(1). Circular buffer distance around site locations. (Default = 1000). fun function(1). Function used summarize length roads within sites location buffer (Default sum). geom FALSE/\"sf\"/\"terra\".. function return geometry? Default FALSE, options geometry \"sf\" \"terra\". coordinate reference system sf SpatVector . ... Placeholders.","code":""},{"path":"https://niehs.github.io/amadeus/reference/calculate_groads.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate roads covariates ‚Äî calculate_groads","text":"data.frame SpatVector object","code":""},{"path":"https://niehs.github.io/amadeus/reference/calculate_groads.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Calculate roads covariates ‚Äî calculate_groads","text":"Unit km / sq km. returned data.frame object contains $time column represent temporal range covered dataset. information, see https://data.nasa.gov/dataset/global-roads-open-access-data-set-version-1-groadsv1.","code":""},{"path":[]},{"path":"https://niehs.github.io/amadeus/reference/calculate_groads.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Calculate roads covariates ‚Äî calculate_groads","text":"Insang Song","code":""},{"path":"https://niehs.github.io/amadeus/reference/calculate_groads.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate roads covariates ‚Äî calculate_groads","text":"","code":"## NOTE: Example is wrapped in `\\dontrun{}` as function requires a large ##       amount of data which is not included in the package. if (FALSE) { # \\dontrun{ loc <- data.frame(id = \"001\", lon = -78.90, lat = 35.97) calculate_groads(   from = groads, # derived from process_groads() example   locs = loc,   locs_id = \"id\",   radius = 1000,   fun = \"sum\",   geom = FALSE ) } # }"},{"path":"https://niehs.github.io/amadeus/reference/calculate_hms.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate wildfire smoke covariates ‚Äî calculate_hms","title":"Calculate wildfire smoke covariates ‚Äî calculate_hms","text":"Extract wildfire smoke plume values point locations. Returns data.frame object containing locs_id, date, binary variable wildfire smoke plume density inherited (0 = point covered wildfire smoke plume; 1 = point covered wildfire smoke plume).","code":""},{"path":"https://niehs.github.io/amadeus/reference/calculate_hms.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate wildfire smoke covariates ‚Äî calculate_hms","text":"","code":"calculate_hms(from, locs, locs_id = NULL, radius = 0, geom = FALSE, ...)"},{"path":"https://niehs.github.io/amadeus/reference/calculate_hms.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate wildfire smoke covariates ‚Äî calculate_hms","text":"SpatVector(1). Output process_hms(). locs data.frame, characater file path, SpatVector, sf object. locs_id character(1). Column within locations CSV file containing identifier unique coordinate location. radius integer(1). Circular buffer distance around site locations. (Default = 0). geom FALSE/\"sf\"/\"terra\".. function return geometry? Default FALSE, options geometry \"sf\" \"terra\". coordinate reference system sf SpatVector . ... Placeholders.","code":""},{"path":"https://niehs.github.io/amadeus/reference/calculate_hms.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate wildfire smoke covariates ‚Äî calculate_hms","text":"data.frame SpatVector object","code":""},{"path":[]},{"path":"https://niehs.github.io/amadeus/reference/calculate_hms.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Calculate wildfire smoke covariates ‚Äî calculate_hms","text":"Mitchell Manware","code":""},{"path":"https://niehs.github.io/amadeus/reference/calculate_hms.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate wildfire smoke covariates ‚Äî calculate_hms","text":"","code":"## NOTE: Example is wrapped in `\\dontrun{}` as function requires a large ##       amount of data which is not included in the package. if (FALSE) { # \\dontrun{ loc <- data.frame(id = \"001\", lon = -78.90, lat = 35.97) calculate_hms(   from = hms, # derived from process_hms() example   locs = loc,   locs_id = \"id\",   radius = 0,   geom = FALSE ) } # }"},{"path":"https://niehs.github.io/amadeus/reference/calculate_koppen_geiger.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate climate classification covariates ‚Äî calculate_koppen_geiger","title":"Calculate climate classification covariates ‚Äî calculate_koppen_geiger","text":"Extract climate classification values point locations. Returns data.frame object containing locs_id binary (0 = point climate region; 1 = point climate region) variables climate classification region.","code":""},{"path":"https://niehs.github.io/amadeus/reference/calculate_koppen_geiger.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate climate classification covariates ‚Äî calculate_koppen_geiger","text":"","code":"calculate_koppen_geiger(   from = NULL,   locs = NULL,   locs_id = \"site_id\",   geom = FALSE,   ... )"},{"path":"https://niehs.github.io/amadeus/reference/calculate_koppen_geiger.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate climate classification covariates ‚Äî calculate_koppen_geiger","text":"SpatVector(1). Output process_koppen_geiger(). locs sf/SpatVector. Unique locs. include unique identifier field named locs_id locs_id character(1). Name unique identifier. geom FALSE/\"sf\"/\"terra\".. function return geometry? Default FALSE, options geometry \"sf\" \"terra\". coordinate reference system sf SpatVector . ... Placeholders.","code":""},{"path":"https://niehs.github.io/amadeus/reference/calculate_koppen_geiger.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate climate classification covariates ‚Äî calculate_koppen_geiger","text":"data.frame SpatVector object","code":""},{"path":"https://niehs.github.io/amadeus/reference/calculate_koppen_geiger.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Calculate climate classification covariates ‚Äî calculate_koppen_geiger","text":"returned object contains $description column represent temporal range covered dataset. information, see https://www.nature.com/articles/sdata2018214.","code":""},{"path":[]},{"path":"https://niehs.github.io/amadeus/reference/calculate_koppen_geiger.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Calculate climate classification covariates ‚Äî calculate_koppen_geiger","text":"Insang Song","code":""},{"path":"https://niehs.github.io/amadeus/reference/calculate_koppen_geiger.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate climate classification covariates ‚Äî calculate_koppen_geiger","text":"","code":"## NOTE: Example is wrapped in `\\dontrun{}` as function requires a large ##       amount of data which is not included in the package. if (FALSE) { # \\dontrun{ loc <- data.frame(id = \"001\", lon = -78.90, lat = 35.97) calculate_koppen_geiger(   from = kg, # derived from process_koppen_geiger() example   locs = loc,   locs_id = \"id\",   geom = FALSE ) } # }"},{"path":"https://niehs.github.io/amadeus/reference/calculate_lagged.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate temporally lagged covariates ‚Äî calculate_lagged","title":"Calculate temporally lagged covariates ‚Äî calculate_lagged","text":"calculate_lagged() function calculates daily temporal lagged covariates output calculate_covariates() calc_*().","code":""},{"path":"https://niehs.github.io/amadeus/reference/calculate_lagged.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate temporally lagged covariates ‚Äî calculate_lagged","text":"","code":"calculate_lagged(from, date, lag, locs_id, time_id = \"time\", geom = FALSE)"},{"path":"https://niehs.github.io/amadeus/reference/calculate_lagged.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate temporally lagged covariates ‚Äî calculate_lagged","text":"data.frame(1). data.frame containing calculated covariates returned calculate_covariates() calc_*(). date character(2). Start end dates desired lagged covariates. Length 10 , format YYYY-MM-DD (ex. September 1, 2023 = \"2023-09-01\"). lag integer(1). Number lag days. locs_id character(1). Name unique identifier. time_id character(1). Column containing time values. geom logical(1). function return SpatVector? Default FALSE. coordinate reference system SpatVector . return SpatVector, must also SpatVector","code":""},{"path":"https://niehs.github.io/amadeus/reference/calculate_lagged.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate temporally lagged covariates ‚Äî calculate_lagged","text":"data.frame object","code":""},{"path":"https://niehs.github.io/amadeus/reference/calculate_lagged.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Calculate temporally lagged covariates ‚Äî calculate_lagged","text":"order calculate temporally lagged covariates, must contain least number lag days desired start date. example, date = c(\"2024-01-01\", \"2024-01-31) lag = 1, must contain data starting 2023-12-31. contains geometry features, calculate_lagged return column geometry features name. calculate_lagged() assumes columns time_id, locs_id, fixed columns \"lat\" \"lon\", follow genre, variable, lag, buffer radius format adopted calc_setcolumns().","code":""},{"path":[]},{"path":"https://niehs.github.io/amadeus/reference/calculate_lagged.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate temporally lagged covariates ‚Äî calculate_lagged","text":"","code":"## NOTE: Example is wrapped in `\\dontrun{}` as function requires a large ##       amount of data which is not included in the package. if (FALSE) { # \\dontrun{ loc <- data.frame(id = \"001\", lon = -78.90, lat = 35.97) terracliamte_covar <- calculate_terraclimate(   from = terraclimate, # derived from process_terraclimate() example   locs = loc,   locs_id = \"id\",   radius = 0,   fun = \"mean\",   geom = FALSE ) calculate_lagged(   from = terracliamte_covar,   locs_id = \"id\",   date = c(\"2023-01-02\", \"2023-01-10\"),   lag = 1,   time_id = \"time\" ) } # }"},{"path":"https://niehs.github.io/amadeus/reference/calculate_merra2.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate meteorological and atmospheric covariates ‚Äî calculate_merra2","title":"Calculate meteorological and atmospheric covariates ‚Äî calculate_merra2","text":"Extract meteorological atmospheric values point locations. Returns data.frame object containing locs_id, date hour, vertical pressure level, meteorological atmospheric variable. Variable column name reflects variable circular buffer radius.","code":""},{"path":"https://niehs.github.io/amadeus/reference/calculate_merra2.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate meteorological and atmospheric covariates ‚Äî calculate_merra2","text":"","code":"calculate_merra2(   from,   locs,   locs_id = NULL,   radius = 0,   fun = \"mean\",   geom = FALSE,   ... )"},{"path":"https://niehs.github.io/amadeus/reference/calculate_merra2.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate meteorological and atmospheric covariates ‚Äî calculate_merra2","text":"SpatRaster(1). Output process_merra2(). locs data.frame, characater file path, SpatVector, sf object. locs_id character(1). Column within locations CSV file containing identifier unique coordinate location. radius integer(1). Circular buffer distance around site locations. (Default = 0). fun character(1). Function used summarize multiple raster cells within sites location buffer (Default = mean). geom FALSE/\"sf\"/\"terra\".. function return geometry? Default FALSE, options geometry \"sf\" \"terra\". coordinate reference system sf SpatVector . ... Placeholders","code":""},{"path":"https://niehs.github.io/amadeus/reference/calculate_merra2.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate meteorological and atmospheric covariates ‚Äî calculate_merra2","text":"data.frame SpatVector object","code":""},{"path":[]},{"path":"https://niehs.github.io/amadeus/reference/calculate_merra2.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Calculate meteorological and atmospheric covariates ‚Äî calculate_merra2","text":"Mitchell Manware","code":""},{"path":"https://niehs.github.io/amadeus/reference/calculate_merra2.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate meteorological and atmospheric covariates ‚Äî calculate_merra2","text":"","code":"## NOTE: Example is wrapped in `\\dontrun{}` as function requires a large ##       amount of data which is not included in the package. if (FALSE) { # \\dontrun{ loc <- data.frame(id = \"001\", lon = -78.90, lat = 35.97) calculate_merra2(   from = merra2, # derived from process_merra2() example   locs = loc,   locs_id = \"id\",   radius = 0,   fun = \"mean\",   geom = FALSE ) } # }"},{"path":"https://niehs.github.io/amadeus/reference/calculate_modis.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate MODIS product covariates in multiple CPU threads ‚Äî calculate_modis","title":"Calculate MODIS product covariates in multiple CPU threads ‚Äî calculate_modis","text":"calculate_modis essentially runs calculate_modis_daily function thread (subprocess). Based daily resolution, day's workload distributed thread. product argument, files processed customized function unique structure /characteristics products considered.","code":""},{"path":"https://niehs.github.io/amadeus/reference/calculate_modis.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate MODIS product covariates in multiple CPU threads ‚Äî calculate_modis","text":"","code":"calculate_modis(   from = NULL,   locs = NULL,   locs_id = \"site_id\",   radius = c(0L, 1000L, 10000L, 50000L),   preprocess = amadeus::process_modis_merge,   name_covariates = NULL,   subdataset = NULL,   fun_summary = \"mean\",   package_list_add = NULL,   export_list_add = NULL,   max_cells = 3e+07,   geom = FALSE,   scale = NULL,   ... )"},{"path":"https://niehs.github.io/amadeus/reference/calculate_modis.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate MODIS product covariates in multiple CPU threads ‚Äî calculate_modis","text":"character. List paths MODIS/VIIRS files. locs sf/SpatVector object. Unique locs covariates calculated. locs_id character(1). Site identifier. Default \"site_id\" radius numeric. Radii calculate covariates. Default c(0, 1000, 10000, 50000). preprocess function. Function handle HDF files. name_covariates character. Name header covariates. e.g., \"MOD_NDVIF_0_\". calculated covariate names form \"{name_covariates}{zero-padded buffer radius meters}\", e.g., 'MOD_NDVIF_0_50000' 50 km radius circular buffer used calculate mean NDVI value. subdataset Indices, names, search patterns subdatasets. Find detail usage argument notes. fun_summary character function. Function summarize extracted raster values. package_list_add character. vector package names load thread. Note sf, terra, exactextractr, doParallel, parallelly dplyr default packages loaded. export_list_add character. vector object names export thread. minimized spare memory. max_cells integer(1). Maximum number cells read . Higher values expedite processing, increase memory usage. Maximum possible value 2^31 - 1. See exactextractr::exact_extract details. geom FALSE/\"sf\"/\"terra\".. function return geometry? Default FALSE, options geometry \"sf\" \"terra\". coordinate reference system sf SpatVector . scale character(1). Scale expression applied raw values. crucial users review technical documentatio MODIS product using ensure proper scale. example MOD11A1 product's LST_Day_1km variable (land surface temperature) scale = \"* 0.02\". Default NULL, applies scale. ... Arguments passed preprocess.","code":""},{"path":"https://niehs.github.io/amadeus/reference/calculate_modis.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate MODIS product covariates in multiple CPU threads ‚Äî calculate_modis","text":"data.frame SpatVector attribute: attr(., \"dates_dropped\"): Dates insufficient tiles. Note dates mean dates insufficient tiles, dates without available tiles.","code":""},{"path":"https://niehs.github.io/amadeus/reference/calculate_modis.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Calculate MODIS product covariates in multiple CPU threads ‚Äî calculate_modis","text":"Overall, function dependent routines assume file system can handle concurrent access (network) disk multiple processes. File system characteristics, package versions, hardware settings specification can affect processing efficiency. locs expected convertible sf object. sf, SpatVector, class objects converted sf can used. Common arguments preprocess functions date path automatically detected passed function. Please note locs path preprocess functions assumed standard naming convention raw files NASA. argument subdataset proper format depending preprocess function: process_modis_merge(): Regular expression pattern. e.g., \"^LST_\" process_modis_swath(): Subdataset names. e.g., c(\"Cloud_Fraction_Day\", \"Cloud_Fraction_Night\") process_blackmarble(): Subdataset number. e.g., VNP46A2 product, 3L. Dates less 80 percent expected number tiles, determined mode number tiles, removed. Users informed dates insufficient tiles. result data.frame attribute dates insufficient tiles.","code":""},{"path":[]},{"path":"https://niehs.github.io/amadeus/reference/calculate_modis.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate MODIS product covariates in multiple CPU threads ‚Äî calculate_modis","text":"","code":"## NOTE: Example is wrapped in `\\dontrun{}` as function requires a large ##       amount of data which is not included in the package. if (FALSE) { # \\dontrun{ locs <- data.frame(lon = -78.8277, lat = 35.95013, id = \"001\") locs <- terra::vect(locs, geom = c(\"lon\", \"lat\"), crs = \"EPSG:4326\") calculate_modis(   from =     list.files(\"./data\", pattern = \"VNP46A2.\", full.names = TRUE),   locs = locs,   locs_id = \"site_id\",   radius = c(0L, 1000L),   preprocess = process_modis_merge,   name_covariates = \"cloud_fraction_0\",   subdataset = \"Cloud_Fraction\",   fun_summary = \"mean\" ) } # }"},{"path":"https://niehs.github.io/amadeus/reference/calculate_modis_daily.html","id":null,"dir":"Reference","previous_headings":"","what":"A single-date MODIS worker ‚Äî calculate_modis_daily","title":"A single-date MODIS worker ‚Äî calculate_modis_daily","text":"function operates MODIS/VIIRS products daily basis. Given raw hdf files downloaded NASA, standard file names include data retrieval date flag starting letter \"\". Leveraging piece information, function select files scope date interest. Please note function provide function filter swaths tiles, strongly recommended check pre-filter file names users' discretion.","code":""},{"path":"https://niehs.github.io/amadeus/reference/calculate_modis_daily.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A single-date MODIS worker ‚Äî calculate_modis_daily","text":"","code":"calculate_modis_daily(   from = NULL,   locs = NULL,   locs_id = \"site_id\",   radius = 0L,   date = NULL,   name_extracted = NULL,   fun_summary = \"mean\",   max_cells = 3e+07,   geom = FALSE,   scale = NULL,   ... )"},{"path":"https://niehs.github.io/amadeus/reference/calculate_modis_daily.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"A single-date MODIS worker ‚Äî calculate_modis_daily","text":"SpatRaster. Preprocessed objects. locs SpatVector/sf/sftime object. Locations MODIS values summarized. locs_id character(1). Field name unique site identifiers stored. Default \"site_id\" radius numeric. Radius generate circular buffers. date Date(1). date query. name_extracted character. Names calculated covariates. fun_summary function. Summary function multilayer rasters. Passed foo. See exactextractr::exact_extract details. max_cells integer(1). Maximum number cells read . Higher values expedite processing, increase memory usage. Maximum possible value 2^31 - 1. geom FALSE/\"sf\"/\"terra\".. function return geometry? Default FALSE, options geometry \"sf\" \"terra\". coordinate reference system sf SpatVector . See exactextractr::exact_extract details. scale character(1). Scale expression applied raw values. crucial users review technical documentatio MODIS product using ensure proper scale. example MOD11A1 product's LST_Day_1km variable (land surface temperature) scale = \"* 0.02\". Default NULL, applies scale. ... Placeholders.","code":""},{"path":"https://niehs.github.io/amadeus/reference/calculate_modis_daily.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"A single-date MODIS worker ‚Äî calculate_modis_daily","text":"data.frame SpatVector object.","code":""},{"path":[]},{"path":"https://niehs.github.io/amadeus/reference/calculate_modis_daily.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"A single-date MODIS worker ‚Äî calculate_modis_daily","text":"Insang Song","code":""},{"path":"https://niehs.github.io/amadeus/reference/calculate_modis_daily.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"A single-date MODIS worker ‚Äî calculate_modis_daily","text":"","code":"## NOTE: Example is wrapped in `\\dontrun{}` as function requires a large ##       amount of data which is not included in the package. if (FALSE) { # \\dontrun{ locs <- data.frame(lon = -78.8277, lat = 35.95013, id = \"001\") calculate_modis_daily(   from = mod06l2_warp, # dervied from process_modis() example   locs = locs,   locs_id = \"id\",   radius = 0,   date = \"2024-01-01\",   name_extracted = \"cloud_fraction_0\",   fun_summary = \"mean\",   max_cells = 3e7 ) } # }"},{"path":"https://niehs.github.io/amadeus/reference/calculate_narr.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate meteorological covariates ‚Äî calculate_narr","title":"Calculate meteorological covariates ‚Äî calculate_narr","text":"Extract meteorological values point locations. Returns data.frame object containing locs_id, date, vertical pressure level, meteorological variable. Meteorological variable column name reflects variable circular buffer radius.","code":""},{"path":"https://niehs.github.io/amadeus/reference/calculate_narr.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate meteorological covariates ‚Äî calculate_narr","text":"","code":"calculate_narr(   from,   locs,   locs_id = NULL,   radius = 0,   fun = \"mean\",   geom = FALSE,   ... )"},{"path":"https://niehs.github.io/amadeus/reference/calculate_narr.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate meteorological covariates ‚Äî calculate_narr","text":"SpatRaster(1). Output process_narr(). locs data.frame, characater file path, SpatVector, sf object. locs_id character(1). Column within locations CSV file containing identifier unique coordinate location. radius integer(1). Circular buffer distance around site locations. (Default = 0). fun character(1). Function used summarize multiple raster cells within sites location buffer (Default = mean). geom FALSE/\"sf\"/\"terra\".. function return geometry? Default FALSE, options geometry \"sf\" \"terra\". coordinate reference system sf SpatVector . ... Placeholders","code":""},{"path":"https://niehs.github.io/amadeus/reference/calculate_narr.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate meteorological covariates ‚Äî calculate_narr","text":"data.frame SpatVector object","code":""},{"path":[]},{"path":"https://niehs.github.io/amadeus/reference/calculate_narr.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Calculate meteorological covariates ‚Äî calculate_narr","text":"Mitchell Manware","code":""},{"path":"https://niehs.github.io/amadeus/reference/calculate_narr.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate meteorological covariates ‚Äî calculate_narr","text":"","code":"## NOTE: Example is wrapped in `\\dontrun{}` as function requires a large ##       amount of data which is not included in the package. if (FALSE) { # \\dontrun{ loc <- data.frame(id = \"001\", lon = -78.90, lat = 35.97) calculate_narr(   from = narr, # derived from process_narr() example   locs = loc,   locs_id = \"id\",   radius = 0,   fun = \"mean\",   geom = FALSE ) } # }"},{"path":"https://niehs.github.io/amadeus/reference/calculate_nei.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate road emissions covariates ‚Äî calculate_nei","title":"Calculate road emissions covariates ‚Äî calculate_nei","text":"Calculate road emissions covariates","code":""},{"path":"https://niehs.github.io/amadeus/reference/calculate_nei.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate road emissions covariates ‚Äî calculate_nei","text":"","code":"calculate_nei(from = NULL, locs = NULL, locs_id = \"site_id\", geom = FALSE, ...)"},{"path":"https://niehs.github.io/amadeus/reference/calculate_nei.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate road emissions covariates ‚Äî calculate_nei","text":"SpatVector(1). Output process_nei(). locs sf/SpatVector. Locations NEI values joined. locs_id character(1). Unique site identifier column name. Unused kept compatibility. geom FALSE/\"sf\"/\"terra\".. function return geometry? Default FALSE, options geometry \"sf\" \"terra\". coordinate reference system sf SpatVector . ... Placeholders.","code":""},{"path":"https://niehs.github.io/amadeus/reference/calculate_nei.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate road emissions covariates ‚Äî calculate_nei","text":"data.frame SpatVector object","code":""},{"path":[]},{"path":"https://niehs.github.io/amadeus/reference/calculate_nei.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Calculate road emissions covariates ‚Äî calculate_nei","text":"Insang Song, Ranadeep Daw","code":""},{"path":"https://niehs.github.io/amadeus/reference/calculate_nei.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate road emissions covariates ‚Äî calculate_nei","text":"","code":"## NOTE: Example is wrapped in `\\dontrun{}` as function requires a large ##       amount of data which is not included in the package. if (FALSE) { # \\dontrun{ loc <- data.frame(id = \"001\", lon = -78.90, lat = 35.97) calculate_nei(   from = nei, # derived from process_nei example   locs = loc,   locs_id = \"id\" ) } # }"},{"path":"https://niehs.github.io/amadeus/reference/calculate_nlcd.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate land cover covariates ‚Äî calculate_nlcd","title":"Calculate land cover covariates ‚Äî calculate_nlcd","text":"Compute ratio land cover class circle buffers around points. Returns data.frame object containing locs_id, longitude, latitude, time (year), computed ratio land cover class.","code":""},{"path":"https://niehs.github.io/amadeus/reference/calculate_nlcd.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate land cover covariates ‚Äî calculate_nlcd","text":"","code":"calculate_nlcd(   from,   locs,   locs_id = \"site_id\",   mode = c(\"exact\", \"terra\"),   radius = 1000,   max_cells = 5e+07,   geom = FALSE,   ... )"},{"path":"https://niehs.github.io/amadeus/reference/calculate_nlcd.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate land cover covariates ‚Äî calculate_nlcd","text":"SpatRaster(1). Output process_nlcd(). locs terra::SpatVector points geometry locs_id character(1). Unique identifier locations mode character(1). One \"exact\" (using exactextractr::exact_extract()) \"terra\" (using terra::freq()). Ignored locs points. radius numeric (non-negative) giving radius buffer around points. max_cells integer(1). Maximum number cells read . Higher values may expedite processing, increase memory usage. Maximum possible value 2^31 - 1. valid mode = \"exact\". See exactextractr::exact_extract details. geom FALSE/\"sf\"/\"terra\".. function return geometry? Default FALSE, options geometry \"sf\" \"terra\". coordinate reference system sf SpatVector . ... Placeholders.","code":""},{"path":"https://niehs.github.io/amadeus/reference/calculate_nlcd.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate land cover covariates ‚Äî calculate_nlcd","text":"data.frame SpatVector object","code":""},{"path":"https://niehs.github.io/amadeus/reference/calculate_nlcd.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Calculate land cover covariates ‚Äî calculate_nlcd","text":"NLCD available U.S. . Users aware spatial extent data. results different depending mode argument. \"terra\" mode less memory intensive less accurate counts number cells intersecting buffer. \"exact\" may accurate uses memory account partial overlap buffer.","code":""},{"path":[]},{"path":"https://niehs.github.io/amadeus/reference/calculate_nlcd.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate land cover covariates ‚Äî calculate_nlcd","text":"","code":"## NOTE: Example is wrapped in `\\dontrun{}` as function requires a large ##       amount of data which is not included in the package. if (FALSE) { # \\dontrun{ loc <- data.frame(id = \"001\", lon = -78.90, lat = 35.97) calculate_nlcd(   from = nlcd, # derived from process_nlcd() example   locs = loc,   locs_id = \"id\",   mode = \"exact\",   geom = FALSE ) } # }"},{"path":"https://niehs.github.io/amadeus/reference/calculate_population.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate population density covariates ‚Äî calculate_population","title":"Calculate population density covariates ‚Äî calculate_population","text":"Extract population density values point locations. Returns data.frame object containing locs_id, year, population density variable. Population density variable column name reflects spatial resolution circular buffer radius.","code":""},{"path":"https://niehs.github.io/amadeus/reference/calculate_population.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate population density covariates ‚Äî calculate_population","text":"","code":"calculate_population(   from,   locs,   locs_id = NULL,   radius = 0,   fun = \"mean\",   geom = FALSE,   ... )"},{"path":"https://niehs.github.io/amadeus/reference/calculate_population.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate population density covariates ‚Äî calculate_population","text":"SpatRaster(1). Output process_population(). locs data.frame, characater file path, SpatVector, sf object. locs_id character(1). Column within locations CSV file containing identifier unique coordinate location. radius integer(1). Circular buffer distance around site locations. (Default = 0). fun character(1). Function used summarize multiple raster cells within sites location buffer (Default = mean). geom FALSE/\"sf\"/\"terra\".. function return geometry? Default FALSE, options geometry \"sf\" \"terra\". coordinate reference system sf SpatVector . ... Placeholders","code":""},{"path":"https://niehs.github.io/amadeus/reference/calculate_population.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate population density covariates ‚Äî calculate_population","text":"data.frame SpatVector object","code":""},{"path":[]},{"path":"https://niehs.github.io/amadeus/reference/calculate_population.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Calculate population density covariates ‚Äî calculate_population","text":"Mitchell Manware","code":""},{"path":"https://niehs.github.io/amadeus/reference/calculate_population.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate population density covariates ‚Äî calculate_population","text":"","code":"## NOTE: Example is wrapped in `\\dontrun{}` as function requires a large ##       amount of data which is not included in the package. if (FALSE) { # \\dontrun{ loc <- data.frame(id = \"001\", lon = -78.90, lat = 35.97) calculate_population(   from = pop, # derived from process_population() example   locs = loc,   locs_id = \"id\",   radius = 0,   fun = \"mean\",   geom = FALSE ) } # }"},{"path":"https://niehs.github.io/amadeus/reference/calculate_temporal_dummies.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate temporal dummy covariates ‚Äî calculate_temporal_dummies","title":"Calculate temporal dummy covariates ‚Äî calculate_temporal_dummies","text":"Calculate temporal dummy covariates point locations. Returns data.frame object locs_id, year binary variable value year, month day week binary variables.","code":""},{"path":"https://niehs.github.io/amadeus/reference/calculate_temporal_dummies.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate temporal dummy covariates ‚Äî calculate_temporal_dummies","text":"","code":"calculate_temporal_dummies(   locs,   locs_id = \"site_id\",   year = seq(2018L, 2022L),   geom = FALSE,   ... )"},{"path":"https://niehs.github.io/amadeus/reference/calculate_temporal_dummies.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate temporal dummy covariates ‚Äî calculate_temporal_dummies","text":"locs data.frame temporal field named \"time\" locs_id character(1). Unique site identifier column name. Default \"site_id\". year integer. Year domain dummify. Default seq(2018L, 2022L). geom FALSE/\"sf\"/\"terra\".. function return geometry? Default FALSE, options geometry \"sf\" \"terra\". coordinate reference system sf SpatVector . ... Placeholders.","code":""},{"path":"https://niehs.github.io/amadeus/reference/calculate_temporal_dummies.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate temporal dummy covariates ‚Äî calculate_temporal_dummies","text":"data.frame SpatVector object","code":""},{"path":"https://niehs.github.io/amadeus/reference/calculate_temporal_dummies.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Calculate temporal dummy covariates ‚Äî calculate_temporal_dummies","text":"Insang Song","code":""},{"path":"https://niehs.github.io/amadeus/reference/calculate_temporal_dummies.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate temporal dummy covariates ‚Äî calculate_temporal_dummies","text":"","code":"## NOTE: Example is wrapped in `\\dontrun{}` as function requires a large ##       amount of data which is not included in the package. if (FALSE) { # \\dontrun{ loc <- data.frame(id = \"001\", lon = -78.90, lat = 35.97) calculate_temporal_dummies(   locs = loc,   locs_id = \"id\",   year = seq(2018L, 2022L) ) } # }"},{"path":"https://niehs.github.io/amadeus/reference/calculate_terraclimate.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate TerraClimate covariates ‚Äî calculate_terraclimate","title":"Calculate TerraClimate covariates ‚Äî calculate_terraclimate","text":"Extract TerraClimate values point locations. Returns data.frame object containing locs_id TerraClimate variable. TerraClimate variable column name reflects TerraClimate variable circular buffer radius. $time column contain year month (\"YYYYMM\") TerraClimate products monthly temporal resolution.","code":""},{"path":"https://niehs.github.io/amadeus/reference/calculate_terraclimate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate TerraClimate covariates ‚Äî calculate_terraclimate","text":"","code":"calculate_terraclimate(   from = NULL,   locs = NULL,   locs_id = NULL,   radius = 0,   fun = \"mean\",   geom = FALSE,   ... )"},{"path":"https://niehs.github.io/amadeus/reference/calculate_terraclimate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate TerraClimate covariates ‚Äî calculate_terraclimate","text":"SpatRaster(1). Output process_terraclimate(). locs data.frame. character file path, SpatVector, sf object. locs_id character(1). Column within locations CSV file containing identifier unique coordinate location. radius integer(1). Circular buffer distance around site locations. (Default = 0). fun character(1). Function used summarize multiple raster cells within sites location buffer (Default = mean). geom FALSE/\"sf\"/\"terra\".. function return geometry? Default FALSE, options geometry \"sf\" \"terra\". coordinate reference system sf SpatVector . ... Placeholders.","code":""},{"path":"https://niehs.github.io/amadeus/reference/calculate_terraclimate.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate TerraClimate covariates ‚Äî calculate_terraclimate","text":"data.frame SpatVector object","code":""},{"path":"https://niehs.github.io/amadeus/reference/calculate_terraclimate.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Calculate TerraClimate covariates ‚Äî calculate_terraclimate","text":"TerraClimate data monthly temporal resolution, $time column contain year month YYYYMM format (ie. January, 2018 = 201801).","code":""},{"path":[]},{"path":"https://niehs.github.io/amadeus/reference/calculate_terraclimate.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Calculate TerraClimate covariates ‚Äî calculate_terraclimate","text":"Mitchell Manware","code":""},{"path":"https://niehs.github.io/amadeus/reference/calculate_terraclimate.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate TerraClimate covariates ‚Äî calculate_terraclimate","text":"","code":"## NOTE: Example is wrapped in `\\dontrun{}` as function requires a large ##       amount of data which is not included in the package. if (FALSE) { # \\dontrun{ loc <- data.frame(id = \"001\", lon = -78.90, lat = 35.97) calculate_terraclimate(   from = terraclimate, # derived from process_terraclimate() example   locs = loc,   locs_id = \"id\",   radius = 0,   fun = \"mean\",   geom = FALSE ) } # }"},{"path":"https://niehs.github.io/amadeus/reference/calculate_tri.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate toxic release covariates ‚Äî calculate_tri","title":"Calculate toxic release covariates ‚Äî calculate_tri","text":"Calculate toxic release values polygons isotropic buffer point locations. Returns data.frame object containing locs_id variables chemical .","code":""},{"path":"https://niehs.github.io/amadeus/reference/calculate_tri.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate toxic release covariates ‚Äî calculate_tri","text":"","code":"calculate_tri(   from = NULL,   locs,   locs_id = \"site_id\",   radius = c(1000L, 10000L, 50000L),   geom = FALSE,   ... )"},{"path":"https://niehs.github.io/amadeus/reference/calculate_tri.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate toxic release covariates ‚Äî calculate_tri","text":"SpatVector(1). Output process_tri(). locs sf/SpatVector. Locations TRI variables calculated. locs_id character(1). Unique site identifier column name. Default \"site_id\". radius Circular buffer radius. Default c(1000, 10000, 50000) (meters) geom FALSE/\"sf\"/\"terra\".. function return geometry? Default FALSE, options geometry \"sf\" \"terra\". coordinate reference system sf SpatVector . ... Placeholders.","code":""},{"path":"https://niehs.github.io/amadeus/reference/calculate_tri.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate toxic release covariates ‚Äî calculate_tri","text":"data.frame SpatVector object","code":""},{"path":"https://niehs.github.io/amadeus/reference/calculate_tri.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Calculate toxic release covariates ‚Äî calculate_tri","text":"U.S. context.","code":""},{"path":[]},{"path":"https://niehs.github.io/amadeus/reference/calculate_tri.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Calculate toxic release covariates ‚Äî calculate_tri","text":"Insang Song, Mariana Kassien","code":""},{"path":"https://niehs.github.io/amadeus/reference/calculate_tri.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate toxic release covariates ‚Äî calculate_tri","text":"","code":"## NOTE: Example is wrapped in `\\dontrun{}` as function requires a large ##       amount of data which is not included in the package. if (FALSE) { # \\dontrun{ loc <- data.frame(id = \"001\", lon = -78.90, lat = 35.97) calculate_tri(   from = tri, # derived from process_tri() example   locs = loc,   locs_id = \"id\",   radius = c(1e3L, 1e4L, 5e4L) ) } # }"},{"path":"https://niehs.github.io/amadeus/reference/check_destfile.html","id":null,"dir":"Reference","previous_headings":"","what":"Check if destination file exists or is 0 bytes. ‚Äî check_destfile","title":"Check if destination file exists or is 0 bytes. ‚Äî check_destfile","text":"Check destination file exists 0 bytes. either condition met, function returns TRUE allow download proceed.","code":""},{"path":"https://niehs.github.io/amadeus/reference/check_destfile.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check if destination file exists or is 0 bytes. ‚Äî check_destfile","text":"","code":"check_destfile(destfile)"},{"path":"https://niehs.github.io/amadeus/reference/check_destfile.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check if destination file exists or is 0 bytes. ‚Äî check_destfile","text":"destfile character(1). Destination file path.","code":""},{"path":"https://niehs.github.io/amadeus/reference/check_destfile.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check if destination file exists or is 0 bytes. ‚Äî check_destfile","text":"logical(1)","code":""},{"path":"https://niehs.github.io/amadeus/reference/check_for_null_parameters.html","id":null,"dir":"Reference","previous_headings":"","what":"Check parameters ‚Äî check_for_null_parameters","title":"Check parameters ‚Äî check_for_null_parameters","text":"Check parameters assigned value.","code":""},{"path":"https://niehs.github.io/amadeus/reference/check_for_null_parameters.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check parameters ‚Äî check_for_null_parameters","text":"","code":"check_for_null_parameters(parameters)"},{"path":"https://niehs.github.io/amadeus/reference/check_for_null_parameters.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check parameters ‚Äî check_for_null_parameters","text":"parameters parameters passed function (called mget(ls()).)","code":""},{"path":"https://niehs.github.io/amadeus/reference/check_for_null_parameters.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check parameters ‚Äî check_for_null_parameters","text":"NULL; returns stop error one function parameters 'extent' NULL","code":""},{"path":"https://niehs.github.io/amadeus/reference/check_geom.html","id":null,"dir":"Reference","previous_headings":"","what":"Check that geom value is one of FALSE, ","title":"Check that geom value is one of FALSE, ","text":"Check geom value one FALSE, \"sf\", \"terra\".","code":""},{"path":"https://niehs.github.io/amadeus/reference/check_geom.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check that geom value is one of FALSE, ","text":"","code":"check_geom(geom)"},{"path":"https://niehs.github.io/amadeus/reference/check_geom.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check that geom value is one of FALSE, ","text":"geom FALSE/\"sf\"/\"terra\".'","code":""},{"path":"https://niehs.github.io/amadeus/reference/check_geom.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check that geom value is one of FALSE, ","text":"NULL; stop geom one three options","code":""},{"path":"https://niehs.github.io/amadeus/reference/check_geom.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Check that geom value is one of FALSE, ","text":"Mitchell Manware","code":""},{"path":"https://niehs.github.io/amadeus/reference/check_mysf.html","id":null,"dir":"Reference","previous_headings":"","what":"Check sf object ‚Äî check_mysf","title":"Check sf object ‚Äî check_mysf","text":"Check sf object class, $geometry column, geometry class.","code":""},{"path":"https://niehs.github.io/amadeus/reference/check_mysf.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check sf object ‚Äî check_mysf","text":"","code":"check_mysf(x)"},{"path":"https://niehs.github.io/amadeus/reference/check_mysf.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check sf object ‚Äî check_mysf","text":"x sf object","code":""},{"path":"https://niehs.github.io/amadeus/reference/check_mysf.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check sf object ‚Äî check_mysf","text":"NULL; returns stop error x match class /column expectations","code":""},{"path":"https://niehs.github.io/amadeus/reference/check_mysf.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Check sf object ‚Äî check_mysf","text":"Eva Marques","code":""},{"path":"https://niehs.github.io/amadeus/reference/check_mysftime.html","id":null,"dir":"Reference","previous_headings":"","what":"Check sftime object ‚Äî check_mysftime","title":"Check sftime object ‚Äî check_mysftime","text":"Check sftime object class, $time column, $geometry column, geometry class.","code":""},{"path":"https://niehs.github.io/amadeus/reference/check_mysftime.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check sftime object ‚Äî check_mysftime","text":"","code":"check_mysftime(x)"},{"path":"https://niehs.github.io/amadeus/reference/check_mysftime.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check sftime object ‚Äî check_mysftime","text":"x sftime object","code":""},{"path":"https://niehs.github.io/amadeus/reference/check_mysftime.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check sftime object ‚Äî check_mysftime","text":"NULL; returns stop error x match class column expectations","code":""},{"path":"https://niehs.github.io/amadeus/reference/check_mysftime.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Check sftime object ‚Äî check_mysftime","text":"Eva Marques","code":""},{"path":"https://niehs.github.io/amadeus/reference/check_url_status.html","id":null,"dir":"Reference","previous_headings":"","what":"Check HTTP status ‚Äî check_url_status","title":"Check HTTP status ‚Äî check_url_status","text":"Check provided URL returns HTTP status 200 206.","code":""},{"path":"https://niehs.github.io/amadeus/reference/check_url_status.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check HTTP status ‚Äî check_url_status","text":"","code":"check_url_status(url, method = c(\"HEAD\", \"GET\"))"},{"path":"https://niehs.github.io/amadeus/reference/check_url_status.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check HTTP status ‚Äî check_url_status","text":"url Download URL checked. method httr method obtain URL (\"HEAD\" \"GET\")","code":""},{"path":"https://niehs.github.io/amadeus/reference/check_url_status.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check HTTP status ‚Äî check_url_status","text":"logical object","code":""},{"path":"https://niehs.github.io/amadeus/reference/check_url_status.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Check HTTP status ‚Äî check_url_status","text":"Insang Song; Mitchell Manware","code":""},{"path":"https://niehs.github.io/amadeus/reference/check_urls.html","id":null,"dir":"Reference","previous_headings":"","what":"Implement check_url_status ‚Äî check_urls","title":"Implement check_url_status ‚Äî check_urls","text":"Apply check_url_status() function sample download URLs.","code":""},{"path":"https://niehs.github.io/amadeus/reference/check_urls.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Implement check_url_status ‚Äî check_urls","text":"","code":"check_urls(urls = urls, size = NULL, method = c(\"HEAD\", \"GET\", \"SKIP\"))"},{"path":"https://niehs.github.io/amadeus/reference/check_urls.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Implement check_url_status ‚Äî check_urls","text":"urls character vector URLs size number observations sampled urls method httr method obtain URL (\"HEAD\" \"GET\"). set \"SKIP\", HTTP status checked returned.","code":""},{"path":"https://niehs.github.io/amadeus/reference/check_urls.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Implement check_url_status ‚Äî check_urls","text":"logical vector URL status = 200","code":""},{"path":"https://niehs.github.io/amadeus/reference/collapse_nlcd.html","id":null,"dir":"Reference","previous_headings":"","what":"Collapse listed NLCD values while filling in NA for sites outside data. ‚Äî collapse_nlcd","title":"Collapse listed NLCD values while filling in NA for sites outside data. ‚Äî collapse_nlcd","text":"Collapse listed NLCD values filling NA sites outside data.","code":""},{"path":"https://niehs.github.io/amadeus/reference/collapse_nlcd.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Collapse listed NLCD values while filling in NA for sites outside data. ‚Äî collapse_nlcd","text":"","code":"collapse_nlcd(   data,   mode = c(\"terra\", \"extract\"),   locs = NULL,   locs_id = \"site_id\" )"},{"path":"https://niehs.github.io/amadeus/reference/collapse_nlcd.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Collapse listed NLCD values while filling in NA for sites outside data. ‚Äî collapse_nlcd","text":"data Buffered values NLCD data. mode \"exact\" \"terra\" locs extraction locations. locs_id character(1). Name unique identifier.","code":""},{"path":"https://niehs.github.io/amadeus/reference/cov.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate code coverage of the beethoven package with the container.sif container. ‚Äî cov","title":"Calculate code coverage of the beethoven package with the container.sif container. ‚Äî cov","text":"Calculate code coverage beethoven package container.sif container.","code":""},{"path":"https://niehs.github.io/amadeus/reference/cov.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate code coverage of the beethoven package with the container.sif container. ‚Äî cov","text":"","code":"cov()"},{"path":"https://niehs.github.io/amadeus/reference/cov.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate code coverage of the beethoven package with the container.sif container. ‚Äî cov","text":"NULL; Prints output code coverage.","code":""},{"path":[]},{"path":"https://niehs.github.io/amadeus/reference/download_aqs.html","id":null,"dir":"Reference","previous_headings":"","what":"Download air quality data ‚Äî download_aqs","title":"Download air quality data ‚Äî download_aqs","text":"download_aqs() function accesses downloads Air Quality System (AQS) data U.S. Environmental Protection Agency's (EPA) Pre-Generated Data Files.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_aqs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Download air quality data ‚Äî download_aqs","text":"","code":"download_aqs(   parameter_code = 88101,   resolution_temporal = \"daily\",   year = c(2018, 2022),   url_aqs_download = \"https://aqs.epa.gov/aqsweb/airdata/\",   directory_to_save = NULL,   acknowledgement = FALSE,   download = FALSE,   remove_command = FALSE,   unzip = TRUE,   remove_zip = FALSE,   hash = FALSE )"},{"path":"https://niehs.github.io/amadeus/reference/download_aqs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Download air quality data ‚Äî download_aqs","text":"parameter_code integer(1). length 5. EPA pollutant parameter code. details, please refer AQS parameter codes resolution_temporal character(1). Name column containing POC values. Currently, value \"daily\" works. year integer(1 2). length 4. Year start/end years downloading data. url_aqs_download character(1). URL AQS pre-generated datasets. directory_to_save character(1). Directory save data. Two sub-directories created downloaded zip files (\"/zip_files\") unzipped data files (\"/data_files\"). acknowledgement logical(1). setting TRUE user acknowledges data downloaded using function may large use lots machine storage memory. download logical(1). FALSE generate *.txt file containing download commands. setting TRUE function download requested data files. remove_command logical(1). Remove (TRUE) keep (FALSE) text file containing download commands. Default FALSE. unzip logical(1). Unzip zip files. Default TRUE. remove_zip logical(1). Remove zip file directory_to_download. Default FALSE. hash logical(1). setting TRUE function return rlang::hash_file() hash character corresponding downloaded files. Default FALSE.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_aqs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Download air quality data ‚Äî download_aqs","text":"hash = FALSE, NULL hash = TRUE, rlang::hash_file character. Zip /data files downloaded stored directory_to_save.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_aqs.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Download air quality data ‚Äî download_aqs","text":"U.S. Environmental Protection Agency (2023). ‚ÄúAir Quality System Data Mart [internet database].‚Äù https://www.epa.gov/outdoor-air-quality-data.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_aqs.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Download air quality data ‚Äî download_aqs","text":"Mariana Kassien, Insang Song, Mitchell Manware","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_aqs.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Download air quality data ‚Äî download_aqs","text":"","code":"if (FALSE) { # \\dontrun{ download_aqs(   parameter_code = 88101,   resolution_temporal = \"daily\",   year = 2023,   directory_to_save = tempdir(),   acknowledgement = TRUE,   download = FALSE, # NOTE: download skipped for examples,   remove_command = TRUE,   unzip = FALSE ) } # }"},{"path":"https://niehs.github.io/amadeus/reference/download_cropscape.html","id":null,"dir":"Reference","previous_headings":"","what":"Download CropScape data ‚Äî download_cropscape","title":"Download CropScape data ‚Äî download_cropscape","text":"Accesses downloads United States Department Agriculture CropScape Cropland Data Layer data USDA National Agricultural Statistics Service George Mason University website.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_cropscape.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Download CropScape data ‚Äî download_cropscape","text":"","code":"download_cropscape(   year = seq(1997, 2023),   source = c(\"USDA\", \"GMU\"),   directory_to_save = NULL,   acknowledgement = FALSE,   download = FALSE,   remove_command = FALSE,   unzip = TRUE,   hash = FALSE )"},{"path":"https://niehs.github.io/amadeus/reference/download_cropscape.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Download CropScape data ‚Äî download_cropscape","text":"year integer(1). Year data download. source character(1). Data source, one c(\"USDA\", \"GMU\"). \"USDA\" download national data USDA website (available 2008-last year). \"GMU\" download data George Mason University website (available 1997-last year). directory_to_save character(1). Directory download files. acknowledgement logical(1). setting TRUE user acknowledges data downloaded using function may large use lots machine storage memory. download logical(1). FALSE generate *.txt file containing download commands. setting TRUE function download requested data files. remove_command logical(1). Remove (TRUE) keep (FALSE) text file containing download commands. unzip logical(1). Unzip downloaded compressed files. Default FALSE. hash logical(1). setting TRUE function return rlang::hash_file() hash character corresponding downloaded files. Default FALSE.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_cropscape.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Download CropScape data ‚Äî download_cropscape","text":"hash = FALSE, NULL hash = TRUE, rlang::hash_file character. Yearly comma-separated value (CSV) files stored directory_to_save.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_cropscape.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Download CropScape data ‚Äî download_cropscape","text":"JSON files found STAC catalog OpenLandMap","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_cropscape.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Download CropScape data ‚Äî download_cropscape","text":"Insang Song","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_cropscape.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Download CropScape data ‚Äî download_cropscape","text":"","code":"if (FALSE) { # \\dontrun{ download_cropscape(   year = 2020,   source = \"USDA\",   directory_to_save = tempdir(),   acknowledgement = TRUE,   download = FALSE, # NOTE: download skipped for examples,   remove_command = TRUE,   unzip = FALSE ) } # }"},{"path":"https://niehs.github.io/amadeus/reference/download_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Download raw data wrapper function ‚Äî download_data","title":"Download raw data wrapper function ‚Äî download_data","text":"download_data() function accesses downloads atmospheric, meteorological, environmental data various open-access data sources.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Download raw data wrapper function ‚Äî download_data","text":"","code":"download_data(   dataset_name = c(\"aqs\", \"ecoregion\", \"ecoregions\", \"geos\", \"gmted\", \"koppen\",     \"koppengeiger\", \"merra2\", \"merra\", \"modis\", \"narr\", \"nlcd\", \"noaa\", \"sedac_groads\",     \"sedac_population\", \"groads\", \"population\", \"hms\", \"smoke\", \"tri\", \"nei\", \"gridmet\",     \"terraclimate\", \"huc\", \"cropscape\", \"cdl\", \"prism\", \"edgar\"),   directory_to_save = NULL,   acknowledgement = FALSE,   hash = FALSE,   ... )"},{"path":"https://niehs.github.io/amadeus/reference/download_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Download raw data wrapper function ‚Äî download_data","text":"dataset_name character(1). Dataset download. directory_to_save character(1). Directory save / unzip (zip files downloaded) data. acknowledgement logical(1). setting TRUE user acknowledges data downloaded using function may large use lots machine storage memory. hash logical(1). setting TRUE function return rlang::hash_file() hash character corresponding downloaded files. Default FALSE. ... Arguments passed download function.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Download raw data wrapper function ‚Äî download_data","text":"hash = FALSE, NULL hash = TRUE, rlang::hash_file character. Data files downloaded stored respective sub-directories within directory_to_save. File format sub-directory names depend data source dataset interest.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_data.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Download raw data wrapper function ‚Äî download_data","text":"download function names download_* formats","code":""},{"path":[]},{"path":"https://niehs.github.io/amadeus/reference/download_data.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Download raw data wrapper function ‚Äî download_data","text":"Insang Song","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_data.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Download raw data wrapper function ‚Äî download_data","text":"","code":"if (FALSE) { # \\dontrun{ download_data(   dataset_name = \"narr\",   variables = \"weasd\",   year = 2023,   directory_to_save = tempdir(),   acknowledgement = TRUE,   download = FALSE, # NOTE: download skipped for examples,   remove_command = TRUE ) } # }"},{"path":"https://niehs.github.io/amadeus/reference/download_ecoregion.html","id":null,"dir":"Reference","previous_headings":"","what":"Download ecoregion data ‚Äî download_ecoregion","title":"Download ecoregion data ‚Äî download_ecoregion","text":"download_ecoregion() function accesses downloads United States Ecoregions data U.S. Environmental Protection Agency's (EPA) Ecorgions. Level 3 data, pieces information higher levels included, downloaded.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_ecoregion.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Download ecoregion data ‚Äî download_ecoregion","text":"","code":"download_ecoregion(   epa_certificate_path = system.file(\"extdata/cacert_gaftp_epa.pem\", package = \"amadeus\"),   certificate_url =     \"http://cacerts.digicert.com/DigiCertGlobalG2TLSRSASHA2562020CA1-1.crt\",   directory_to_save = NULL,   acknowledgement = FALSE,   download = FALSE,   remove_command = FALSE,   unzip = TRUE,   remove_zip = FALSE,   hash = FALSE )"},{"path":"https://niehs.github.io/amadeus/reference/download_ecoregion.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Download ecoregion data ‚Äî download_ecoregion","text":"epa_certificate_path character(1). Path certificate file EPA DataCommons. Default 'extdata/cacert_gaftp_epa.pem' package installation path. certificate_url character(1). URL certificate file. See notes details. directory_to_save character(1). Directory save data. Two sub-directories created downloaded zip files (\"/zip_files\") unzipped data files (\"/data_files\"). acknowledgement logical(1). setting TRUE user acknowledges data downloaded using function may large use lots machine storage memory. download logical(1). FALSE generate *.txt file containing download commands. setting TRUE function download requested data files. remove_command logical(1). Remove (TRUE) keep (FALSE) text file containing download commands. unzip logical(1). Unzip zip files. Default TRUE. remove_zip logical(1). Remove zip file directory_to_download. Default FALSE. hash logical(1). setting TRUE function return rlang::hash_file() hash character corresponding downloaded files. Default FALSE.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_ecoregion.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Download ecoregion data ‚Äî download_ecoregion","text":"hash = FALSE, NULL hash = TRUE, rlang::hash_file character. Zip /data files downloaded stored directory_to_save.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_ecoregion.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Download ecoregion data ‚Äî download_ecoregion","text":"EPA Data Commons certificate errors, follow steps : Click Lock icon address bar https://gaftp.epa.gov Click Show Certificate Access Details Find URL *.crt extension Currently bundle pre-downloaded crt PEM (accepted wget command) file ./inst/extdata. instruction certificate updates future.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_ecoregion.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Download ecoregion data ‚Äî download_ecoregion","text":"Omernik JM, Griffith GE (2014). ‚ÄúEcoregions Conterminous United States: Evolution Hierarchical Spatial Framework.‚Äù Environmental Management, 54(6), 1249‚Äì1266. ISSN 0364-152X, 1432-1009, doi:10.1007/s00267-014-0364-1 , https://link.springer.com/article/10.1007/s00267-014-0364-1.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_ecoregion.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Download ecoregion data ‚Äî download_ecoregion","text":"Insang Song","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_ecoregion.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Download ecoregion data ‚Äî download_ecoregion","text":"","code":"if (FALSE) { # \\dontrun{ download_ecoregion(   directory_to_save = tempdir(),   acknowledgement = TRUE,   download = FALSE, # NOTE: download skipped for examples,   remove_command = TRUE,   unzip = FALSE ) } # }"},{"path":"https://niehs.github.io/amadeus/reference/download_edgar.html","id":null,"dir":"Reference","previous_headings":"","what":"Download EDGAR Emissions Data ‚Äî download_edgar","title":"Download EDGAR Emissions Data ‚Äî download_edgar","text":"Constructs optionally downloads EDGAR emissions data URLs based user-specified inputs including species, temporal resolution, emission sectors, file formats.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_edgar.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Download EDGAR Emissions Data ‚Äî download_edgar","text":"","code":"download_edgar(   species = c(\"BC\", \"CO\", \"NH3\", \"NMVOC\", \"NOx\", \"OC\", \"PM10\", \"PM2.5\", \"SO2\"),   version = \"8.1\",   temp_res = NULL,   sector_yearly = NULL,   sector_monthly = NULL,   sector_voc = NULL,   format = \"nc\",   output = \"emi\",   year_range = NULL,   voc = NULL,   directory_to_save = NULL,   acknowledgement = FALSE,   download = FALSE,   remove_command = FALSE,   unzip = TRUE,   remove_zip = FALSE,   hash = FALSE )"},{"path":"https://niehs.github.io/amadeus/reference/download_edgar.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Download EDGAR Emissions Data ‚Äî download_edgar","text":"species Character vector. One species download. Supported values: \"BC\", \"CO\", \"NH3\", \"NMVOC\", \"NOx\", \"OC\", \"PM10\", \"PM2.5\", \"SO2\". Input case-insensitive supports \"pm2.5\" \"pm25\". version Character. EDGAR data version. Supported values: \"8.1\" recent version data \"8.1_voc\" VOC speciation data. temp_res Character. Temporal resolution specification version 8.1. One \"yearly\", \"monthly\", \"timeseries\". temp_res needed version=8.1_voc ignored specified. sector_yearly Character vector NULL. Emission sectors yearly data. NULL, totals used. Possible values include: \"AGS\", \"AWB\", \"CHE\", \"ENE\", \"IND\", \"MNM\", \"NMM\", \"PRU_SOL\", \"RCO\", \"REF_TRF\", \"SWD_INC\", \"SWD_LDF\", \"TNR_Aviation_CDS\", \"TNR_Aviation_CRS\", \"TNR_Aviation_LTO\", \"TNR_Aviation_SPS\", \"TNR_Other\", \"TNR_Ship\", \"TRO\", \"WWT\" sector_monthly Character vector NULL. Emission sectors monthly data. NULL, function use full-species files (sector-specific). Supported values: \"AGRICULTURE\", \"BUILDINGS\", \"FUEL_EXPLOITATION\", \"IND_COMBUSTION\", \"IND_PROCESSES\", \"POWER_INDUSTRY\", \"TRANSPORT\", \"WASTE\". sector_voc Character vector NULL. Emission sectors VOC speciation data. NULL, function use full-species files (sector-specific). Supported values: \"AGRICULTURE\", \"BUILDINGS\", \"FUEL_EXPLOITATION\", \"IND_COMBUSTION\", \"IND_PROCESSES\", \"POWER_INDUSTRY\", \"TRANSPORT\", \"WASTE\". format Character. File format download. Typically \"nc\" (NetCDF) \"txt\". Flux output monthly outputs supported .nc format output Character. Output type. Supported values include \"emi\" emissions \"flx\" fluxes. year_range Numeric vector length 1, 2 NULL. Year range, e.g., 2021, c(2021, 2022). NULL, uses available years (1970-2022 yearly data, 2000-2022 monthly VOC speciation data) voc Integer vector NULL. Used VOC speciation version \"8.1_voc\". Accepts integers 1 25. See: https://edgar.jrc.ec.europa.eu/dataset_ap81_VOC_spec#p3  reference speciation groups VOC numbers. directory_to_save character(1). Directory save data. Two sub-directories created downloaded zip files (\"/zip_files\") unzipped data files (\"/data_files\"). acknowledgement logical(1). setting TRUE user acknowledges data downloaded using function may large use lots machine storage memory. download logical(1). FALSE generate *.txt file containing download commands. setting TRUE function download requested data files. remove_command logical(1). Remove (TRUE) keep (FALSE) text file containing download commands. Default FALSE. unzip logical(1). Unzip zip files. Default TRUE. remove_zip logical(1). Remove zip file directory_to_download. Default FALSE. hash logical(1). setting TRUE function return rlang::hash_file() hash character corresponding downloaded files. Default FALSE.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_edgar.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Download EDGAR Emissions Data ‚Äî download_edgar","text":"list download URLs (character). Optionally downloads available files warns missing ones. hash = FALSE, NULL hash = TRUE, rlang::hash_file character. Zip /data files downloaded stored directory_to_save.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_edgar.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Download EDGAR Emissions Data ‚Äî download_edgar","text":"European Comission Joint Research Centre (2023). ‚ÄúEDGAR Global Air Pollutant Emissions Version 8.1.‚Äù https://edgar.jrc.ec.europa.eu/index.php/dataset_ap81.  European Comission Joint Research Centre (2025). ‚ÄúEmissions Database Global Atmospheric Research Global Speciated NMVOC Emissions Version 8.1.‚Äù https://edgar.jrc.ec.europa.eu/dataset_ap81_VOC_spec#sources. nolint end","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_edgar.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Download EDGAR Emissions Data ‚Äî download_edgar","text":"Mariana Alifa Kassien","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_edgar.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Download EDGAR Emissions Data ‚Äî download_edgar","text":"","code":"if (FALSE) { # \\dontrun{ download_edgar( species = \"CO\", acknowledgement = TRUE, temp_res = \"yearly\", sector_yearly = \"ENE\", year_range = c(2021, 2022) ) } # } if (FALSE) { # \\dontrun{ download_edgar( species = \"PM2.5\", acknowledgement = TRUE, temp_res = \"monthly\", sector_monthly = c(\"TRANSPORT\", \"WASTE\") ) } # } if (FALSE) { # \\dontrun{ download_edgar( species = \"SO2\", acknowledgement = TRUE, temp_res = \"timeseries\" ) } # }"},{"path":"https://niehs.github.io/amadeus/reference/download_epa_certificate.html","id":null,"dir":"Reference","previous_headings":"","what":"Check EPA certificate ‚Äî download_epa_certificate","title":"Check EPA certificate ‚Äî download_epa_certificate","text":"Check EPA certificate","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_epa_certificate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check EPA certificate ‚Äî download_epa_certificate","text":"","code":"download_epa_certificate(   epa_certificate_path = \"cacert_gaftp_epa.pem\",   certificate_url =     \"http://cacerts.digicert.com/DigiCertGlobalG2TLSRSASHA2562020CA1-1.crt\" )"},{"path":"https://niehs.github.io/amadeus/reference/download_epa_certificate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check EPA certificate ‚Äî download_epa_certificate","text":"epa_certificate_path character(1). Full path converted certificate EPA. end .pem certificate_url character(1). URL original certificate.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_epa_certificate.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check EPA certificate ‚Äî download_epa_certificate","text":"file designated epa_certificate_path","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_epa_certificate.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Check EPA certificate ‚Äî download_epa_certificate","text":"Insang Song","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_geos.html","id":null,"dir":"Reference","previous_headings":"","what":"Download atmospheric composition data ‚Äî download_geos","title":"Download atmospheric composition data ‚Äî download_geos","text":"download_geos() function accesses downloads various atmospheric composition collections NASA's Global Earth Observing System (GEOS) model.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_geos.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Download atmospheric composition data ‚Äî download_geos","text":"","code":"download_geos(   collection = c(\"aqc_tavg_1hr_g1440x721_v1\", \"chm_tavg_1hr_g1440x721_v1\",     \"met_tavg_1hr_g1440x721_x1\", \"xgc_tavg_1hr_g1440x721_x1\",     \"chm_inst_1hr_g1440x721_p23\", \"met_inst_1hr_g1440x721_p23\"),   date = c(\"2018-01-01\", \"2018-01-01\"),   directory_to_save = NULL,   acknowledgement = FALSE,   download = FALSE,   remove_command = FALSE,   hash = FALSE )"},{"path":"https://niehs.github.io/amadeus/reference/download_geos.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Download atmospheric composition data ‚Äî download_geos","text":"collection character(1). GEOS-CF data collection file name. date character(1 2). length 10. Date start/end dates downloading data. Format \"YYYY-MM-DD\" (ex. January 1, 2018 = \"2018-01-01\"). directory_to_save character(1). Directory save data. Sub-directories created within directory_to_save GEOS-CF collection. acknowledgement logical(1). setting TRUE user acknowledges data downloaded using function may large use lots machine storage memory. download logical(1). FALSE generate *.txt file containing download commands. setting TRUE function download requested data files. remove_command logical(1). Remove (TRUE) keep (FALSE) text file containing download commands. hash logical(1). setting TRUE function return rlang::hash_file() hash character corresponding downloaded files. Default FALSE.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_geos.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Download atmospheric composition data ‚Äî download_geos","text":"hash = FALSE, NULL hash = TRUE, rlang::hash_file character. netCDF (.nc4) files stored collection-specific folder within directory_to_save.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_geos.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Download atmospheric composition data ‚Äî download_geos","text":"Keller CA, Knowland KE, Duncan BN, Liu J, Anderson DC, Das S, Lucchesi RA, Lundgren EW, Nicely JM, Nielsen E, Ott LE, Saunders E, Strode SA, Wales PA, Jacob DJ, Pawson S (2021). ‚ÄúDescription NASA GEOS Composition Forecast Modeling System GEOS‚ÄêCF v1.0.‚Äù Journal Advances Modeling Earth Systems, 13(4), e2020MS002413. ISSN 1942-2466, 1942-2466, doi:10.1029/2020MS002413 .","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_geos.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Download atmospheric composition data ‚Äî download_geos","text":"Mitchell Manware, Insang Song","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_geos.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Download atmospheric composition data ‚Äî download_geos","text":"","code":"if (FALSE) { # \\dontrun{ download_geos(   collection = \"aqc_tavg_1hr_g1440x721_v1\",   date = \"2024-01-01\",   directory_to_save = tempdir(),   acknowledgement = TRUE,   download = FALSE, # NOTE: download skipped for examples,   remove_command = TRUE ) } # }"},{"path":"https://niehs.github.io/amadeus/reference/download_gmted.html","id":null,"dir":"Reference","previous_headings":"","what":"Download elevation data ‚Äî download_gmted","title":"Download elevation data ‚Äî download_gmted","text":"download_gmted() function accesses downloads Global Multi-resolution Terrain Elevation Data (GMTED2010) U.S. Geological Survey National Geospatial-Intelligence Agency.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_gmted.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Download elevation data ‚Äî download_gmted","text":"","code":"download_gmted(   statistic = c(\"Breakline Emphasis\", \"Systematic Subsample\", \"Median Statistic\",     \"Minimum Statistic\", \"Mean Statistic\", \"Maximum Statistic\",     \"Standard Deviation Statistic\"),   resolution = c(\"7.5 arc-seconds\", \"15 arc-seconds\", \"30 arc-seconds\"),   directory_to_save = NULL,   acknowledgement = FALSE,   download = FALSE,   remove_command = FALSE,   unzip = TRUE,   remove_zip = FALSE,   hash = FALSE )"},{"path":"https://niehs.github.io/amadeus/reference/download_gmted.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Download elevation data ‚Äî download_gmted","text":"statistic character(1). Available statistics include \"Breakline Emphasis\", \"Systematic Subsample\", \"Median Statistic\", \"Minimum Statistic\", \"Mean Statistic\", \"Maximum Statistic\", \"Standard Deviation Statistic\". resolution character(1). Available resolutions include \"7.5 arc-seconds\", \"15 arc-seconds\", \"30 arc-seconds\". directory_to_save character(1). Directory save data. Two sub-directories created downloaded zip files (\"/zip_files\") unzipped data files (\"/data_files\"). acknowledgement logical(1). setting TRUE user acknowledges data downloaded using function may large use lots machine storage memory. download logical(1). FALSE generate *.txt file containing download commands. setting TRUE function download requested data files. remove_command logical(1). Remove (TRUE) keep (FALSE) text file containing download commands. Default FALSE. unzip logical(1). Unzip zip files. Default TRUE. remove_zip logical(1). Remove zip file directory_to_download. Default FALSE. hash logical(1). setting TRUE function return rlang::hash_file() hash character corresponding downloaded files. Default FALSE.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_gmted.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Download elevation data ‚Äî download_gmted","text":"hash = FALSE, NULL hash = TRUE, rlang::hash_file character. Zip /data files downloaded stored directory_to_save.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_gmted.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Download elevation data ‚Äî download_gmted","text":"Danielson JJ, Gesch DB (2011). ‚ÄúGlobal multi-resolution terrain elevation data 2010 (GMTED2010).‚Äù Open-File Report 2011-1073, U.S. Geological Survey. Series: Open-File Report, https://doi.org/10.3133/ofr20111073.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_gmted.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Download elevation data ‚Äî download_gmted","text":"Mitchell Manware, Insang Song","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_gmted.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Download elevation data ‚Äî download_gmted","text":"","code":"if (FALSE) { # \\dontrun{ download_gmted(   statistic = \"Breakline Emphasis\",   resolution = \"7.5 arc-seconds\",   directory_to_save = tempdir(),   acknowledgement = TRUE,   download = FALSE, # NOTE: download skipped for examples,   remove_command = TRUE,   unzip = FALSE ) } # }"},{"path":"https://niehs.github.io/amadeus/reference/download_gridmet.html","id":null,"dir":"Reference","previous_headings":"","what":"Download gridMET data ‚Äî download_gridmet","title":"Download gridMET data ‚Äî download_gridmet","text":"download_gridmet function accesses downloads gridded surface meteorological data University California Merced Climatology Lab's gridMET dataset.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_gridmet.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Download gridMET data ‚Äî download_gridmet","text":"","code":"download_gridmet(   variables = NULL,   year = c(2018, 2022),   directory_to_save = NULL,   acknowledgement = FALSE,   download = FALSE,   remove_command = FALSE,   hash = FALSE )"},{"path":"https://niehs.github.io/amadeus/reference/download_gridmet.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Download gridMET data ‚Äî download_gridmet","text":"variables character(1). Variable(s) name(s). See gridMET Generate Wget File variable names acronym codes. (Note: variable \"Burning Index\" code \"bi\" variable \"Energy Release Component\" code \"erc\"). year integer(1 2). length 4. Year start/end years downloading data. directory_to_save character(1). Directory(s) save downloaded data files. acknowledgement logical(1). setting TRUE user acknowledges data downloaded using function may large use lots machine storage memory. download logical(1). FALSE generate *.txt file containing download commands. setting TRUE function download requested data files. remove_command logical(1). Remove (TRUE) keep (FALSE) text file containing download commands. hash logical(1). setting TRUE function return rlang::hash_file() hash character corresponding downloaded files. Default FALSE.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_gridmet.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Download gridMET data ‚Äî download_gridmet","text":"hash = FALSE, NULL hash = TRUE, rlang::hash_file character. netCDF (.nc) files stored variable-specific folder within directory_to_save.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_gridmet.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Download gridMET data ‚Äî download_gridmet","text":"Abatzoglou JT (2013). ‚ÄúDevelopment gridded surface meteorological data ecological applications modelling.‚Äù International journal climatology, 33(1), 121‚Äì131.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_gridmet.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Download gridMET data ‚Äî download_gridmet","text":"Mitchell Manware","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_gridmet.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Download gridMET data ‚Äî download_gridmet","text":"","code":"if (FALSE) { # \\dontrun{ download_gridmet(   variables = \"Precipitation\",   year = 2023,   directory_to_save = tempdir(),   acknowledgement = TRUE,   download = FALSE, # NOTE: download skipped for examples,   remove_command = TRUE ) } # }"},{"path":"https://niehs.github.io/amadeus/reference/download_groads.html","id":null,"dir":"Reference","previous_headings":"","what":"Download roads data ‚Äî download_groads","title":"Download roads data ‚Äî download_groads","text":"download_groads() function accesses downloads roads data NASA's Global Roads Open Access Data Set (gROADS), v1 (1980-2010).","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_groads.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Download roads data ‚Äî download_groads","text":"","code":"download_groads(   data_region = c(\"Americas\", \"Global\", \"Africa\", \"Asia\", \"Europe\", \"Oceania East\",     \"Oceania West\"),   data_format = c(\"Shapefile\", \"Geodatabase\"),   directory_to_save = NULL,   acknowledgement = FALSE,   download = FALSE,   remove_command = FALSE,   unzip = TRUE,   remove_zip = FALSE,   hash = FALSE )"},{"path":"https://niehs.github.io/amadeus/reference/download_groads.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Download roads data ‚Äî download_groads","text":"data_region character(1). Data can downloaded \"Global\", \"Africa\", \"Asia\", \"Europe\", \"Americas\", \"Oceania East\", \"Oceania West\". data_format character(1). Data can downloaded \"Shapefile\" \"Geodatabase\". (\"Geodatabase\" available \"Global\" region). directory_to_save character(1). Directory save data. Two sub-directories created downloaded zip files (\"/zip_files\") unzipped shapefiles (\"/data_files\"). acknowledgement logical(1). setting TRUE user acknowledges data downloaded using function may large use lots machine storage memory. download logical(1). FALSE generate *.txt file containing download commands. setting TRUE function download requested data files. remove_command logical(1). Remove (TRUE) keep (FALSE) text file containing download commands. unzip logical(1). Unzip zip files. Default TRUE. remove_zip logical(1). Remove zip files directory_to_download. Default FALSE. hash logical(1). setting TRUE function return rlang::hash_file() hash character corresponding downloaded files. Default FALSE.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_groads.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Download roads data ‚Äî download_groads","text":"hash = FALSE, NULL hash = TRUE, rlang::hash_file character. Zip /data files downloaded stored respective sub-directories within directory_to_save.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_groads.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Download roads data ‚Äî download_groads","text":"Center International Earth Science Information Network-CIESIN-Columbia University, Information Technology Outreach Services-ITOS-University Georgia (2013). ‚ÄúGlobal Roads Open Access Data Set, Version 1 (gROADSv1).‚Äù doi:10.7927/H4VD6WCT , https://data.nasa.gov/dataset/global-roads-open-access-data-set-version-1-groadsv1.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_groads.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Download roads data ‚Äî download_groads","text":"Mitchell Manware, Insang Song","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_groads.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Download roads data ‚Äî download_groads","text":"","code":"if (FALSE) { # \\dontrun{ download_groads(   data_region = \"Americas\",   data_format = \"Shapefile\",   directory_to_save = tempdir(),   acknowledgement = TRUE,   download = FALSE, # NOTE: download skipped for examples,   remove_command = TRUE,   unzip = FALSE ) } # }"},{"path":"https://niehs.github.io/amadeus/reference/download_hash.html","id":null,"dir":"Reference","previous_headings":"","what":"Create hash of downloaded files. ‚Äî download_hash","title":"Create hash of downloaded files. ‚Äî download_hash","text":"Create combined md5sum hash based files specified directory.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_hash.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create hash of downloaded files. ‚Äî download_hash","text":"","code":"download_hash(hash = TRUE, dir = NULL)"},{"path":"https://niehs.github.io/amadeus/reference/download_hash.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create hash of downloaded files. ‚Äî download_hash","text":"hash logical(1). Create hash downloaded files. dir character(1). Directory path.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_hash.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create hash of downloaded files. ‚Äî download_hash","text":"character(1) Combined 128-bit md5sum download files.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_hms.html","id":null,"dir":"Reference","previous_headings":"","what":"Download wildfire smoke data ‚Äî download_hms","title":"Download wildfire smoke data ‚Äî download_hms","text":"download_hms() function accesses downloads wildfire smoke plume coverage data NOAA's Hazard Mapping System Fire Smoke Product.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_hms.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Download wildfire smoke data ‚Äî download_hms","text":"","code":"download_hms(   data_format = \"Shapefile\",   date = c(\"2018-01-01\", \"2018-01-01\"),   directory_to_save = NULL,   acknowledgement = FALSE,   download = FALSE,   remove_command = FALSE,   unzip = TRUE,   remove_zip = FALSE,   hash = FALSE )"},{"path":"https://niehs.github.io/amadeus/reference/download_hms.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Download wildfire smoke data ‚Äî download_hms","text":"data_format character(1). \"Shapefile\" \"KML\". date character(1 2). length 10. Date start/end dates downloading data. Format \"YYYY-MM-DD\" (ex. January 1, 2018 = \"2018-01-01\"). NOAA HMS data available August 5, 2005 present day. Data unavailable August 10, 2005. directory_to_save character(1). Directory save data. data_format = \"Shapefile\", two sub-directories created downloaded zip files (\"/zip_files\") unzipped shapefiles (\"/data_files\"). data_format = \"KML\", single sub-directory (\"/data_files\") created. acknowledgement logical(1). setting TRUE user acknowledges data downloaded using function may large use lots machine storage memory. download logical(1). FALSE generate *.txt file containing download commands. setting TRUE function download requested data files. remove_command logical(1). Remove (TRUE) keep (FALSE) text file containing download commands. unzip logical(1). Unzip zip files. Default TRUE. (Ignored data_format = \"KML\".) remove_zip logical(1). Remove zip files directory_to_download. Default FALSE. (Ignored data_format = \"KML\".) hash logical(1). setting TRUE function return rlang::hash_file() hash character corresponding downloaded files. Default FALSE.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_hms.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Download wildfire smoke data ‚Äî download_hms","text":"hash = FALSE, NULL hash = TRUE, rlang::hash_file character. Zip /data files downloaded stored respective sub-directories within directory_to_save.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_hms.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Download wildfire smoke data ‚Äî download_hms","text":"(????). ‚ÄúHazard Mapping System Fire Smoke Product: Hazard Mapping System.‚Äù https://www.ospo.noaa.gov/products/land/hms.html#. https://www.ospo.noaa.gov/products/land/hms.html#.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_hms.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Download wildfire smoke data ‚Äî download_hms","text":"Mitchell Manware, Insang Song","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_hms.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Download wildfire smoke data ‚Äî download_hms","text":"","code":"if (FALSE) { # \\dontrun{ download_hms(   data_format = \"Shapefile\",   date = \"2024-01-01\",   directory_to_save = tempdir(),   acknowledgement = TRUE,   download = FALSE, # NOTE: download skipped for examples,   remove_command = TRUE,   unzip = FALSE ) } # }"},{"path":"https://niehs.github.io/amadeus/reference/download_huc.html","id":null,"dir":"Reference","previous_headings":"","what":"Download National Hydrography Dataset (NHD) data ‚Äî download_huc","title":"Download National Hydrography Dataset (NHD) data ‚Äî download_huc","text":"NHDPlus data provides comprehensive high-resolution hydrography data. function downloads national dataset NHDPlus Version 2.1 USGS Amazon S3 storage.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_huc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Download National Hydrography Dataset (NHD) data ‚Äî download_huc","text":"","code":"download_huc(   region = c(\"Lower48\", \"Islands\"),   type = c(\"Seamless\", \"OceanCatchment\"),   directory_to_save = NULL,   acknowledgement = FALSE,   download = FALSE,   remove_command = FALSE,   unzip = FALSE,   hash = FALSE )"},{"path":"https://niehs.github.io/amadeus/reference/download_huc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Download National Hydrography Dataset (NHD) data ‚Äî download_huc","text":"region character(1). One c(\"Lower48\", \"Islands\"). \"Islands\" selected, data downloaded Hawaii, Puerto Rico, Virgin Islands. type character(1). One c(\"Seamless\", \"OceanCatchment\"). directory_to_save character(1). Directory download files. acknowledgement logical(1). setting TRUE user acknowledges data downloaded using function may large use lots machine storage memory. download logical(1). FALSE generate *.txt file containing download commands. setting TRUE function download requested data files. remove_command logical(1). Remove (TRUE) keep (FALSE) text file containing download commands. unzip logical(1). Unzip downloaded compressed files. Default FALSE. working function since HUC data 7z format. hash logical(1). setting TRUE function return rlang::hash_file() hash character corresponding downloaded files. Default FALSE.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_huc.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Download National Hydrography Dataset (NHD) data ‚Äî download_huc","text":"hash = FALSE, NULL hash = TRUE, rlang::hash_file character. Downloaded files stored directory_to_save.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_huc.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Download National Hydrography Dataset (NHD) data ‚Äî download_huc","text":"HUC, set type = \"Seamless\". HUC12 layer presents seamless geodatabase. Users can aggregate HUC12 layer make HUC6, HUC8, HUC10, etc. wants download specific region, please visit Get NHDPlus Data","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_huc.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Download National Hydrography Dataset (NHD) data ‚Äî download_huc","text":"U.S. Geological Survey (2023). ‚ÄúNational Hydrography Dataset (NHD) ‚Äì USGS National Map Downloadable Data Collection.‚Äù https://www.usgs.gov/national-hydrography.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_huc.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Download National Hydrography Dataset (NHD) data ‚Äî download_huc","text":"Insang Song","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_huc.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Download National Hydrography Dataset (NHD) data ‚Äî download_huc","text":"","code":"if (FALSE) { # \\dontrun{ download_huc(   region = \"Lower48\",   type = \"Seamless\",   directory_to_save = tempdir(),   acknowledgement = TRUE,   download = FALSE, # NOTE: download skipped for examples,   remove_command = TRUE,   unzip = FALSE ) } # }"},{"path":"https://niehs.github.io/amadeus/reference/download_koppen_geiger.html","id":null,"dir":"Reference","previous_headings":"","what":"Download climate classification data ‚Äî download_koppen_geiger","title":"Download climate classification data ‚Äî download_koppen_geiger","text":"download_koppen_geiger() function accesses downloads climate classification data Present future K√∂ppen-Geiger climate classification maps 1-km resolution(link article; link data).","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_koppen_geiger.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Download climate classification data ‚Äî download_koppen_geiger","text":"","code":"download_koppen_geiger(   data_resolution = c(\"0.0083\", \"0.083\", \"0.5\"),   time_period = c(\"Present\", \"Future\"),   directory_to_save = NULL,   acknowledgement = FALSE,   download = FALSE,   remove_command = FALSE,   unzip = TRUE,   remove_zip = FALSE,   hash = FALSE )"},{"path":"https://niehs.github.io/amadeus/reference/download_koppen_geiger.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Download climate classification data ‚Äî download_koppen_geiger","text":"data_resolution character(1). Available resolutions \"0.0083\" degrees (approx. 1 km), \"0.083\" degrees (approx. 10 km), \"0.5\" degrees (approx. 50 km). time_period character(1). Available times \"Present\" (1980-2016) \"Future\" (2071-2100). (\"Future\" classifications based scenario RCP8.5). directory_to_save character(1). Directory save data. Two sub-directories created downloaded zip files (\"/zip_files\") unzipped shapefiles (\"/data_files\"). acknowledgement logical(1). setting TRUE user acknowledges data downloaded using function may large use lots machine storage memory. download logical(1). FALSE generate *.txt file containing download commands. setting TRUE function download requested data files. remove_command logical(1). Remove (TRUE) keep (FALSE) text file containing download commands. unzip logical(1). Unzip zip files. Default TRUE. remove_zip logical(1). Remove zip files directory_to_download. Default FALSE. hash logical(1). setting TRUE function return rlang::hash_file() hash character corresponding downloaded files. Default FALSE.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_koppen_geiger.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Download climate classification data ‚Äî download_koppen_geiger","text":"hash = FALSE, NULL hash = TRUE, rlang::hash_file character. Zip /data files downloaded stored respective sub-directories within directory_to_save.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_koppen_geiger.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Download climate classification data ‚Äî download_koppen_geiger","text":"Beck , McVicar TR, Vergopolan N, Berg , Lutsko NJ, Dufour , Zeng Z, Jiang X, Van Dijk AIJM, Miralles DG (2023). ‚ÄúHigh-resolution (1 km) K√∂ppen-Geiger maps 1901‚Äì2099 based constrained CMIP6 projections.‚Äù Scientific Data, 10(1), 724. ISSN 2052-4463, doi:10.1038/s41597-023-02549-6 , https://www.nature.com/articles/s41597-023-02549-6. Beck , Zimmermann NE, McVicar TR, Vergopolan N, Berg , Wood EF (2018). ‚ÄúPresent future K√∂ppen-Geiger climate classification maps 1-km resolution.‚Äù Scientific data, 5(1), 1‚Äì12. doi:10.1038/sdata.2018.214 .","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_koppen_geiger.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Download climate classification data ‚Äî download_koppen_geiger","text":"Mitchell Manware, Insang Song","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_koppen_geiger.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Download climate classification data ‚Äî download_koppen_geiger","text":"","code":"if (FALSE) { # \\dontrun{ download_koppen_geiger(   data_resolution = \"0.0083\",   time_period = \"Present\",   directory_to_save = tempdir(),   acknowledgement = TRUE,   download = FALSE, # NOTE: download skipped for examples,   remove_command = TRUE,   unzip = FALSE ) } # }"},{"path":"https://niehs.github.io/amadeus/reference/download_merra2.html","id":null,"dir":"Reference","previous_headings":"","what":"Download meteorological and atmospheric data ‚Äî download_merra2","title":"Download meteorological and atmospheric data ‚Äî download_merra2","text":"download_merra2() function accesses downloads various meteorological atmospheric collections NASA's Modern-Era Retrospective analysis Research Applications, Version 2 (MERRA-2) model.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_merra2.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Download meteorological and atmospheric data ‚Äî download_merra2","text":"","code":"download_merra2(   collection = c(\"inst1_2d_asm_Nx\", \"inst1_2d_int_Nx\", \"inst1_2d_lfo_Nx\",     \"inst3_3d_asm_Np\", \"inst3_3d_aer_Nv\", \"inst3_3d_asm_Nv\", \"inst3_3d_chm_Nv\",     \"inst3_3d_gas_Nv\", \"inst3_2d_gas_Nx\", \"inst6_3d_ana_Np\", \"inst6_3d_ana_Nv\",     \"statD_2d_slv_Nx\", \"tavg1_2d_adg_Nx\", \"tavg1_2d_aer_Nx\", \"tavg1_2d_chm_Nx\",     \"tavg1_2d_csp_Nx\", \"tavg1_2d_flx_Nx\", \"tavg1_2d_int_Nx\", \"tavg1_2d_lfo_Nx\",     \"tavg1_2d_lnd_Nx\", \"tavg1_2d_ocn_Nx\", \"tavg1_2d_rad_Nx\", \"tavg1_2d_slv_Nx\",     \"tavg3_3d_mst_Ne\", \"tavg3_3d_trb_Ne\", \"tavg3_3d_nav_Ne\", \"tavg3_3d_cld_Np\",           \"tavg3_3d_mst_Np\", \"tavg3_3d_rad_Np\", \"tavg3_3d_tdt_Np\", \"tavg3_3d_trb_Np\",     \"tavg3_3d_udt_Np\", \"tavg3_3d_odt_Np\", \"tavg3_3d_qdt_Np\", \"tavg3_3d_asm_Nv\",     \"tavg3_3d_cld_Nv\", \"tavg3_3d_mst_Nv\", \"tavg3_3d_rad_Nv\", \"tavg3_2d_glc_Nx\"),   date = c(\"2018-01-01\", \"2018-01-01\"),   directory_to_save = NULL,   acknowledgement = FALSE,   download = FALSE,   remove_command = FALSE,   hash = FALSE )"},{"path":"https://niehs.github.io/amadeus/reference/download_merra2.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Download meteorological and atmospheric data ‚Äî download_merra2","text":"collection character(1). MERRA-2 data collection file name. date character(1 2). length 10. Date start/end dates downloading data. Format \"YYYY-MM-DD\" (ex. January 1, 2018 = \"2018-01-01\"). directory_to_save character(1). Directory save data. acknowledgement logical(1). setting TRUE user acknowledges data downloaded using function may large use lots machine storage memory. download logical(1). FALSE generate *.txt file containing download commands. setting TRUE function download requested data files. remove_command logical(1). Remove (TRUE) keep (FALSE). hash logical(1). setting TRUE function return rlang::hash_file() hash character corresponding downloaded files. Default FALSE. text file containing download commands.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_merra2.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Download meteorological and atmospheric data ‚Äî download_merra2","text":"hash = FALSE, NULL hash = TRUE, rlang::hash_file character. netCDF (.nc4) files stored collection-specific folder within directory_to_save.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_merra2.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Download meteorological and atmospheric data ‚Äî download_merra2","text":"Global Modeling Assimilation Office, Pawson S (2015). ‚ÄúMERRA-2 inst1_2d_ asm_ Nx: 2d,3-Hourly,Instantaneous,Single-Level,Assimilation,Single-Level Diagnostics V5.12.4.‚Äù doi:10.5067/3Z173KIE2TPD , https://disc.gsfc.nasa.gov/datasets/M2I1NXASM_5.12.4/summary. Global Modeling Assimilation Office, Pawson S (2015). ‚ÄúMERRA-2 inst1_2d_ int_ Nx: 2d,1-Hourly,Instantaneous,Single-Level,Assimilation,Vertically Integrated Diagnostics V5.12.4.‚Äù doi:10.5067/G0U6NGQ3BLE0 , https://disc.gsfc.nasa.gov/datasets/M2I1NXINT_5.12.4/summary. Global Modeling Assimilation Office, Pawson S (2015). ‚ÄúMERRA-2 inst1_2d_ lfo_ Nx: 2d,1-Hourly,Instantaneous,Single-Level,Assimilation,Land Surface Forcings V5.12.4.‚Äù doi:10.5067/RCMZA6TL70BG , https://disc.gsfc.nasa.gov/datasets/M2I1NXLFO_5.12.4/summary. Global Modeling Assimilation Office, Pawson S (2015). ‚ÄúMERRA-2 inst3_3d_ asm_ Np: 3d,3-Hourly,Instantaneous,Pressure-Level,Assimilation,Assimilated Meteorological Fields V5.12.4.‚Äù doi:10.5067/QBZ6MG944HW0 , https://disc.gsfc.nasa.gov/datasets/M2I3NPASM_5.12.4/summary. Global Modeling Assimilation Office, Pawson S (2015). ‚ÄúMERRA-2 inst3_3d_ aer_ Nv: 3d,3-Hourly,Instantaneous,Model-Level,Assimilation,Aerosol Mixing Ratio V5.12.4.‚Äù doi:10.5067/LTVB4GPCOTK2 , https://disc.gsfc.nasa.gov/datasets/M2I3NVAER_5.12.4/summary. Global Modeling Assimilation Office, Pawson S (2015). ‚ÄúMERRA-2 inst3_3d_ asm_ Nv: 3d,3-Hourly,Instantaneous,Model-Level,Assimilation,Assimilated Meteorological Fields V5.12.4.‚Äù doi:10.5067/WWQSXQ8IVFW8 , https://disc.gsfc.nasa.gov/datasets/M2I3NVASM_5.12.4/summary. Global Modeling Assimilation Office, Pawson S (2015). ‚ÄúMERRA-2 inst3_3d_ chm_ Nv: 3d,3-Hourly,Instantaneous,Model-Level,Assimilation,Carbon Monoxide Ozone Mixing Ratio V5.12.4.‚Äù doi:10.5067/HO9OVZWF3KW2 , https://disc.gsfc.nasa.gov/datasets/M2I3NVCHM_5.12.4/summary. Global Modeling Assimilation Office, Pawson S (2015). ‚ÄúMERRA-2 inst3_3d_ gas_ Nv: 3d,3-Hourly,Instantaneous,Model-Level,Assimilation,Aerosol Mixing Ratio Analysis Increments V5.12.4.‚Äù doi:10.5067/96BUID8HGGX5 , https://disc.gsfc.nasa.gov/datasets/M2I3NVGAS_5.12.4/summary. Global Modeling Assimilation Office, Pawson S (2015). ‚ÄúMERRA-2 inst3_2d_ gas_ Nx: 2d,3-Hourly,Instantaneous,Single-Level,Assimilation,Aerosol Optical Depth Analysis V5.12.4.‚Äù doi:10.5067/HNGA0EWW0R09 , https://disc.gsfc.nasa.gov/datasets/M2I3NXGAS_5.12.4/summary. Global Modeling Assimilation Office, Pawson S (2015). ‚ÄúMERRA-2 inst6_3d_ ana_ Np: 3d,6-Hourly,Instantaneous,Pressure-Level,Analysis,Analyzed Meteorological Fields V5.12.4.‚Äù doi:10.5067/A7S6XP56VZWS , https://disc.gsfc.nasa.gov/datasets/M2I6NPANA_5.12.4/summary. Global Modeling Assimilation Office, Pawson S (2015). ‚ÄúMERRA-2 inst6_3d_ ana_ Nv: 3d,6-Hourly,Instantaneous,Model-Level,Analysis,Analyzed Meteorological Fields V5.12.4.‚Äù doi:10.5067/IUUF4WB9FT4W , https://disc.gsfc.nasa.gov/datasets/M2I6NVANA_5.12.4/summary. Global Modeling Assimilation Office, Pawson S (2015). ‚ÄúMERRA-2 statD_2d_ slv_ Nx: 2d,Monthly,Aggregated Statistics,Single-Level,Assimilation,Single-Level Diagnostics V5.12.4.‚Äù doi:10.5067/KVIMOMCUO83U , https://disc.gsfc.nasa.gov/datasets/M2SMNXSLV_5.12.4/summary. Global Modeling Assimilation Office, Pawson S (2015). ‚ÄúMERRA-2 statD_2d_ slv_ Nx: 2d,Daily,Aggregated Statistics,Single-Level,Assimilation,Single-Level Diagnostics V5.12.4.‚Äù doi:10.5067/9SC1VNTWGWV3 , https://disc.gsfc.nasa.gov/datasets/M2SDNXSLV_5.12.4/summary. Global Modeling Assimilation Office, Pawson S (2015). ‚ÄúMERRA-2 tavg1_2d_ adg_ Nx: 2d,3-Hourly,Time-averaged,Single-Level,Assimilation,Aerosol Diagnostics (extended) V5.12.4.‚Äù doi:10.5067/HM00OHQBHKTP , https://disc.gsfc.nasa.gov/datasets/M2T1NXADG_5.12.4/summary. Global Modeling Assimilation Office, Pawson S (2015). ‚ÄúMERRA-2 tavg1_2d_ aer_ Nx: 2d,1-Hourly,Time-averaged,Single-Level,Assimilation,Aerosol Diagnostics V5.12.4.‚Äù doi:10.5067/KLICLTZ8EM9D , https://disc.gsfc.nasa.gov/datasets/M2T1NXAER_5.12.4/summary. Global Modeling Assimilation Office, Pawson S (2015). ‚ÄúMERRA-2 tavg1_2d_ chm_ Nx: 2d,3-Hourly,Time-Averaged,Single-Level,Assimilation,Carbon Monoxide Ozone Diagnostics V5.12.4.‚Äù doi:10.5067/3RQ5YS674DGQ , https://disc.gsfc.nasa.gov/datasets/M2T1NXCHM_5.12.4/summary. Global Modeling Assimilation Office, Pawson S (2015). ‚ÄúMERRA-2 tavg1_2d_ csp_ Nx: 2d,1-Hourly,Time-averaged,Single-Level,Assimilation,COSP Satellite Simulator V5.12.4.‚Äù doi:10.5067/H0VVAD8F6MX5 , https://disc.gsfc.nasa.gov/datasets/M2T1NXCSP_5.12.4/summary. Global Modeling Assimilation Office, Pawson S (2015). ‚ÄúMERRA-2 tavg1_2d_ flx_ Nx: 2d,1-Hourly,Time-Averaged,Single-Level,Assimilation,Surface Flux Diagnostics V5.12.4.‚Äù doi:10.5067/7MCPBJ41Y0K6 , https://disc.gsfc.nasa.gov/datasets/M2T1NXFLX_5.12.4/summary. Global Modeling Assimilation Office, Pawson S (2015). ‚ÄúMERRA-2 tavg1_2d_ int_ Nx: 2d,1-Hourly,Time-averaged,Single-Level,Assimilation,Vertically Integrated Diagnostics V5.12.4.‚Äù doi:10.5067/Q5GVUVUIVGO7 , https://disc.gsfc.nasa.gov/datasets/M2T1NXINT_5.12.4/summary. Pawson S (2020). ‚ÄúMERRA-2 tavg1_2d_ lfo_ Nx: 2d,1-Hourly,Time-Averaged,Single-Level,Assimilation,Land Surface Forcings V5.12.4.‚Äù doi:10.5067/L0T5GEG1NYFA , https://disc.gsfc.nasa.gov/datasets/M2T1NXLFO_5.12.4/summary. Global Modeling Assimilation Office, Pawson S (2015). ‚ÄúMERRA-2 tavg1_2d_ lnd_ Nx: 2d,1-Hourly,Time-Averaged,Single-Level,Assimilation,Land Surface Diagnostics V5.12.4.‚Äù doi:10.5067/RKPHT8KC1Y1T , https://disc.gsfc.nasa.gov/datasets/M2T1NXLND_5.12.4/summary. Global Modeling Assimilation Office, Pawson S (2015). ‚ÄúMERRA-2 tavg1_2d_ ocn_ Nx: 2d,1-Hourly,Time-Averaged,Single-Level,Assimilation,Ocean Surface Diagnostics V5.12.4.‚Äù doi:10.5067/Y67YQ1L3ZZ4R , https://disc.gsfc.nasa.gov/datasets/M2T1NXOCN_5.12.4/summary. Global Modeling Assimilation Office, Pawson S (2015). ‚ÄúMERRA-2 tavg1_2d_ rad_ Nx: 2d,1-Hourly,Time-Averaged,Single-Level,Assimilation,Radiation Diagnostics V5.12.4.‚Äù doi:10.5067/Q9QMY5PBNV1T , https://disc.gsfc.nasa.gov/datasets/M2T1NXRAD_5.12.4/summary. Global Modeling Assimilation Office, Pawson S (2015). ‚ÄúMERRA-2 tavg1_2d_ slv_ Nx: 2d,1-Hourly,Time-Averaged,Single-Level,Assimilation,Single-Level Diagnostics V5.12.4.‚Äù doi:10.5067/VJAFPLI1CSIV , https://disc.gsfc.nasa.gov/datasets/M2T1NXSLV_5.12.4/summary. Global Modeling Assimilation Office, Pawson S (2015). ‚ÄúMERRA-2 tavg3_3d_ mst_ Ne: 3d,3-Hourly,Time-Averaged,Model-Level Edge,Assimilation,Moist Processes Diagnostics V5.12.4.‚Äù doi:10.5067/JRUZ3SJ3ZJ72 , https://disc.gsfc.nasa.gov/datasets/M2T3NEMST_5.12.4/summary. Global Modeling Assimilation Office, Pawson S (2015). ‚ÄúMERRA-2 tavg3_3d_ trb_ Ne: 3d,3-Hourly,Time-Averaged,Model-Level Edge,Assimilation,Turbulence Diagnostics V5.12.4.‚Äù doi:10.5067/4I7ZI35QRH8K , https://disc.gsfc.nasa.gov/datasets/M2T3NETRB_5.12.4/summary. Global Modeling Assimilation Office, Pawson S (2015). ‚ÄúMERRA-2 tavg3_3d_ nav_ Ne: 3d,3-Hourly,Time-Averaged, Vertical Coordinates V5.12.4.‚Äù doi:10.5067/N5WAKNS1UYQN , https://disc.gsfc.nasa.gov/datasets/M2T3NENAV_5.12.4/summary. Global Modeling Assimilation Office, Pawson S (2015). ‚ÄúMERRA-2 tavg3_3d_ cld_ Np: 3d,3-Hourly,Time-Averaged,Pressure-Level,Assimilation,Cloud Diagnostics V5.12.4.‚Äù doi:10.5067/TX10URJSKT53 , https://disc.gsfc.nasa.gov/datasets/M2T3NPCLD_5.12.4/summary. Global Modeling Assimilation Office, Pawson S (2015). ‚ÄúMERRA-2 tavg3_3d_ mst_ Np: 3d,3-Hourly,Time-Averaged,Pressure-Level,Assimilation,Moist Processes Diagnostics V5.12.4.‚Äù doi:10.5067/0TUFO90Q2PMS , https://disc.gsfc.nasa.gov/datasets/M2T3NPMST_5.12.4/summary. Global Modeling Assimilation Office, Pawson S (2015). ‚ÄúMERRA-2 tavg3_3d_ rad_ Np: 3d,3-Hourly,Time-Averaged,Pressure-Level,Assimilation,Radiation Diagnostics V5.12.4.‚Äù doi:10.5067/3UGE8WQXZAOK , https://disc.gsfc.nasa.gov/datasets/M2T3NPRAD_5.12.4/summary. Global Modeling Assimilation Office, Pawson S (2015). ‚ÄúMERRA-2 tavg3_3d_ tdt_ Np: 3d,3-Hourly,Time-Averaged,Pressure-Level,Assimilation,Temperature Tendencies V5.12.4.‚Äù doi:10.5067/9NCR9DDDOPFI , https://disc.gsfc.nasa.gov/datasets/M2T3NPTDT_5.12.4/summary. Global Modeling Assimilation Office, Pawson S (2015). ‚ÄúMERRA-2 tavg3_3d_ trb_ Np: 3d,3-Hourly,Time-Averaged,Pressure-Level,Assimilation,Turbulence Diagnostics V5.12.4.‚Äù doi:10.5067/ZRRJPGWL8AVL , https://disc.gsfc.nasa.gov/datasets/M2T3NPTRB_5.12.4/summary. Global Modeling Assimilation Office, Pawson S (2015). ‚ÄúMERRA-2 tavg3_3d_ udt_ Np: 3d,3-Hourly,Time-Averaged,Pressure-Level,Assimilation,Wind Tendencies V5.12.4.‚Äù doi:10.5067/CWV0G3PPPWFW , https://disc.gsfc.nasa.gov/datasets/M2T3NPUDT_5.12.4/summary. Global Modeling Assimilation Office, Pawson S (2015). ‚ÄúMERRA-2 tavg3_3d_ odt_ Np: 3d,3-Hourly,Time-Averaged,Pressure-Level,Assimilation,Ozone Tendencies V5.12.4.‚Äù doi:10.5067/S0LYTK57786Z , https://disc.gsfc.nasa.gov/datasets/M2T3NPODT_5.12.4/summary. Global Modeling Assimilation Office, Pawson S (2015). ‚ÄúMERRA-2 tavg3_3d_ qdt_ Np: 3d,3-Hourly,Time-Averaged,Pressure-Level,Assimilation,Moist Tendencies V5.12.4.‚Äù doi:10.5067/A9KWADY78YHQ , https://disc.gsfc.nasa.gov/datasets/M2T3NPQDT_5.12.4/summary. Global Modeling Assimilation Office, Pawson S (2015). ‚ÄúMERRA-2 tavg3_3d_ asm_ Nv: 3d,3-Hourly,Time-Averaged,Model-Level,Assimilation,Assimilated Meteorological Fields V5.12.4.‚Äù doi:10.5067/SUOQESM06LPK , https://disc.gsfc.nasa.gov/datasets/M2T3NVASM_5.12.4/summary. Global Modeling Assimilation Office, Pawson S (2015). ‚ÄúMERRA-2 tavg3_3d_ cld_ Nv: 3d,3-Hourly,Time-Averaged,Model-Level,Assimilation,Cloud Diagnostics V5.12.4.‚Äù doi:10.5067/F9353J0FAHIH , https://disc.gsfc.nasa.gov/datasets/M2T3NVCLD_5.12.4/summary. Global Modeling Assimilation Office, Pawson S (2015). ‚ÄúMERRA-2 tavg3_3d_ mst_ Nv: 3d,3-Hourly,Time-Averaged,Model-Level,Assimilation,Moist Processes Diagnostics V5.12.4.‚Äù doi:10.5067/ZXTJ28TQR1TR , https://disc.gsfc.nasa.gov/datasets/M2T3NVMST_5.12.4/summary. Global Modeling Assimilation Office, Pawson S (2015). ‚ÄúMERRA-2 tavg3_3d_ rad_ Nv: 3d,3-Hourly,Time-Averaged,Model-Level,Assimilation,Radiation Diagnostics V5.12.4.‚Äù doi:10.5067/7GFQKO1T43RW , https://disc.gsfc.nasa.gov/datasets/M2T3NVRAD_5.12.4/summary. Global Modeling Assimilation Office, Pawson S (2015). ‚ÄúMERRA-2 tavg3_2d_ glc_ Nx: 2d,3-Hourly,Time-Averaged,Single-Level,Assimilation,Land Ice Surface Diagnostics V5.12.4.‚Äù doi:10.5067/9ETB4TT5J6US , https://disc.gsfc.nasa.gov/datasets/M2T3NXGLC_5.12.4/summary. Global Modeling Assimilation Office, Pawson S (2015). ‚ÄúMERRA-2 instM_2d_ asm_ Nx: 2d,Monthly mean,Single-Level,Assimilation,Single-Level Diagnostics V5.12.4.‚Äù doi:10.5067/5ESKGQTZG7FO , https://disc.gsfc.nasa.gov/datasets/M2IMNXASM_5.12.4/summary. Global Modeling Assimilation Office, Pawson S (2015). ‚ÄúMERRA-2 instM_2d_ int_ Nx: 2d,Monthly mean,Instantaneous,Single-Level,Assimilation,Vertically Integrated Diagnostics V5.12.4.‚Äù doi:10.5067/KVTU1A8BWFSJ , https://disc.gsfc.nasa.gov/datasets/M2IMNXINT_5.12.4/summary. Global Modeling Assimilation Office, Pawson S (2015). ‚ÄúMERRA-2 instM_2d_ lfo_ Nx: 2d,Monthly mean,Instantaneous,Single-Level,Assimilation,Land Surface Forcings V5.12.4.‚Äù doi:10.5067/11F99Y6TXN99 , https://disc.gsfc.nasa.gov/datasets/M2IMNXLFO_5.12.4/summary. Global Modeling Assimilation Office, Pawson S (2015). ‚ÄúMERRA-2 instM_2d_ gas_ Nx: 2d,Monthly mean,Instantaneous,Single-Level,Assimilation,Aerosol Optical Depth Analysis V5.12.4.‚Äù doi:10.5067/XOGNBQEPLUC5 , https://disc.gsfc.nasa.gov/datasets/M2IMNXGAS_5.12.4/summary. Global Modeling Assimilation Office, Pawson S (2015). ‚ÄúMERRA-2 instM_3d_ asm_ Np: 3d,Monthly mean,Instantaneous,Pressure-Level,Assimilation,Assimilated Meteorological Fields V5.12.4.‚Äù doi:10.5067/2E096JV59PK7 , https://disc.gsfc.nasa.gov/datasets/M2IMNPASM_5.12.4/summary. Global Modeling Assimilation Office, Pawson S (2015). ‚ÄúMERRA-2 instM_3d_ ana_ Np: 3d,Monthly mean,Instantaneous,Pressure-Level,Analysis,Analyzed Meteorological Fields V5.12.4.‚Äù doi:10.5067/V92O8XZ30XBI , https://disc.gsfc.nasa.gov/datasets/M2IMNPANA_5.12.4/summary. Global Modeling Assimilation Office, Pawson S (2015). ‚ÄúMERRA-2 tavgM_2d_ adg_ Nx: 2d,Monthly mean,Time-averaged,Single-Level,Assimilation,Aerosol Diagnostics (extended) V5.12.4.‚Äù doi:10.5067/RZIK2TV7PP38 , https://disc.gsfc.nasa.gov/datasets/M2TMNXADG_5.12.4/summary. Global Modeling Assimilation Office, Pawson S (2015). ‚ÄúMERRA-2 tavgM_2d_ aer_ Nx: 2d,Monthly mean,Time-averaged,Single-Level,Assimilation,Aerosol Diagnostics V5.12.4.‚Äù doi:10.5067/FH9A0MLJPC7N , https://disc.gsfc.nasa.gov/datasets/M2TMNXAER_5.12.4/summary. Global Modeling Assimilation Office, Pawson S (2015). ‚ÄúMERRA-2 tavgM_2d_ chm_ Nx: 2d,Monthly mean,Time-Averaged,Single-Level,Assimilation,Carbon Monoxide Ozone Diagnostics V5.12.4.‚Äù doi:10.5067/WMT31RKEXK8I , https://disc.gsfc.nasa.gov/datasets/M2TMNXCHM_5.12.4/summary. Global Modeling Assimilation Office, Pawson S (2015). ‚ÄúMERRA-2 tavgM_2d_ csp_ Nx: 2d,Monthly mean,Time-averaged,Single-Level,Assimilation,COSP Satellite Simulator V5.12.4.‚Äù doi:10.5067/BZPOTGJOQKLU , https://disc.gsfc.nasa.gov/datasets/M2TMNXCSP_5.12.4/summary. Global Modeling Assimilation Office, Pawson S (2015). ‚ÄúMERRA-2 tavgM_2d_ flx_ Nx: 2d,Monthly mean,Time-Averaged,Single-Level,Assimilation,Surface Flux Diagnostics V5.12.4.‚Äù doi:10.5067/0JRLVL8YV2Y4 , https://disc.gsfc.nasa.gov/datasets/M2TMNXFLX_5.12.4/summary. Global Modeling Assimilation Office, Pawson S (2015). ‚ÄúMERRA-2 tavgM_2d_ int_ Nx: 2d,Monthly mean,Time-Averaged,Single-Level,Assimilation,Vertically Integrated Diagnostics V5.12.4.‚Äù doi:10.5067/FQPTQ4OJ22TL , https://disc.gsfc.nasa.gov/datasets/M2TMNXINT_5.12.4/summary. Global Modeling Assimilation Office, Pawson S (2015). ‚ÄúMERRA-2 tavgM_2d_ lfo_ Nx: 2d,Monthly mean,Time-Averaged,Single-Level,Assimilation,Land Surface Forcings V5.12.4.‚Äù doi:10.5067/5V7K6LJD44SY , https://disc.gsfc.nasa.gov/datasets/M2TMNXLFO_5.12.4/summary. Global Modeling Assimilation Office, Pawson S (2015). ‚ÄúMERRA-2 tavgM_2d_ lnd_ Nx: 2d,Monthly mean,Time-Averaged,Single-Level,Assimilation,Land Surface Diagnostics V5.12.4.‚Äù doi:10.5067/8S35XF81C28F , https://disc.gsfc.nasa.gov/datasets/M2TMNXLND_5.12.4/summary. Global Modeling Assimilation Office, Pawson S (2015). ‚ÄúMERRA-2 tavgM_2d_ ocn_ Nx: 2d,Monthly mean,Time-Averaged,Single-Level,Assimilation,Ocean Surface Diagnostics V5.12.4.‚Äù doi:10.5067/4IASLIDL8EEC , https://disc.gsfc.nasa.gov/datasets/M2TMNXOCN_5.12.4/summary. Global Modeling Assimilation Office, Pawson S (2015). ‚ÄúMERRA-2 tavgM_2d_ rad_ Nx: 2d,Monthly mean,Time-Averaged,Single-Level,Assimilation,Radiation Diagnostics V5.12.4.‚Äù doi:10.5067/OU3HJDS973O0 , https://disc.gsfc.nasa.gov/datasets/M2TMNXRAD_5.12.4/summary. Global Modeling Assimilation Office, Pawson S (2015). ‚ÄúMERRA-2 tavgM_2d_ slv_ Nx: 2d,Monthly mean,Time-Averaged,Single-Level,Assimilation,Single-Level Diagnostics V5.12.4.‚Äù doi:10.5067/AP1B0BA5PD2K , https://disc.gsfc.nasa.gov/datasets/M2TMNXSLV_5.12.4/summary. Global Modeling Assimilation Office, Pawson S (2015). ‚ÄúMERRA-2 tavgM_2d_ glc_ Nx: 2d,Monthly mean,Time-Averaged,Single-Level,Assimilation,Land Ice Surface Diagnostics V5.12.4.‚Äù doi:10.5067/5W8Q3I9WUFGX , https://disc.gsfc.nasa.gov/datasets/M2TMNXGLC_5.12.4/summary. Global Modeling Assimilation Office, Pawson S (2015). ‚ÄúMERRA-2 tavgM_3d_ cld_ Np: 3d,Monthly mean,Time-Averaged,Pressure-Level,Assimilation,Cloud Diagnostics V5.12.4.‚Äù doi:10.5067/J9R0LXGH48JR , https://disc.gsfc.nasa.gov/datasets/M2TMNPCLD_5.12.4/summary. Global Modeling Assimilation Office, Pawson S (2015). ‚ÄúMERRA-2 tavgM_3d_ mst_ Np: 3d,Monthly mean,Time-Averaged,Pressure-Level,Assimilation,Moist Processes Diagnostics V5.12.4.‚Äù doi:10.5067/ZRZGD0DCK1CG , https://disc.gsfc.nasa.gov/datasets/M2TMNPMST_5.12.4/summary. Global Modeling Assimilation Office, Pawson S (2015). ‚ÄúMERRA-2 tavgM_3d_ rad_ Np: 3d,Monthly mean,Time-Averaged,Pressure-Level,Assimilation,Radiation Diagnostics V5.12.4.‚Äù doi:10.5067/H3YGROBVBGFJ , https://disc.gsfc.nasa.gov/datasets/M2TMNPRAD_5.12.4/summary. Global Modeling Assimilation Office, Pawson S (2015). ‚ÄúMERRA-2 tavgM_3d_ tdt_ Np: 3d,Monthly mean,Time-Averaged,Pressure-Level,Assimilation,Temperature Tendencies V5.12.4.‚Äù doi:10.5067/VILT59HI2MOY , https://disc.gsfc.nasa.gov/datasets/M2TMNPTDT_5.12.4/summary. Global Modeling Assimilation Office, Pawson S (2015). ‚ÄúMERRA-2 tavgM_3d_ trb_ Np: 3d,Monthly mean,Time-Averaged,Pressure-Level,Assimilation,Turbulence Diagnostics V5.12.4.‚Äù doi:10.5067/2YOIQB5C3ACN , https://disc.gsfc.nasa.gov/datasets/M2TMNPTRB_5.12.4/summary. Global Modeling Assimilation Office, Pawson S (2015). ‚ÄúMERRA-2 tavgM_3d_ udt_ Np: 3d,Monthly mean,Time-Averaged,Pressure-Level,Assimilation,Wind Tendencies V5.12.4.‚Äù doi:10.5067/YSR6IA5057XX , https://disc.gsfc.nasa.gov/datasets/M2TMNPUDT_5.12.4/summary. Global Modeling Assimilation Office, Pawson S (2015). ‚ÄúMERRA-2 tavgM_3d_ odt_ Np: 3d,Monthly mean,Time-Averaged,Pressure-Level,Assimilation,Ozone Tendencies V5.12.4.‚Äù doi:10.5067/Z2KCWAV4GPD2 , https://disc.gsfc.nasa.gov/datasets/M2TMNPODT_5.12.4/summary. Global Modeling Assimilation Office, Pawson S (2015). ‚ÄúMERRA-2 tavgM_3d_ qdt_ Np: 3d,Monthly mean,Time-Averaged,Pressure-Level,Assimilation,Moist Tendencies V5.12.4.‚Äù doi:10.5067/2ZTU87V69ATP , https://disc.gsfc.nasa.gov/datasets/M2TMNPQDT_5.12.4/summary. Global Modeling Assimilation Office, Pawson S (2015). ‚ÄúMERRA-2 const_2d_ asm_ Nx: 2d, constants.‚Äù doi:10.5067/ME5QX6Q5IGGU , https://disc.gsfc.nasa.gov/datasets/M2C0NXASM_5.12.4/summary. Global Modeling Assimilation Office, Pawson S (2015). ‚ÄúMERRA-2 instU_2d_ asm_ Nx: 2d,Diurnal,Instantaneous,Single-Level,Assimilation,Single-Level Diagnostics V5.12.4.‚Äù doi:10.5067/BOJSTZAO2L8R , https://disc.gsfc.nasa.gov/datasets/M2IUNXASM_5.12.4/summary. Global Modeling Assimilation Office, Pawson S (2015). ‚ÄúMERRA-2 instU_2d_ int_ Nx: 2d,Diurnal,Instantaneous,Single-Level,Assimilation,Vertically Integrated Diagnostics V5.12.4.‚Äù doi:10.5067/DGAB3HFEYMLY , https://disc.gsfc.nasa.gov/datasets/M2IUNXINT_5.12.4/summary. Global Modeling Assimilation Office, Pawson S (2015). ‚ÄúMERRA-2 instU_2d_ lfo_ Nx: 2d,Diurnal,Instantaneous,Single-Level,Assimilation,Land Surface Forcings V5.12.4.‚Äù doi:10.5067/FC3BVJ88Y8A2 , https://disc.gsfc.nasa.gov/datasets/M2IUNXLFO_5.12.4/summary. Global Modeling Assimilation Office, Pawson S (2015). ‚ÄúMERRA-2 instU_2d_ gas_ Nx: 2d,Diurnal,Instantaneous,Single-Level,Assimilation,Aerosol Optical Depth Analysis V5.12.4.‚Äù doi:10.5067/TVJ4MHBED39L , https://disc.gsfc.nasa.gov/datasets/M2IUNXGAS_5.12.4/summary. Global Modeling Assimilation Office, Pawson S (2015). ‚ÄúMERRA-2 instU_3d_ asm_ Np: 3d,Diurnal,Instantaneous,Pressure-Level,Assimilation,Assimilated Meteorological Fields V5.12.4.‚Äù doi:10.5067/6EGRBNEBMIYS , https://disc.gsfc.nasa.gov/datasets/M2IUNPASM_5.12.4/summary. Global Modeling Assimilation Office, Pawson S (2015). ‚ÄúMERRA-2 instU_3d_ ana_ Np: 3d,Diurnal,Instantaneous,Pressure-Level,Analysis,Analyzed Meteorological Fields V5.12.4.‚Äù doi:10.5067/TRD91YO9S6E7 , https://disc.gsfc.nasa.gov/datasets/M2IUNPANA_5.12.4/summary. Global Modeling Assimilation Office, Pawson S (2015). ‚ÄúMERRA-2 tavgU_2d_ adg_ Nx: 2d,Diurnal,Time-averaged,Single-Level,Assimilation,Aerosol Diagnostics (extended) V5.12.4.‚Äù doi:10.5067/YZJJXZTFCX6B , https://disc.gsfc.nasa.gov/datasets/M2TUNXADG_5.12.4/summary. Global Modeling Assimilation Office, Pawson S (2015). ‚ÄúMERRA-2 tavgU_2d_ aer_ Nx: 2d,Diurnal,Time-averaged,Single-Level,Assimilation,Aerosol Diagnostics V5.12.4.‚Äù doi:10.5067/KPUMVXFEQLA1 , https://disc.gsfc.nasa.gov/datasets/M2TUNXAER_5.12.4/summary. Global Modeling Assimilation Office, Pawson S (2015). ‚ÄúMERRA-2 tavgU_2d_ chm_ Nx: 2d,Diurnal,Time-Averaged,Single-Level,Assimilation,Carbon Monoxide Ozone Diagnostics V5.12.4.‚Äù doi:10.5067/5KFZ6GXRHZKN , https://disc.gsfc.nasa.gov/datasets/M2TUNXCHM_5.12.4/summary. Global Modeling Assimilation Office, Pawson S (2015). ‚ÄúMERRA-2 tavgU_2d_ csp_ Nx: 2d,Diurnal,Time-averaged,Single-Level,Assimilation,COSP Satellite Simulator V5.12.4.‚Äù doi:10.5067/9PH5QU4CL9E8 , https://disc.gsfc.nasa.gov/datasets/M2TUNXCSP_5.12.4/summary. Global Modeling Assimilation Office, Pawson S (2015). ‚ÄúMERRA-2 tavgU_2d_ flx_ Nx: 2d,Diurnal,Time-Averaged,Single-Level,Assimilation,Surface Flux Diagnostics V5.12.4.‚Äù doi:10.5067/LUHPNWAKYIO3 , https://disc.gsfc.nasa.gov/datasets/M2TUNXFLX_5.12.4/summary. Global Modeling Assimilation Office, Pawson S (2015). ‚ÄúMERRA-2 tavgU_2d_ int_ Nx: 2d,Diurnal,Time-Averaged,Single-Level,Assimilation,Vertically Integrated Diagnostics V5.12.4.‚Äù doi:10.5067/R2MPVU4EOSWT , https://disc.gsfc.nasa.gov/datasets/M2TUNXINT_5.12.4/summary. Global Modeling Assimilation Office, Pawson S (2015). ‚ÄúMERRA-2 tavgU_2d_ lfo_ Nx: 2d,Diurnal,Time-Averaged,Single-Level,Assimilation,Land Surface Forcings V5.12.4.‚Äù doi:10.5067/BTSNKAJND3ME , https://disc.gsfc.nasa.gov/datasets/M2TUNXLFO_5.12.4/summary. Global Modeling Assimilation Office, Pawson S (2015). ‚ÄúMERRA-2 tavgU_2d_ lnd_ Nx: 2d,Diurnal,Time-Averaged,Single-Level,Assimilation,Land Surface Diagnostics V5.12.4.‚Äù doi:10.5067/W0J15047CF6N , https://disc.gsfc.nasa.gov/datasets/M2TUNXLND_5.12.4/summary. Global Modeling Assimilation Office, Pawson S (2015). ‚ÄúMERRA-2 tavgU_2d_ ocn_ Nx: 2d,Diurnal,Time-Averaged,Single-Level,Assimilation,Ocean Surface Diagnostics V5.12.4.‚Äù doi:10.5067/KLNAVGAX7J66 , https://disc.gsfc.nasa.gov/datasets/M2TUNXOCN_5.12.4/summary. Global Modeling Assimilation Office, Pawson S (2015). ‚ÄúMERRA-2 tavgU_2d_ rad_ Nx: 2d,Diurnal,Time-Averaged,Single-Level,Assimilation,Radiation Diagnostics V5.12.4.‚Äù doi:10.5067/4SDCJYK8P9QU , https://disc.gsfc.nasa.gov/datasets/M2TUNXRAD_5.12.4/summary. Global Modeling Assimilation Office, Pawson S (2015). ‚ÄúMERRA-2 tavgU_2d_ slv_ Nx: 2d,Diurnal,Time-Averaged,Single-Level,Assimilation,Single-Level Diagnostics V5.12.4.‚Äù doi:10.5067/AFOK0TPEVQEK , https://disc.gsfc.nasa.gov/datasets/M2TUNXSLV_5.12.4/summary. Global Modeling Assimilation Office, Pawson S (2015). ‚ÄúMERRA-2 tavgU_2d_ glc_ Nx: 2d,Diurnal,Time-Averaged,Single-Level,Assimilation,Land Ice Surface Diagnostics V5.12.4.‚Äù doi:10.5067/7VUPQC736SWX , https://disc.gsfc.nasa.gov/datasets/M2TUNXGLC_5.12.4/summary. Global Modeling Assimilation Office, Pawson S (2015). ‚ÄúMERRA-2 tavgU_3d_ cld_ Np: 3d,Diurnal,Time-Averaged,Pressure-Level,Assimilation,Cloud Diagnostics V5.12.4.‚Äù doi:10.5067/EPW7T5UO0C0N , https://disc.gsfc.nasa.gov/datasets/M2TUNPCLD_5.12.4/summary. Global Modeling Assimilation Office, Pawson S (2015). ‚ÄúMERRA-2 tavgU_3d_ mst_ Np: 3d,Diurnal,Time-Averaged,Pressure-Level,Assimilation,Moist Processes Diagnostics V5.12.4.‚Äù doi:10.5067/ZRSN0JU27DK2 , https://disc.gsfc.nasa.gov/datasets/M2TUNPMST_5.12.4/summary. Global Modeling Assimilation Office, Pawson S (2015). ‚ÄúMERRA-2 tavgU_3d_ rad_ Np: 3d,Diurnal,Time-Averaged,Pressure-Level,Assimilation,Radiation Diagnostics V5.12.4.‚Äù doi:10.5067/H140JMDOWB0Y , https://disc.gsfc.nasa.gov/datasets/M2TUNPRAD_5.12.4/summary. Global Modeling Assimilation Office, Pawson S (2015). ‚ÄúMERRA-2 tavgU_3d_ tdt_ Np: 3d,Diurnal,Time-Averaged,Pressure-Level,Assimilation,Temperature Tendencies V5.12.4.‚Äù doi:10.5067/QPO9E5TPZ8OF , https://disc.gsfc.nasa.gov/datasets/M2TUNPTDT_5.12.4/summary. Global Modeling Assimilation Office, Pawson S (2015). ‚ÄúMERRA-2 tavgU_3d_ trb_ Np: 3d,Diurnal,Time-Averaged,Pressure-Level,Assimilation,Turbulence Diagnostics V5.12.4.‚Äù doi:10.5067/2A99C60CG7WC , https://disc.gsfc.nasa.gov/datasets/M2TUNPTRB_5.12.4/summary. Global Modeling Assimilation Office, Pawson S (2015). ‚ÄúMERRA-2 tavgU_3d_ udt_ Np: 3d,Diurnal,Time-Averaged,Pressure-Level,Assimilation,Wind Tendencies V5.12.4.‚Äù doi:10.5067/DO715T7T5PG8 , https://disc.gsfc.nasa.gov/datasets/M2TUNPUDT_5.12.4/summary. Global Modeling Assimilation Office, Pawson S (2015). ‚ÄúMERRA-2 tavgU_3d_ odt_ Np: 3d,Diurnal,Time-Averaged,Pressure-Level,Assimilation,Ozone Tendencies V5.12.4.‚Äù doi:10.5067/M8OJ09GZP23E , https://disc.gsfc.nasa.gov/datasets/M2TUNPODT_5.12.4/summary. Global Modeling Assimilation Office, Pawson S (2015). ‚ÄúMERRA-2 tavgU_3d_ qdt_ Np: 3d,Diurnal,Time-Averaged,Pressure-Level,Assimilation,Moist Tendencies V5.12.4.‚Äù doi:10.5067/S8HJXIR0BFTS , https://disc.gsfc.nasa.gov/datasets/M2TUNPQDT_5.12.4/summary.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_merra2.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Download meteorological and atmospheric data ‚Äî download_merra2","text":"Mitchell Manware, Insang Song","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_merra2.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Download meteorological and atmospheric data ‚Äî download_merra2","text":"","code":"if (FALSE) { # \\dontrun{ download_merra2(   collection = \"inst1_2d_int_Nx\",   date = \"2024-01-01\",   directory_to_save = tempdir(),   acknowledgement = TRUE,   download = FALSE, # NOTE: download skipped for examples,   remove_command = TRUE, ) } # }"},{"path":"https://niehs.github.io/amadeus/reference/download_modis.html","id":null,"dir":"Reference","previous_headings":"","what":"Download MODIS product files ‚Äî download_modis","title":"Download MODIS product files ‚Äî download_modis","text":"Need maintenance directory path change NASA EOSDIS. function first retrieves hdf download links certain day, selects relevant tiles retrieved links. Download done queried horizontal-vertical tile number combinations. exception MOD06_L2 product, produced every five minutes every day.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_modis.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Download MODIS product files ‚Äî download_modis","text":"","code":"download_modis(   product = c(\"MOD09GA\", \"MYD09GA\", \"MOD09GQ\", \"MYD09GQ\", \"MOD09A1\", \"MYD09A1\",     \"MOD09Q1\", \"MYD09Q1\", \"MOD11A1\", \"MYD11A1\", \"MOD11A2\", \"MYD11A2\", \"MOD11B1\",     \"MYD11B1\", \"MOD13A1\", \"MYD13A1\", \"MOD13A2\", \"MYD13A2\", \"MOD13A3\", \"MYD13A3\",     \"MOD06_L2\", \"MCD19A2\", \"VNP46A2\"),   version = \"61\",   horizontal_tiles = c(7, 13),   vertical_tiles = c(3, 6),   mod06_links = NULL,   nasa_earth_data_token = NULL,   date = c(\"2023-09-01\", \"2023-09-01\"),   directory_to_save = NULL,   acknowledgement = FALSE,   download = FALSE,   remove_command = FALSE,   hash = FALSE )"},{"path":"https://niehs.github.io/amadeus/reference/download_modis.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Download MODIS product files ‚Äî download_modis","text":"product character(1). One c(\"MOD09GA\", \"MOD11A1\", \"MOD06_L2\", \"MCD19A2\", \"MOD13A2\", \"VNP46A2\") version character(1). Default \"61\", meaning v061. horizontal_tiles integer(2). Horizontal tile numbers c({start}, {end}). Default c(7, 13). vertical_tiles integer(2). Vertical tile numbers c({start}, {end}). Default c(3, 6). mod06_links character(1). CSV file path MOD06_L2 download links NASA LAADS MOD06_L2. Default NULL. nasa_earth_data_token character(1). Token downloading data NASA. set trying running function. date character(1 2). length 10. Date start/end dates downloading data. Format \"YYYY-MM-DD\" (ex. January 1, 2018 = \"2018-01-01\"). Note: ignored product == \"MOD06_L2\". directory_to_save character(1). Directory save data. acknowledgement logical(1). setting TRUE user acknowledges data downloaded using function may large use lots machine storage memory. download logical(1). Download data save wget commands. remove_command logical(1). Remove (TRUE) keep (FALSE) text file containing download commands. hash logical(1). setting TRUE function return rlang::hash_file() hash character corresponding downloaded files. Default FALSE.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_modis.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Download MODIS product files ‚Äî download_modis","text":"hash = FALSE, NULL hash = TRUE, rlang::hash_file character. HDF (.hdf) files stored year/day_of_year sub-directories within directory_to_save.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_modis.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Download MODIS product files ‚Äî download_modis","text":"dates date year. Directory structure looks like input/modis/raw/{version}/{product}/{year}/{day_of_year}.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_modis.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Download MODIS product files ‚Äî download_modis","text":"Lyapustin , Wang Y (2022). ‚ÄúMODIS/Terra+Aqua Land Aerosol Optical Depth Daily L2G Global 1km SIN Grid V061.‚Äù doi:10.5067/MODIS/MCD19A2.061 , https://www.earthdata.nasa.gov/data/catalog/lpcloud-mcd19a2-061. MODIS Atmosphere Science Team (2017). ‚ÄúMODIS/Terra Clouds 5-Min L2 Swath 1km 5km.‚Äù doi:10.5067/MODIS/MOD06_L2.061 , https://ladsweb.modaps.eosdis.nasa.gov/missions--measurements/products/MOD06_L2. Vermote E, Wolfe R (2021). ‚ÄúMODIS/Terra Surface Reflectance Daily L2G Global 1km 500m SIN Grid V061.‚Äù doi:10.5067/MODIS/MOD09GA.061 , https://www.earthdata.nasa.gov/data/catalog/lpcloud-mod09ga-061. Wan Z, Hook S, Hulley G (2021). ‚ÄúMODIS/Terra Land Surface Temperature/Emissivity Daily L3 Global 1km SIN Grid V061.‚Äù doi:10.5067/MODIS/MOD11A1.061 , https://www.earthdata.nasa.gov/data/catalog/lpcloud-mod11a1-061. Didan K (2021). ‚ÄúMODIS/Terra Vegetation Indices 16-Day L3 Global 1km SIN Grid V061.‚Äù doi:10.5067/MODIS/MOD13A2.061 , https://www.earthdata.nasa.gov/data/catalog/lpcloud-mod13a2-061. Rom√°n MO, Wang Z, Sun Q, Kalb V, Miller SD, Molthan , Schultz L, Bell J, Stokes EC, Pandey B, Seto KC, Hall D, Oda T, Wolfe RE, Lin G, Golpayegani N, Devadiga S, Davidson C, Sarkar S, Praderas C, Schmaltz J, Boller R, Stevens J, Ramos Gonz√°lez OM, Padilla E, Alonso J, Detr√©s Y, Armstrong R, Miranda , Conte Y, Marrero N, MacManus K, Esch T, Masuoka EJ (2018). ‚ÄúNASA's Black Marble nighttime lights product suite.‚Äù Remote Sensing Environment, 210, 113‚Äì143. ISSN 00344257, doi:10.1016/j.rse.2018.03.017 , https://linkinghub.elsevier.com/retrieve/pii/S003442571830110X.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_modis.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Download MODIS product files ‚Äî download_modis","text":"Mitchell Manware, Insang Song","code":""},{"path":[]},{"path":"https://niehs.github.io/amadeus/reference/download_narr.html","id":null,"dir":"Reference","previous_headings":"","what":"Download meteorological data ‚Äî download_narr","title":"Download meteorological data ‚Äî download_narr","text":"download_narr function accesses downloads daily meteorological data NOAA's North American Regional Reanalysis (NARR) model.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_narr.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Download meteorological data ‚Äî download_narr","text":"","code":"download_narr(   variables = NULL,   year = c(2018, 2022),   directory_to_save = NULL,   acknowledgement = FALSE,   download = FALSE,   remove_command = FALSE,   hash = FALSE )"},{"path":"https://niehs.github.io/amadeus/reference/download_narr.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Download meteorological data ‚Äî download_narr","text":"variables character. Variable(s) name acronym. See List Variables NARR Files variable names acronym codes. year integer(1 2). length 4. Year start/end years downloading data. directory_to_save character(1). Directory(s) save downloaded data files. acknowledgement logical(1). setting TRUE user acknowledges data downloaded using function may large use lots machine storage memory. download logical(1). FALSE generate *.txt file containing download commands. setting TRUE function download requested data files. remove_command logical(1). Remove (TRUE) keep (FALSE) text file containing download commands. hash logical(1). setting TRUE function return rlang::hash_file() hash character corresponding downloaded files. Default FALSE.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_narr.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Download meteorological data ‚Äî download_narr","text":"hash = FALSE, NULL hash = TRUE, rlang::hash_file character. netCDF (.nc) files stored directory_to_save.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_narr.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Download meteorological data ‚Äî download_narr","text":"\"Pressure levels\" variables contain variable values 29 atmospheric levels, ranging 1000 hPa 100 hPa. pressure levels data downloaded variable.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_narr.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Download meteorological data ‚Äî download_narr","text":"Mesinger F, DiMego G, Kalnay E, Mitchell K, Shafran PC, Ebisuzaki W, Joviƒá D, Woollen J, Rogers E, Berbery EH, Ek MB, Fan Y, Grumbine R, Higgins W, Li H, Lin Y, Manikin G, Parrish D, Shi W (2006). ‚ÄúNorth American Regional Reanalysis.‚Äù Bulletin American Meteorological Society, 87(3), 343‚Äì360. ISSN 0003-0007, 1520-0477, doi:10.1175/BAMS-87-3-343 .","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_narr.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Download meteorological data ‚Äî download_narr","text":"Mitchell Manware, Insang Song","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_narr.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Download meteorological data ‚Äî download_narr","text":"","code":"if (FALSE) { # \\dontrun{ download_narr(   variables = c(\"weasd\", \"omega\"),   year = 2023,   directory_to_save = tempdir(),   acknowledgement = TRUE,   download = FALSE, # NOTE: download skipped for examples,   remove_command = TRUE ) } # }"},{"path":"https://niehs.github.io/amadeus/reference/download_nei.html","id":null,"dir":"Reference","previous_headings":"","what":"Download road emissions data ‚Äî download_nei","title":"Download road emissions data ‚Äî download_nei","text":"download_nei() function accesses downloads road emissions data U.S Environmental Protection Agency's (EPA) National Emissions Inventory (NEI).","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_nei.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Download road emissions data ‚Äî download_nei","text":"","code":"download_nei(   epa_certificate_path = system.file(\"extdata/cacert_gaftp_epa.pem\", package = \"amadeus\"),   certificate_url =     \"http://cacerts.digicert.com/DigiCertGlobalG2TLSRSASHA2562020CA1-1.crt\",   year = c(2017L, 2020L),   directory_to_save = NULL,   acknowledgement = FALSE,   download = FALSE,   remove_command = FALSE,   unzip = TRUE,   hash = FALSE )"},{"path":"https://niehs.github.io/amadeus/reference/download_nei.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Download road emissions data ‚Äî download_nei","text":"epa_certificate_path character(1). Path certificate file EPA DataCommons. Default 'extdata/cacert_gaftp_epa.pem' package installation path. certificate_url character(1). URL certificate file. See notes details. year integer(1) Available years NEI data. Default c(2017L, 2020L). directory_to_save character(1). Directory save data. Two sub-directories created downloaded zip files (\"/zip_files\") unzipped data files (\"/data_files\"). acknowledgement logical(1). setting TRUE user acknowledges data downloaded using function may large use lots machine storage memory. download logical(1). FALSE generate *.txt file containing download commands. setting TRUE function download requested data files. remove_command logical(1). Remove (TRUE) keep (FALSE) text file containing download commands. unzip logical(1). Unzip downloaded zip files. Default FALSE. hash logical(1). setting TRUE function return rlang::hash_file() hash character corresponding downloaded files. Default FALSE.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_nei.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Download road emissions data ‚Äî download_nei","text":"hash = FALSE, NULL hash = TRUE, rlang::hash_file character. Zip /data files downloaded stored respective sub-directories within directory_to_save.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_nei.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Download road emissions data ‚Äî download_nei","text":"EPA Data Commons certificate errors, follow steps : Click Lock icon address bar https://gaftp.epa.gov Click Show Certificate Access Details Find URL *.crt extension Currently bundle pre-downloaded crt PEM (accepted wget command) file ./inst/extdata. instruction certificate updates future.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_nei.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Download road emissions data ‚Äî download_nei","text":"United States Environmental Protection Agency (2024). ‚ÄúAir Emissions Inventories.‚Äù https://www.epa.gov/air-emissions-inventories.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_nei.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Download road emissions data ‚Äî download_nei","text":"Ranadeep Daw, Insang Song","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_nei.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Download road emissions data ‚Äî download_nei","text":"","code":"if (FALSE) { # \\dontrun{ download_nei(   year = c(2017L, 2020L),   directory_to_save = tempdir(),   acknowledgement = TRUE,   download = FALSE, # NOTE: download skipped for examples,   remove_command = TRUE,   unzip = FALSE ) } # }"},{"path":"https://niehs.github.io/amadeus/reference/download_nlcd.html","id":null,"dir":"Reference","previous_headings":"","what":"Download land cover data ‚Äî download_nlcd","title":"Download land cover data ‚Äî download_nlcd","text":"download_nlcd() function accesses downloads annual land cover data Multi-Resolution Land Characteristics (MRLC) Consortium's National Land Cover Database (NLCD) products data base.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_nlcd.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Download land cover data ‚Äî download_nlcd","text":"","code":"download_nlcd(   product = \"Land Cover\",   year = 2021,   directory_to_save = NULL,   acknowledgement = FALSE,   download = FALSE,   remove_command = FALSE,   unzip = TRUE,   remove_zip = FALSE,   hash = FALSE )"},{"path":"https://niehs.github.io/amadeus/reference/download_nlcd.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Download land cover data ‚Äî download_nlcd","text":"product character(1). \"Land Cover\", \"Land Cover Change\", \"Land Cover Confidence\", \"Fractional Impervious Surface\", \"Impervious Descriptor\", \"Spectral Change Day Year \". year integer(1). Available years Coterminous United States range 1985 2023. directory_to_save character(1). Directory save data. Two sub-directories created downloaded zip files (\"/zip_files\") unzipped shapefiles (\"/data_files\"). acknowledgement logical(1). setting TRUE user acknowledges data downloaded using function may large use lots machine storage memory. download logical(1). FALSE generate *.txt file containing download commands. setting TRUE function download requested data files. remove_command logical(1). Remove (TRUE) keep (FALSE) text file containing download commands. unzip logical(1). Unzip zip files. Default TRUE. remove_zip logical(1). Remove zip files directory_to_download. Default FALSE. hash logical(1). setting TRUE function return rlang::hash_file() hash character corresponding downloaded files. Default FALSE.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_nlcd.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Download land cover data ‚Äî download_nlcd","text":"hash = FALSE, NULL hash = TRUE, rlang::hash_file character. Zip /data files downloaded stored respective sub-directories within directory_to_save.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_nlcd.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Download land cover data ‚Äî download_nlcd","text":"Dewitz J (2023). ‚ÄúNational Land Cover Database (NLCD) 2021 Products.‚Äù doi:10.5066/P9JZ7AO3 .  Dewitz J (2024). ‚ÄúNational Land Cover Database (NLCD) 2019 Products (ver. 3.0, February 2024).‚Äù doi:10.5066/P9KZCM54 .","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_nlcd.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Download land cover data ‚Äî download_nlcd","text":"Mitchell Manware, Insang Song","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_nlcd.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Download land cover data ‚Äî download_nlcd","text":"","code":"if (FALSE) { # \\dontrun{ download_nlcd(   product = \"Land Cover\",   year = 2021,   directory_to_save = tempdir(),   acknowledgement = TRUE,   download = FALSE # NOTE: download skipped for examples ) } # }"},{"path":"https://niehs.github.io/amadeus/reference/download_permit.html","id":null,"dir":"Reference","previous_headings":"","what":"Check data download acknowledgement ‚Äî download_permit","title":"Check data download acknowledgement ‚Äî download_permit","text":"Return error acknowledgement = FALSE.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_permit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check data download acknowledgement ‚Äî download_permit","text":"","code":"download_permit(acknowledgement)"},{"path":"https://niehs.github.io/amadeus/reference/download_permit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check data download acknowledgement ‚Äî download_permit","text":"acknowledgement logical(1). Whether start downloading","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_permit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check data download acknowledgement ‚Äî download_permit","text":"NULL; returns stop error acknowledgement FALSE","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_permit.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Check data download acknowledgement ‚Äî download_permit","text":"acknowledgement parameter designed help users avoid accidentally initiating large data download may take long time run exceed machine capabilities.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_population.html","id":null,"dir":"Reference","previous_headings":"","what":"Download population density data ‚Äî download_population","title":"Download population density data ‚Äî download_population","text":"download_population() function accesses downloads population density data NASA's UN WPP-Adjusted Population Density, v4.11.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_population.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Download population density data ‚Äî download_population","text":"","code":"download_population(   data_resolution = \"60 minute\",   data_format = c(\"GeoTIFF\", \"ASCII\", \"netCDF\"),   year = \"2020\",   directory_to_save = NULL,   acknowledgement = FALSE,   download = FALSE,   remove_command = FALSE,   unzip = TRUE,   remove_zip = FALSE,   hash = FALSE )"},{"path":"https://niehs.github.io/amadeus/reference/download_population.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Download population density data ‚Äî download_population","text":"data_resolution character(1). Available resolutions 30 second (approx. 1 km), 2.5 minute (approx. 5 km), 15 minute (approx. 30 km), 30 minute (approx. 55 km), 60 minute (approx. 110 km). data_format character(1). Individual year data can downloaded \"ASCII\" \"GeoTIFF\". \"\" years downloaded \"netCDF\". year character(1). Available years 2000, 2005, 2010, 2015, 2020, \"\" years. directory_to_save character(1). Directory save data. Two sub-directories created downloaded zip files (\"/zip_files\") unzipped shapefiles (\"/data_files\"). acknowledgement logical(1). setting TRUE user acknowledges data downloaded using function may large use lots machine storage memory. download logical(1). FALSE generate *.txt file containing download commands. setting TRUE function download requested data files. remove_command logical(1). Remove (TRUE) keep (FALSE) text file containing download commands. unzip logical(1). Unzip zip files. Default TRUE. remove_zip logical(1). Remove zip files directory_to_download. Default FALSE. hash logical(1). setting TRUE function return rlang::hash_file() hash character corresponding downloaded files. Default FALSE.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_population.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Download population density data ‚Äî download_population","text":"hash = FALSE, NULL hash = TRUE, rlang::hash_file character. Zip /data files downloaded stored respective sub-directories within directory_to_save.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_population.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Download population density data ‚Äî download_population","text":"Center International Earth Science Information Network-CIESIN-Columbia University (2017). ‚ÄúGridded Population World, Version 4 (GPWv4): Population Density, Revision 11.‚Äù doi:10.7927/H49C6VHW , https://earthdata.nasa.gov/data/catalog/sedac-ciesin-sedac-gpwv4-popdens-r11-4.11.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_population.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Download population density data ‚Äî download_population","text":"Mitchell Manware, Insang Song","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_population.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Download population density data ‚Äî download_population","text":"","code":"if (FALSE) { # \\dontrun{ download_population(   data_resolution = \"30 second\",   data_format = \"GeoTIFF\",   year = \"2020\",   directory_to_save = tempdir(),   acknowledgement = TRUE,   download = FALSE, # NOTE: download skipped for examples,   remove_command = TRUE,   unzip = FALSE ) } # }"},{"path":"https://niehs.github.io/amadeus/reference/download_prism.html","id":null,"dir":"Reference","previous_headings":"","what":"Download PRISM data ‚Äî download_prism","title":"Download PRISM data ‚Äî download_prism","text":"Accesses downloads Oregon State University's PRISM data PRISM Climate Group Web Service","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_prism.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Download PRISM data ‚Äî download_prism","text":"","code":"download_prism(   time,   element = c(\"ppt\", \"tmin\", \"tmax\", \"tmean\", \"tdmean\", \"vpdmin\", \"vpdmax\", \"solslope\",     \"soltotal\", \"solclear\", \"soltrans\"),   data_type = c(\"ts\", \"normals_800\", \"normals\"),   format = c(\"nc\", \"asc\", \"grib2\"),   directory_to_save = NULL,   acknowledgement = FALSE,   download = FALSE,   remove_command = FALSE,   hash = FALSE )"},{"path":"https://niehs.github.io/amadeus/reference/download_prism.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Download PRISM data ‚Äî download_prism","text":"time character(1). Length 2, 4, 6, 8. Time period time series normals. According PRISM Web Service Guide, acceptable formats include (disclaimer: following direct quote; minimal formatting applied): Time Series: YYYYMMDD daily data (yesterday January 1st, 1981) ‚Äì returns single grid .zip file YYYYMM monthly data (last month January 1981) ‚Äì returns single grid .zip file YYYY annual data (last year 1981) - returns single grid .zip file YYYY historical data (1980 1895) - returns single zip file containing 12 monthly grids YYYY plus annual. Normals: Monthly normal: date MM (.e., 04 April) value 14, returns annual normal Daily normal: date MMDD (.e., 0430 April 30) element character(1). Data element. One c(\"ppt\", \"tmin\", \"tmax\", \"tmean\", \"tdmean\", \"vpdmin\", \"vpdmax\") normals, c(\"solslope\", \"soltotal\", \"solclear\", \"soltrans\") also accepted. data_type character(1). Data type. \"ts\": 4km resolution time series. \"normals_800\": 800m resolution normals. \"normals\": 4km resolution normals. format character(1). Data format. applicable data_type = \"ts\". directory_to_save character(1). Directory download files. acknowledgement logical(1). setting TRUE user acknowledges data downloaded using function may large use lots machine storage memory. download logical(1). FALSE generate *.txt file containing download commands. setting TRUE function download requested data files. remove_command logical(1). Remove (TRUE) keep (FALSE) text file containing download commands. hash logical(1). setting TRUE function return rlang::hash_file() hash character corresponding downloaded files. Default FALSE.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_prism.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Download PRISM data ‚Äî download_prism","text":"hash = FALSE, NULL hash = TRUE, rlang::hash_file character. .bil (normals) single grid files depending format choice stored directory_to_save.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_prism.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Download PRISM data ‚Äî download_prism","text":"Daly C, Taylor GH, Gibson WP, Parzybok TW, Johnson GL, Pasteris PA (2000). ‚ÄúHIGH-QUALITY SPATIAL CLIMATE DATA SETS UNITED STATES BEYOND.‚Äù Transactions ASAE, 43(6), 1957‚Äì1962. ISSN 2151-0059, doi:10.13031/2013.3101 , http://elibrary.asabe.org/abstract.asp??JID=3&AID=3101&CID=t2000&v=43&=6&T=1. PRISM Climate Group PRISM Web Service Guide","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_prism.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Download PRISM data ‚Äî download_prism","text":"Insang Song","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_prism.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Download PRISM data ‚Äî download_prism","text":"","code":"if (FALSE) { # \\dontrun{ download_prism(   time = \"202104\",   element = \"ppt\",   data_type = \"ts\",   format = \"nc\",   directory_to_save = tempdir(),   acknowledgement = TRUE,   download = FALSE, # NOTE: download skipped for examples,   remove_command = TRUE ) } # }"},{"path":"https://niehs.github.io/amadeus/reference/download_remove_command.html","id":null,"dir":"Reference","previous_headings":"","what":"Remove download commands ‚Äî download_remove_command","title":"Remove download commands ‚Äî download_remove_command","text":"Remove retain .txt file storing download commands.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_remove_command.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Remove download commands ‚Äî download_remove_command","text":"","code":"download_remove_command(commands_txt = NULL, remove = FALSE)"},{"path":"https://niehs.github.io/amadeus/reference/download_remove_command.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Remove download commands ‚Äî download_remove_command","text":"commands_txt character(1). Path download commands remove logical(1). Remove (TRUE) keep (FALSE) commands","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_remove_command.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Remove download commands ‚Äî download_remove_command","text":"NULL; removes .txt/.bat file storing download commands.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_remove_zips.html","id":null,"dir":"Reference","previous_headings":"","what":"Remove zip files ‚Äî download_remove_zips","title":"Remove zip files ‚Äî download_remove_zips","text":"Remove downloaded \".zip\" files.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_remove_zips.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Remove zip files ‚Äî download_remove_zips","text":"","code":"download_remove_zips(remove = FALSE, download_name)"},{"path":"https://niehs.github.io/amadeus/reference/download_remove_zips.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Remove zip files ‚Äî download_remove_zips","text":"remove logical(1). Confirm removal. Default FALSE. download_name character. Full zip file path","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_remove_zips.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Remove zip files ‚Äî download_remove_zips","text":"NULL; removes downloaded zip files unzipped","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_remove_zips.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Remove zip files ‚Äî download_remove_zips","text":"!!! USE FUNCTION CAUTION !!! remove = TRUE, ensure unzip = TRUE. Choosing remove \".zip\" files without unzipping retain none downloaded data. remove files second higher level directory.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_run.html","id":null,"dir":"Reference","previous_headings":"","what":"Run download commands ‚Äî download_run","title":"Run download commands ‚Äî download_run","text":"Execute skip commands listed ...wget/curl_commands.txt file produced one data download functions.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_run.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Run download commands ‚Äî download_run","text":"","code":"download_run(download = FALSE, commands_txt = NULL, remove = FALSE)"},{"path":"https://niehs.github.io/amadeus/reference/download_run.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Run download commands ‚Äî download_run","text":"download logical(1). Execute (TRUE) skip (FALSE) download. commands_txt character(1). Path download commands remove logical(1). Remove (TRUE) keep (FALSE) command. Passed download_remove_commands.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_run.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Run download commands ‚Äî download_run","text":"NULL; runs download commands shell (Unix/Linux) command prompt (Windows) removes commands_txt file remove = TRUE.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_sanitize_path.html","id":null,"dir":"Reference","previous_headings":"","what":"Sanitize directory ‚Äî download_sanitize_path","title":"Sanitize directory ‚Äî download_sanitize_path","text":"Append forward slash end directory already end one.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_sanitize_path.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sanitize directory ‚Äî download_sanitize_path","text":"","code":"download_sanitize_path(directory)"},{"path":"https://niehs.github.io/amadeus/reference/download_sanitize_path.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sanitize directory ‚Äî download_sanitize_path","text":"directory character(1). Path","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_sanitize_path.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sanitize directory ‚Äî download_sanitize_path","text":"character ending forward slash.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_setup_dir.html","id":null,"dir":"Reference","previous_headings":"","what":"Setup directory ‚Äî download_setup_dir","title":"Setup directory ‚Äî download_setup_dir","text":"Create directory already exist. directory exist, directory created.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_setup_dir.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Setup directory ‚Äî download_setup_dir","text":"","code":"download_setup_dir(directory, zip = FALSE)"},{"path":"https://niehs.github.io/amadeus/reference/download_setup_dir.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Setup directory ‚Äî download_setup_dir","text":"directory character(1) directory path zip logical(1). sub-directories created zip files data files? TRUE, vector sub-directoy names returned.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_setup_dir.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Setup directory ‚Äî download_setup_dir","text":"NULL; zip = TRUE vector directories zip files data files","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_sink.html","id":null,"dir":"Reference","previous_headings":"","what":"Sink download commands ‚Äî download_sink","title":"Sink download commands ‚Äî download_sink","text":"Open connection command_txt file store download commands.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_sink.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sink download commands ‚Äî download_sink","text":"","code":"download_sink(command_txt)"},{"path":"https://niehs.github.io/amadeus/reference/download_sink.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sink download commands ‚Äî download_sink","text":"command_txt character(1). file path export commands.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_sink.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sink download commands ‚Äî download_sink","text":"NULL; creates opens connection text file store download commands","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_terraclimate.html","id":null,"dir":"Reference","previous_headings":"","what":"Download TerraClimate data ‚Äî download_terraclimate","title":"Download TerraClimate data ‚Äî download_terraclimate","text":"download_terraclimate function accesses downloads climate water balance data University California Merced Climatology Lab's TerraClimate dataset.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_terraclimate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Download TerraClimate data ‚Äî download_terraclimate","text":"","code":"download_terraclimate(   variables = NULL,   year = c(2018, 2022),   directory_to_save = NULL,   acknowledgement = FALSE,   download = FALSE,   remove_command = FALSE,   hash = FALSE )"},{"path":"https://niehs.github.io/amadeus/reference/download_terraclimate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Download TerraClimate data ‚Äî download_terraclimate","text":"variables character(1). Variable(s) name(s). See TerraClimate Direct Downloads variable names acronym codes. year integer(1 2). length 4. Year start/end years downloading data. directory_to_save character(1). Directory(s) save downloaded data files. acknowledgement logical(1). setting TRUE user acknowledges data downloaded using function may large use lots machine storage memory. download logical(1). FALSE generate *.txt file containing download commands. setting TRUE function download requested data files. remove_command logical(1). Remove (TRUE) keep (FALSE) text file containing download commands. hash logical(1). setting TRUE function return rlang::hash_file() hash character corresponding downloaded files. Default FALSE.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_terraclimate.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Download TerraClimate data ‚Äî download_terraclimate","text":"hash = FALSE, NULL hash = TRUE, rlang::hash_file character. netCDF (.nc) files stored variable-specific folder within directory_to_save.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_terraclimate.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Download TerraClimate data ‚Äî download_terraclimate","text":"Abatzoglou JT, Dobrowski SZ, Parks SA, Hegewisch KC (2018). ‚ÄúTerraClimate, high-resolution global dataset monthly climate climatic water balance 1958‚Äì2015.‚Äù Scientific data, 5(1), 1‚Äì12.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_terraclimate.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Download TerraClimate data ‚Äî download_terraclimate","text":"Mitchell Manware, Insang Song","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_terraclimate.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Download TerraClimate data ‚Äî download_terraclimate","text":"","code":"if (FALSE) { # \\dontrun{ download_terraclimate(   variables = \"Precipitation\",   year = 2023,   directory_to_save = tempdir(),   acknowledgement = TRUE,   download = FALSE, # NOTE: download skipped for examples,   remove_command = TRUE ) } # }"},{"path":"https://niehs.github.io/amadeus/reference/download_tri.html","id":null,"dir":"Reference","previous_headings":"","what":"Download toxic release data ‚Äî download_tri","title":"Download toxic release data ‚Äî download_tri","text":"download_tri() function accesses downloads toxic release data U.S. Environmental Protection Agency's (EPA) Toxic Release Inventory (TRI) Program.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_tri.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Download toxic release data ‚Äî download_tri","text":"","code":"download_tri(   year = c(2018L, 2022L),   directory_to_save = NULL,   acknowledgement = FALSE,   download = FALSE,   remove_command = FALSE,   hash = FALSE )"},{"path":"https://niehs.github.io/amadeus/reference/download_tri.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Download toxic release data ‚Äî download_tri","text":"year integer(1 2). length 4. Year start/end years downloading data. directory_to_save character(1). Directory download files. acknowledgement logical(1). setting TRUE user acknowledges data downloaded using function may large use lots machine storage memory. download logical(1). FALSE generate *.txt file containing download commands. setting TRUE function download requested data files. remove_command logical(1). Remove (TRUE) keep (FALSE) text file containing download commands. hash logical(1). setting TRUE function return rlang::hash_file() hash character corresponding downloaded files. Default FALSE.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_tri.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Download toxic release data ‚Äî download_tri","text":"hash = FALSE, NULL hash = TRUE, rlang::hash_file character. Comma-separated value (CSV) files stored directory_to_save.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_tri.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Download toxic release data ‚Äî download_tri","text":"United States Environmental Protection Agency (2024). ‚ÄúTRI Basic Data Files: Calendar Years 1987 ‚Äì Present.‚Äù https://www.epa.gov/toxics-release-inventory-tri-program/tri-data-action-0.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_tri.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Download toxic release data ‚Äî download_tri","text":"Mariana Kassien, Insang Song","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_tri.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Download toxic release data ‚Äî download_tri","text":"","code":"if (FALSE) { # \\dontrun{ download_tri(   year = 2021L,   directory_to_save = tempdir(),   acknowledgement = TRUE,   download = FALSE, # NOTE: download skipped for examples,   remove_command = TRUE ) } # }"},{"path":"https://niehs.github.io/amadeus/reference/download_unzip.html","id":null,"dir":"Reference","previous_headings":"","what":"Unzip zip files ‚Äî download_unzip","title":"Unzip zip files ‚Äî download_unzip","text":"Unzip (inflate) downloaded \".zip\" files.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_unzip.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Unzip zip files ‚Äî download_unzip","text":"","code":"download_unzip(file_name, directory_to_unzip, unzip = TRUE)"},{"path":"https://niehs.github.io/amadeus/reference/download_unzip.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Unzip zip files ‚Äî download_unzip","text":"file_name character(1). Full zip file path directory_to_unzip character(1). Directory unzip data unzip logical(1). Unzip (TRUE) .","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_unzip.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Unzip zip files ‚Äî download_unzip","text":"NULL; unzips downloaded zip files","code":""},{"path":"https://niehs.github.io/amadeus/reference/dt_as_mysftime.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert a data.table to an sftime ‚Äî dt_as_mysftime","title":"Convert a data.table to an sftime ‚Äî dt_as_mysftime","text":"Convert data.table object sftime. x must data.table object \"lon\", \"lat\", \"time\" columns describe longitude, latitude, time-orientation, respectively, x.","code":""},{"path":"https://niehs.github.io/amadeus/reference/dt_as_mysftime.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert a data.table to an sftime ‚Äî dt_as_mysftime","text":"","code":"dt_as_mysftime(x, lonname, latname, timename, crs)"},{"path":"https://niehs.github.io/amadeus/reference/dt_as_mysftime.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert a data.table to an sftime ‚Äî dt_as_mysftime","text":"x data.table lonname character longitude column name latname character latitude column name timename character time column name crs coordinate reference system","code":""},{"path":"https://niehs.github.io/amadeus/reference/dt_as_mysftime.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert a data.table to an sftime ‚Äî dt_as_mysftime","text":"sftime object","code":""},{"path":"https://niehs.github.io/amadeus/reference/dt_as_mysftime.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Convert a data.table to an sftime ‚Äî dt_as_mysftime","text":"Eva Marques","code":""},{"path":"https://niehs.github.io/amadeus/reference/extract_urls.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract download URLs ‚Äî extract_urls","title":"Extract download URLs ‚Äî extract_urls","text":"Extract download URLs multi-argument download commands.","code":""},{"path":"https://niehs.github.io/amadeus/reference/extract_urls.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract download URLs ‚Äî extract_urls","text":"","code":"extract_urls(commands = commands, position = NULL)"},{"path":"https://niehs.github.io/amadeus/reference/extract_urls.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract download URLs ‚Äî extract_urls","text":"commands character vector containing download commands position URL position vector","code":""},{"path":"https://niehs.github.io/amadeus/reference/extract_urls.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract download URLs ‚Äî extract_urls","text":"character vector containing download URLs","code":""},{"path":"https://niehs.github.io/amadeus/reference/generate_date_sequence.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate date sequence ‚Äî generate_date_sequence","title":"Generate date sequence ‚Äî generate_date_sequence","text":"Generate sequence dates date_start date_end.","code":""},{"path":"https://niehs.github.io/amadeus/reference/generate_date_sequence.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate date sequence ‚Äî generate_date_sequence","text":"","code":"generate_date_sequence(date_start, date_end, sub_hyphen = TRUE)"},{"path":"https://niehs.github.io/amadeus/reference/generate_date_sequence.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate date sequence ‚Äî generate_date_sequence","text":"date_start character(1). Beginning date sequence. date_end character(1). End date sequence. sub_hyphen logical(1). Substitute hyphen dates. TRUE, returns date sequence \"YYYYMMDD\". FALSE, returns date sequence \"YYYY-MM-DD\".","code":""},{"path":"https://niehs.github.io/amadeus/reference/generate_date_sequence.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate date sequence ‚Äî generate_date_sequence","text":"vector","code":""},{"path":"https://niehs.github.io/amadeus/reference/generate_time_sequence.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate time sequence ‚Äî generate_time_sequence","title":"Generate time sequence ‚Äî generate_time_sequence","text":"Generate sequence time values based GEOS-CF collection.","code":""},{"path":"https://niehs.github.io/amadeus/reference/generate_time_sequence.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate time sequence ‚Äî generate_time_sequence","text":"","code":"generate_time_sequence(collection)"},{"path":"https://niehs.github.io/amadeus/reference/generate_time_sequence.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate time sequence ‚Äî generate_time_sequence","text":"collection character(1). GEOS-CF data collection","code":""},{"path":"https://niehs.github.io/amadeus/reference/generate_time_sequence.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate time sequence ‚Äî generate_time_sequence","text":"vector","code":""},{"path":"https://niehs.github.io/amadeus/reference/generate_time_sequence.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Generate time sequence ‚Äî generate_time_sequence","text":"GEOS-CF hourly values observed hour (ie. 0000 = 12:00:00 , 0100 = 01:00:00 ) half hour (ie. 0030 = 12:30:00 , 0130 = 01:30:00 ). Typically, 2-dimensional collections (latitude longitude ) utilize half hour, 3-dimensional collections (latitude, longitude, time) utilize hour.","code":""},{"path":"https://niehs.github.io/amadeus/reference/interactive.html","id":null,"dir":"Reference","previous_headings":"","what":"Open interactive session with container.sif container. ‚Äî interactive","title":"Open interactive session with container.sif container. ‚Äî interactive","text":"Open interactive session container.sif container.","code":""},{"path":"https://niehs.github.io/amadeus/reference/interactive.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Open interactive session with container.sif container. ‚Äî interactive","text":"","code":"interactive(dir = \".\")"},{"path":"https://niehs.github.io/amadeus/reference/interactive.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Open interactive session with container.sif container. ‚Äî interactive","text":"dir character(1). Directory interactive.sh","code":""},{"path":"https://niehs.github.io/amadeus/reference/is_date_proper.html","id":null,"dir":"Reference","previous_headings":"","what":"Check date format ‚Äî is_date_proper","title":"Check date format ‚Äî is_date_proper","text":"Check date input strings conform required format.","code":""},{"path":"https://niehs.github.io/amadeus/reference/is_date_proper.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check date format ‚Äî is_date_proper","text":"","code":"is_date_proper(instr = NULL, format = \"%Y-%m-%d\")"},{"path":"https://niehs.github.io/amadeus/reference/is_date_proper.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check date format ‚Äî is_date_proper","text":"instr character(1). String check. format character(1). Matching format checked. Default \"%Y-%m-%d\", can detect \"%Y/%m/%d. See strftime details formatting string.","code":""},{"path":"https://niehs.github.io/amadeus/reference/is_date_proper.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check date format ‚Äî is_date_proper","text":"returning value. stops function instr conform format.","code":""},{"path":"https://niehs.github.io/amadeus/reference/is_date_proper.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Check date format ‚Äî is_date_proper","text":"Insang Song","code":""},{"path":"https://niehs.github.io/amadeus/reference/narr_variable.html","id":null,"dir":"Reference","previous_headings":"","what":"Sort NOAA NARR variables ‚Äî narr_variable","title":"Sort NOAA NARR variables ‚Äî narr_variable","text":"Determine whether NOAA NARR variable selected download monolevel pressure level variable. Monolevel variables derived https://downloads.psl.noaa.gov/Datasets/NARR/Dailies/monolevel/, pressure level variables derived https://downloads.psl.noaa.gov//Datasets/NARR/Dailies/pressure/.","code":""},{"path":"https://niehs.github.io/amadeus/reference/narr_variable.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sort NOAA NARR variables ‚Äî narr_variable","text":"","code":"narr_variable(variable)"},{"path":"https://niehs.github.io/amadeus/reference/narr_variable.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sort NOAA NARR variables ‚Äî narr_variable","text":"variable character(1). User-selected NARR variable","code":""},{"path":"https://niehs.github.io/amadeus/reference/narr_variable.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sort NOAA NARR variables ‚Äî narr_variable","text":"list URL base vector months (blank monolevel)","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_aqs.html","id":null,"dir":"Reference","previous_headings":"","what":"Process U.S. EPA AQS daily CSV data ‚Äî process_aqs","title":"Process U.S. EPA AQS daily CSV data ‚Äî process_aqs","text":"process_aqs() function cleans imports raw air quality monitoring sites pre-generated daily CSV files, returning single SpatVector sf object. date used filter raw data read csv files. Filtered rows processed according mode argument. sites report multiple measurements per day without exceptional events internal procedure function keeps \"Included\" multiple event types per site-time.","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_aqs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Process U.S. EPA AQS daily CSV data ‚Äî process_aqs","text":"","code":"process_aqs(   path = NULL,   date = c(\"2018-01-01\", \"2022-12-31\"),   mode = c(\"date-location\", \"available-data\", \"location\"),   data_field = \"Arithmetic.Mean\",   return_format = c(\"terra\", \"sf\", \"data.table\"),   extent = NULL,   ... )"},{"path":"https://niehs.github.io/amadeus/reference/process_aqs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Process U.S. EPA AQS daily CSV data ‚Äî process_aqs","text":"path character(1). Directory path daily measurement data. date character(1 2). Date (1) start end dates (2). \"YYYY-MM-DD\" format sorted. mode character(1). One \"date-location\" (dates * locations) \"available-data\" (date-location pairs available data) \"location\" (unique locations). data_field character(1). Data field extract. return_format character(1). \"terra\" \"sf\" \"data.table\". extent numeric(4). Spatial extent resulting object. order c(xmin, xmax, ymin, ymax). coordinate system WGS84 (EPSG:4326). ... Placeholders.","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_aqs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Process U.S. EPA AQS daily CSV data ‚Äî process_aqs","text":"SpatVector, sf, data.table object depending return_format","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_aqs.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Process U.S. EPA AQS daily CSV data ‚Äî process_aqs","text":"Choose date mode values caution. function may return massive data.table depending time range, resulting long processing time even crash data large computing environment process.","code":""},{"path":[]},{"path":"https://niehs.github.io/amadeus/reference/process_aqs.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Process U.S. EPA AQS daily CSV data ‚Äî process_aqs","text":"","code":"## NOTE: Example is wrapped in `\\dontrun{}` as function requires a large ##       amount of data which is not included in the package. if (FALSE) { # \\dontrun{ aqs <- process_aqs(   path = \"./data/aqs_daily_example.csv\",   date = c(\"2022-12-01\", \"2023-01-31\"),   mode = \"full\",   return_format = \"terra\" ) } # }"},{"path":"https://niehs.github.io/amadeus/reference/process_blackmarble.html","id":null,"dir":"Reference","previous_headings":"","what":"Assign VIIRS Black Marble products corner coordinates to retrieve a merged raster ‚Äî process_blackmarble","title":"Assign VIIRS Black Marble products corner coordinates to retrieve a merged raster ‚Äî process_blackmarble","text":"function return SpatRaster object georeferenced h5 files Black Marble product. Referencing corner coordinates necessary original h5 data include information.","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_blackmarble.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Assign VIIRS Black Marble products corner coordinates to retrieve a merged raster ‚Äî process_blackmarble","text":"","code":"process_blackmarble(   path = NULL,   date = NULL,   tile_df = process_blackmarble_corners(),   subdataset = 3L,   crs = \"EPSG:4326\",   ... )"},{"path":"https://niehs.github.io/amadeus/reference/process_blackmarble.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Assign VIIRS Black Marble products corner coordinates to retrieve a merged raster ‚Äî process_blackmarble","text":"path character. Full paths h5 files. date character(1). Date query. tile_df data.frame. Contains four corner coordinates fields named c(\"xmin\", \"xmax\", \"ymin\", \"ymax\"). See process_blackmarble_corners generate valid object argument. subdataset integer(1). Subdataset number process. Default 3L. crs character(1). terra::crs compatible CRS. Default \"EPSG:4326\" ... internal use.","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_blackmarble.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Assign VIIRS Black Marble products corner coordinates to retrieve a merged raster ‚Äî process_blackmarble","text":"SpatRaster object","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_blackmarble.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Assign VIIRS Black Marble products corner coordinates to retrieve a merged raster ‚Äî process_blackmarble","text":"Wang, Z. (2022). Black Marble User Guide (Version 1.3). NASA.","code":""},{"path":[]},{"path":"https://niehs.github.io/amadeus/reference/process_blackmarble.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Assign VIIRS Black Marble products corner coordinates to retrieve a merged raster ‚Äî process_blackmarble","text":"Insang Song","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_blackmarble.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Assign VIIRS Black Marble products corner coordinates to retrieve a merged raster ‚Äî process_blackmarble","text":"","code":"## NOTE: Example is wrapped in `\\dontrun{}` as function requires a large ##       amount of data which is not included in the package. if (FALSE) { # \\dontrun{ vnp46a2 <- process_blackmarble(   path =     list.files(\"./data\", pattern = \"VNP46A2.\", full.names = TRUE),   date = \"2024-01-01\",   tile_df =     process_blackmarble_corners(hrange = c(8, 10), vrange = c(4, 5)),   subdataset = 3L,   crs = \"EPSG:4326\" ) } # }"},{"path":"https://niehs.github.io/amadeus/reference/process_blackmarble_corners.html","id":null,"dir":"Reference","previous_headings":"","what":"Process Black Marble corners ‚Äî process_blackmarble_corners","title":"Process Black Marble corners ‚Äî process_blackmarble_corners","text":"Tile corner generator Black Marble products. Black Marble products HDF5 format read without georeference typical R geospatial packages. function generates data.frame corner coordinates assignment.","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_blackmarble_corners.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Process Black Marble corners ‚Äî process_blackmarble_corners","text":"","code":"process_blackmarble_corners(hrange = c(5, 11), vrange = c(3, 6))"},{"path":"https://niehs.github.io/amadeus/reference/process_blackmarble_corners.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Process Black Marble corners ‚Äî process_blackmarble_corners","text":"hrange integer(2). 0-35. vrange integer(2). 0-17.","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_blackmarble_corners.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Process Black Marble corners ‚Äî process_blackmarble_corners","text":"data.frame xmin, xmax, ymin, ymax fields","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_blackmarble_corners.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Process Black Marble corners ‚Äî process_blackmarble_corners","text":"Wang, Z. (2022). Black Marble User Guide (Version 1.3). NASA.","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_blackmarble_corners.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Process Black Marble corners ‚Äî process_blackmarble_corners","text":"Insang Song","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_blackmarble_corners.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Process Black Marble corners ‚Äî process_blackmarble_corners","text":"","code":"process_blackmarble_corners(hrange = c(1, 2), vrange = c(1, 2)) #>     tile xmin xmax ymin ymax #> 1 h01v01 -170 -160   70   80 #> 2 h01v02 -170 -160   60   70 #> 3 h02v01 -160 -150   70   80 #> 4 h02v02 -160 -150   60   70"},{"path":"https://niehs.github.io/amadeus/reference/process_collection.html","id":null,"dir":"Reference","previous_headings":"","what":"Process GEOS-CF and MERRA2 collection codes ‚Äî process_collection","title":"Process GEOS-CF and MERRA2 collection codes ‚Äî process_collection","text":"Identify GEOS-CF MERRA2 collection based file path.","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_collection.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Process GEOS-CF and MERRA2 collection codes ‚Äî process_collection","text":"","code":"process_collection(   path,   source,   collection = FALSE,   date = FALSE,   datetime = FALSE )"},{"path":"https://niehs.github.io/amadeus/reference/process_collection.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Process GEOS-CF and MERRA2 collection codes ‚Äî process_collection","text":"path character(1). File path data file. source character(1). \"geos\" GEOS-CF \"merra2\" MERRA2 collection logical(1). Identifies returns collection name(s) based provided file path(s). date logical(1). Identifies returns date sequence (YYYYMMDD) based provided file path(s). datetime logical(1). Identifies returns date time sequence (YYYYMoMoDDHHMiMi) based provided file path(s).","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_collection.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Process GEOS-CF and MERRA2 collection codes ‚Äî process_collection","text":"character","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_conformity.html","id":null,"dir":"Reference","previous_headings":"","what":"Check input assumptions ‚Äî process_conformity","title":"Check input assumptions ‚Äî process_conformity","text":"Check \"lon\", \"lat\", \"time\" (check_time = TRUE) convert inputs SpatVector object.","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_conformity.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check input assumptions ‚Äî process_conformity","text":"","code":"process_conformity(locs = NULL, check_time = FALSE, locs_epsg = \"EPSG:4326\")"},{"path":"https://niehs.github.io/amadeus/reference/process_conformity.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check input assumptions ‚Äî process_conformity","text":"locs Data. sf, SpatVector, data.frame check_time logical(1). Whether \"time\" exists column names. locs_epsg character(1). \"{authority}:{code}\" Well-Known Text format coordinate reference system definition.","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_conformity.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check input assumptions ‚Äî process_conformity","text":"SpatVector object","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_conformity.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Check input assumptions ‚Äî process_conformity","text":"Insang Song","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_covariates.html","id":null,"dir":"Reference","previous_headings":"","what":"Process raw data wrapper function ‚Äî process_covariates","title":"Process raw data wrapper function ‚Äî process_covariates","text":"function processes raw data files downloaded download_data. process_covariates underlying source-specific processing functions designed operate raw data files. avoid errors, edit raw data files passing process_covariates.","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_covariates.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Process raw data wrapper function ‚Äî process_covariates","text":"","code":"process_covariates(   covariate = c(\"modis_swath\", \"modis_merge\", \"koppen-geiger\", \"blackmarble\",     \"koeppen-geiger\", \"koppen\", \"koeppen\", \"geos\", \"dummies\", \"gmted\", \"hms\", \"smoke\",     \"sedac_population\", \"population\", \"sedac_groads\", \"groads\", \"roads\", \"nlcd\", \"tri\",     \"narr\", \"nei\", \"ecoregions\", \"ecoregion\", \"merra\", \"merra2\", \"gridmet\",     \"terraclimate\", \"huc\", \"cropscape\", \"cdl\", \"prism\"),   path = NULL,   ... )"},{"path":"https://niehs.github.io/amadeus/reference/process_covariates.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Process raw data wrapper function ‚Äî process_covariates","text":"covariate character(1). Covariate type. path character(1). Directory file path raw data depending covariate value. ... Arguments passed raw data processing function.","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_covariates.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Process raw data wrapper function ‚Äî process_covariates","text":"SpatVector, SpatRaster, sf, character depending covariate type selections.","code":""},{"path":[]},{"path":"https://niehs.github.io/amadeus/reference/process_covariates.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Process raw data wrapper function ‚Äî process_covariates","text":"Insang Song","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_covariates.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Process raw data wrapper function ‚Äî process_covariates","text":"","code":"## NOTE: Example is wrapped in `\\dontrun{}` as function requires a large ##       amount of data which is not included in the package. if (FALSE) { # \\dontrun{ process_covariates(   covariate = \"narr\",   date = c(\"2018-01-01\", \"2018-01-10\"),   variable = \"weasd\",   path = system.file(\"extdata\", \"examples\", \"narr\", \"weasd\") ) } # }"},{"path":"https://niehs.github.io/amadeus/reference/process_cropscape.html","id":null,"dir":"Reference","previous_headings":"","what":"Process CropScape data ‚Äî process_cropscape","title":"Process CropScape data ‚Äî process_cropscape","text":"function imports cleans raw CropScape data, returning single SpatRaster object. Reads CropScape file selected year.","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_cropscape.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Process CropScape data ‚Äî process_cropscape","text":"","code":"process_cropscape(path = NULL, year = 2021, extent = NULL, ...)"},{"path":"https://niehs.github.io/amadeus/reference/process_cropscape.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Process CropScape data ‚Äî process_cropscape","text":"path character giving CropScape data path year numeric giving year CropScape data used extent numeric(4) SpatExtent giving extent raster NULL (default), entire raster loaded ... Placeholders.","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_cropscape.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Process CropScape data ‚Äî process_cropscape","text":"SpatRaster object","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_cropscape.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Process CropScape data ‚Äî process_cropscape","text":"Insang Song","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_cropscape.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Process CropScape data ‚Äî process_cropscape","text":"","code":"## NOTE: Example is wrapped in `\\dontrun{}` as function requires a large ##       amount of data which is not included in the package. if (FALSE) { # \\dontrun{ cropscape <- process_cropscape(   path = \"./data/cropscape_example.tif\",   year = 2020 ) } # }"},{"path":"https://niehs.github.io/amadeus/reference/process_ecoregion.html","id":null,"dir":"Reference","previous_headings":"","what":"Process ecoregion data ‚Äî process_ecoregion","title":"Process ecoregion data ‚Äî process_ecoregion","text":"process_ecoregion function imports cleans raw ecoregion data, returning SpatVector object.","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_ecoregion.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Process ecoregion data ‚Äî process_ecoregion","text":"","code":"process_ecoregion(path = NULL, extent = NULL, ...)"},{"path":"https://niehs.github.io/amadeus/reference/process_ecoregion.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Process ecoregion data ‚Äî process_ecoregion","text":"path character(1). Path Ecoregion Shapefiles extent numeric(4) SpatExtent giving extent raster NULL (default), entire raster loaded ... Placeholders.","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_ecoregion.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Process ecoregion data ‚Äî process_ecoregion","text":"SpatVector object","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_ecoregion.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Process ecoregion data ‚Äî process_ecoregion","text":"function fix Tukey's bridge Portland, . fix ensure EPA air quality monitoring sites located within ecoregion.","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_ecoregion.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Process ecoregion data ‚Äî process_ecoregion","text":"Insang Song","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_ecoregion.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Process ecoregion data ‚Äî process_ecoregion","text":"","code":"## NOTE: Example is wrapped in `\\dontrun{}` as function requires a large ##       amount of data which is not included in the package. if (FALSE) { # \\dontrun{ ecoregion <- process_ecoregion(   path = \"./data/epa_ecoregion.gpkg\" ) } # }"},{"path":"https://niehs.github.io/amadeus/reference/process_flatten_sds.html","id":null,"dir":"Reference","previous_headings":"","what":"Process MODIS layers ‚Äî process_flatten_sds","title":"Process MODIS layers ‚Äî process_flatten_sds","text":"Aggregate layers sub-dataset sinusoidal MODIS products. MODIS products consist multi-layer subdatasets. function aggregates multiple layers single layer SpatRaster. fun_agg applied overlapping cells.","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_flatten_sds.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Process MODIS layers ‚Äî process_flatten_sds","text":"","code":"process_flatten_sds(path = NULL, subdataset = NULL, fun_agg = \"mean\", ...)"},{"path":"https://niehs.github.io/amadeus/reference/process_flatten_sds.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Process MODIS layers ‚Äî process_flatten_sds","text":"path character(1). Full path MODIS HDF4/HDF5 file. Direct sub-dataset access supported, example, HDF4_EOS:EOS_GRID:{filename}:{base_grid_information}:{sub-dataset} subdataset character(1). Exact regular expression filter sub-dataset. See process_modis_sds details. fun_agg character(1). Function name aggregate layers. acceptable terra::tapp. ... Placeholders.","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_flatten_sds.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Process MODIS layers ‚Äî process_flatten_sds","text":"SpatRaster object","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_flatten_sds.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Process MODIS layers ‚Äî process_flatten_sds","text":"HDF values read original without scaling. Users consult MODIS product documentation apply proper scaling factor post-hoc adjustment. users preliminary information MODIS sub-datasets, consider running terra::describe(__filename__, sds = TRUE) navigate full list sub-datasets input file consult documentation MODIS product.","code":""},{"path":[]},{"path":"https://niehs.github.io/amadeus/reference/process_flatten_sds.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Process MODIS layers ‚Äî process_flatten_sds","text":"Insang Song","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_flatten_sds.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Process MODIS layers ‚Äî process_flatten_sds","text":"","code":"## NOTE: Example is wrapped in `\\dontrun{}` as function requires a large ##       amount of data which is not included in the package. if (FALSE) { # \\dontrun{ mod09ga_flatten <- process_flatten_sds(   path =     list.files(\"./data\", pattern = \"MOD09GA.\", full.names = TRUE)[1],   subdataset = process_modis_sds(\"MOD09GA\"),   fun_agg = \"mean\" ) } # }"},{"path":"https://niehs.github.io/amadeus/reference/process_geos.html","id":null,"dir":"Reference","previous_headings":"","what":"Process atmospheric composition data ‚Äî process_geos","title":"Process atmospheric composition data ‚Äî process_geos","text":"process_geos() function imports cleans raw atmospheric composition data, returning single SpatRaster object.","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_geos.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Process atmospheric composition data ‚Äî process_geos","text":"","code":"process_geos(   date = c(\"2018-01-01\", \"2018-01-10\"),   variable = NULL,   path = NULL,   extent = NULL,   ... )"},{"path":"https://niehs.github.io/amadeus/reference/process_geos.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Process atmospheric composition data ‚Äî process_geos","text":"date character(1 2). Date (1) start end dates (2). Format YYYY-MM-DD (ex. September 1, 2023 = \"2023-09-01\"). variable character(1). GEOS-CF variable name(s). path character(1). Directory downloaded netCDF (.nc4) files. extent numeric(4) SpatExtent giving extent raster NULL (default), entire raster loaded ... Placeholders.","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_geos.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Process atmospheric composition data ‚Äî process_geos","text":"SpatRaster object;","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_geos.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Process atmospheric composition data ‚Äî process_geos","text":"Layer names returned SpatRaster object contain variable, pressure level, date, hour.","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_geos.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Process atmospheric composition data ‚Äî process_geos","text":"Mitchell Manware","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_geos.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Process atmospheric composition data ‚Äî process_geos","text":"","code":"## NOTE: Example is wrapped in `\\dontrun{}` as function requires a large ##       amount of data which is not included in the package. if (FALSE) { # \\dontrun{ geos <- process_geos(   date = c(\"2024-01-01\", \"2024-01-10\"),   variable = \"O3\",   path = \"./data/aqc_tavg_1hr_g1440x721_v1\" ) } # }"},{"path":"https://niehs.github.io/amadeus/reference/process_gmted.html","id":null,"dir":"Reference","previous_headings":"","what":"Process elevation data ‚Äî process_gmted","title":"Process elevation data ‚Äî process_gmted","text":"process_gmted() function imports cleans raw elevation data, returning single SpatRaster object.","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_gmted.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Process elevation data ‚Äî process_gmted","text":"","code":"process_gmted(variable = NULL, path = NULL, extent = NULL, ...)"},{"path":"https://niehs.github.io/amadeus/reference/process_gmted.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Process elevation data ‚Äî process_gmted","text":"variable vector(1). Vector containing GMTED statistic first resolution second. (Example: variable = c(\"Breakline Emphasis\", \"7.5 arc-seconds\")). Statistic options: \"Breakline Emphasis\", \"Systematic Subsample\", \"Median Statistic\", \"Minimum Statistic\", \"Mean Statistic\", \"Maximum Statistic\", \"Standard Deviation Statistic\" Resolution options: \"30 arc-seconds\", \"15 arc-seconds\", \"7.5 arc-seconds\" path character(1). Directory downloaded GMTED  \"*_grd\" folder containing .adf files. extent numeric(4) SpatExtent giving extent raster NULL (default), entire raster loaded ... Placeholders.","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_gmted.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Process elevation data ‚Äî process_gmted","text":"SpatRaster object","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_gmted.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Process elevation data ‚Äî process_gmted","text":"SpatRaster layer name indicates selected variable resolution, year release (2010).","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_gmted.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Process elevation data ‚Äî process_gmted","text":"Mitchell Manware","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_gmted.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Process elevation data ‚Äî process_gmted","text":"","code":"## NOTE: Example is wrapped in `\\dontrun{}` as function requires a large ##       amount of data which is not included in the package. if (FALSE) { # \\dontrun{ gmted <- process_gmted(   variable = c(\"Breakline Emphasis\", \"7.5 arc-seconds\"),   path = \"./data/be75_grd\" ) } # }"},{"path":"https://niehs.github.io/amadeus/reference/process_gmted_codes.html","id":null,"dir":"Reference","previous_headings":"","what":"Process elevation statistic and resolution codes ‚Äî process_gmted_codes","title":"Process elevation statistic and resolution codes ‚Äî process_gmted_codes","text":"Identify GMTED statistic resolution based file path. Convert statistic resolution /full string /statistic resolution code.","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_gmted_codes.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Process elevation statistic and resolution codes ‚Äî process_gmted_codes","text":"","code":"process_gmted_codes(   string,   statistic = FALSE,   resolution = FALSE,   invert = FALSE )"},{"path":"https://niehs.github.io/amadeus/reference/process_gmted_codes.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Process elevation statistic and resolution codes ‚Äî process_gmted_codes","text":"string character(1). File path GMTED data file. statistic logical(1). Matches statistic statistic code. resolution logical(1). Matches resolution resolution code. invert logical(1). Default = FALSE. invert = TRUE assumes string provides statistic resolution code, returns full length statistic resolution.","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_gmted_codes.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Process elevation statistic and resolution codes ‚Äî process_gmted_codes","text":"character","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_gridmet.html","id":null,"dir":"Reference","previous_headings":"","what":"Process gridMET data ‚Äî process_gridmet","title":"Process gridMET data ‚Äî process_gridmet","text":"process_gridmet() function imports cleans raw gridded surface meteorological data, returning single SpatRaster object.","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_gridmet.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Process gridMET data ‚Äî process_gridmet","text":"","code":"process_gridmet(   date = c(\"2023-09-01\", \"2023-09-10\"),   variable = NULL,   path = NULL,   extent = NULL,   ... )"},{"path":"https://niehs.github.io/amadeus/reference/process_gridmet.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Process gridMET data ‚Äî process_gridmet","text":"date character(1 2). Date (1) start end dates (2). Format YYYY-MM-DD (ex. September 1, 2023 = \"2023-09-01\"). variable character(1). Variable name acronym code. See gridMET Generate Wget File variable names acronym codes. (Note: variable \"Burning Index\" code \"bi\" variable \"Energy Release Component\" code \"erc\"). path character(1). Directory downloaded netCDF (.nc) files. extent numeric(4) SpatExtent giving extent raster NULL (default), entire raster loaded ... Placeholders.","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_gridmet.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Process gridMET data ‚Äî process_gridmet","text":"SpatRaster object","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_gridmet.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Process gridMET data ‚Äî process_gridmet","text":"Layer names returned SpatRaster object contain variable acronym, date.","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_gridmet.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Process gridMET data ‚Äî process_gridmet","text":"Mitchell Manware","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_gridmet.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Process gridMET data ‚Äî process_gridmet","text":"","code":"## NOTE: Example is wrapped in `\\dontrun{}` as function requires a large ##       amount of data which is not included in the package. if (FALSE) { # \\dontrun{ gridmet <- process_gridmet(   date = c(\"2023-01-01\", \"2023-01-10\"),   variable = \"Precipitation\",   path = \"./data/pr\" ) } # }"},{"path":"https://niehs.github.io/amadeus/reference/process_gridmet_codes.html","id":null,"dir":"Reference","previous_headings":"","what":"Process gridMET variable codes ‚Äî process_gridmet_codes","title":"Process gridMET variable codes ‚Äî process_gridmet_codes","text":"Convert gridMET variable names /variable codes.","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_gridmet_codes.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Process gridMET variable codes ‚Äî process_gridmet_codes","text":"","code":"process_gridmet_codes(string, invert = FALSE)"},{"path":"https://niehs.github.io/amadeus/reference/process_gridmet_codes.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Process gridMET variable codes ‚Äî process_gridmet_codes","text":"string character(1). gridMET variable name variable code. invert logical(1). Default = FALSE. invert = TRUE assumes string provides variable code returns full length variable name.","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_gridmet_codes.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Process gridMET variable codes ‚Äî process_gridmet_codes","text":"character","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_groads.html","id":null,"dir":"Reference","previous_headings":"","what":"Process roads data ‚Äî process_groads","title":"Process roads data ‚Äî process_groads","text":"process_groads() function imports cleans raw road data, returning single SpatVector object.","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_groads.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Process roads data ‚Äî process_groads","text":"","code":"process_groads(path = NULL, extent = NULL, ...)"},{"path":"https://niehs.github.io/amadeus/reference/process_groads.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Process roads data ‚Äî process_groads","text":"path character(1). Path geodatabase shapefiles. extent numeric(4) SpatExtent giving extent raster NULL (default), entire raster loaded ... Placeholders.","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_groads.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Process roads data ‚Äî process_groads","text":"SpatVector object","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_groads.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Process roads data ‚Äî process_groads","text":"U.S. context. returned SpatVector object contains $description column represent temporal range covered dataset. information, see https://data.nasa.gov/dataset/global-roads-open-access-data-set-version-1-groadsv1.","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_groads.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Process roads data ‚Äî process_groads","text":"Insang Song","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_groads.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Process roads data ‚Äî process_groads","text":"","code":"## NOTE: Example is wrapped in `\\dontrun{}` as function requires a large ##       amount of data which is not included in the package. if (FALSE) { # \\dontrun{ groads <- process_groads(   path = \"./data/groads_example.shp\" ) } # }"},{"path":"https://niehs.github.io/amadeus/reference/process_hms.html","id":null,"dir":"Reference","previous_headings":"","what":"Process wildfire smoke data ‚Äî process_hms","title":"Process wildfire smoke data ‚Äî process_hms","text":"process_hms() function imports cleans raw wildfire smoke plume coverage data, returning single SpatVector object.","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_hms.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Process wildfire smoke data ‚Äî process_hms","text":"","code":"process_hms(date = \"2018-01-01\", path = NULL, extent = NULL, ...)"},{"path":"https://niehs.github.io/amadeus/reference/process_hms.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Process wildfire smoke data ‚Äî process_hms","text":"date character(1 2). Date (1) start end dates (2). Format YYYY-MM-DD (ex. September 1, 2023 = \"2023-09-01\"). path character(1). Directory downloaded NOAA HMS data files. extent numeric(4) SpatExtent giving extent output NULL (default), entire data returned ... Placeholders.","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_hms.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Process wildfire smoke data ‚Äî process_hms","text":"SpatVector character object","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_hms.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Process wildfire smoke data ‚Äî process_hms","text":"process_hms() return character object wildfire smoke plumes present selected dates density. returned character contain density value sequence dates wildfire smoke plumes detected (see \"Examples\"). multiple density polygons overlap, function return highest density value.","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_hms.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Process wildfire smoke data ‚Äî process_hms","text":"Mitchell Manware","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_hms.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Process wildfire smoke data ‚Äî process_hms","text":"","code":"hms <- process_hms(   date = c(\"2018-12-30\", \"2019-01-01\"),   path = \"../tests/testdata/hms/\" ) #> Smoke plume polygons absent from 2018-12-30 to 2019-01-01. Returning vector of dates."},{"path":"https://niehs.github.io/amadeus/reference/process_huc.html","id":null,"dir":"Reference","previous_headings":"","what":"Retrieve Hydrologic Unit Code (HUC) data ‚Äî process_huc","title":"Retrieve Hydrologic Unit Code (HUC) data ‚Äî process_huc","text":"Retrieve Hydrologic Unit Code (HUC) data","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_huc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Retrieve Hydrologic Unit Code (HUC) data ‚Äî process_huc","text":"","code":"process_huc(   path,   layer_name = NULL,   huc_level = NULL,   huc_header = NULL,   extent = NULL,   ... )"},{"path":"https://niehs.github.io/amadeus/reference/process_huc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Retrieve Hydrologic Unit Code (HUC) data ‚Äî process_huc","text":"path character. Path file directory containing HUC data. layer_name character(1). Layer name path huc_level character(1). Field name HUC level huc_header character(1). upper level HUC code header extract lower level HUCs. extent numeric(4) SpatExtent giving extent raster NULL (default), entire raster loaded ... Arguments passed nhdplusTools::get_huc()","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_huc.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Retrieve Hydrologic Unit Code (HUC) data ‚Äî process_huc","text":"SpatVector object","code":""},{"path":[]},{"path":"https://niehs.github.io/amadeus/reference/process_huc.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Retrieve Hydrologic Unit Code (HUC) data ‚Äî process_huc","text":"Insang Song","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_huc.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Retrieve Hydrologic Unit Code (HUC) data ‚Äî process_huc","text":"","code":"## NOTE: Examples are wrapped in `\\dontrun{}` as function requires a large ##       amount of data which is not included in the package. if (FALSE) { # \\dontrun{ library(terra) getf <- \"WBD_National_GDB.gdb\" # check the layer name to read terra::vector_layers(getf) test1 <- process_huc(   getf,   layer_name = \"WBDHU8\",   huc_level = \"huc8\" ) test2 <- process_huc(   getf,   layer_name = \"WBDHU8\",   huc_level = \"huc8\" ) test3 <- process_huc(   \"\",   layer_name = NULL,   huc_level = NULL,   huc_header = NULL,   id = \"030202\",   type = \"huc06\" ) } # }"},{"path":"https://niehs.github.io/amadeus/reference/process_koppen_geiger.html","id":null,"dir":"Reference","previous_headings":"","what":"Process climate classification data ‚Äî process_koppen_geiger","title":"Process climate classification data ‚Äî process_koppen_geiger","text":"process_koppen_geiger() function imports cleans raw climate classification data, returning single SpatRaster object.","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_koppen_geiger.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Process climate classification data ‚Äî process_koppen_geiger","text":"","code":"process_koppen_geiger(path = NULL, extent = NULL, ...)"},{"path":"https://niehs.github.io/amadeus/reference/process_koppen_geiger.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Process climate classification data ‚Äî process_koppen_geiger","text":"path character(1). Path Koppen-Geiger climate zone raster file extent numeric(4) SpatExtent giving extent raster NULL (default), entire raster loaded ... Placeholders.","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_koppen_geiger.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Process climate classification data ‚Äî process_koppen_geiger","text":"SpatRaster object","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_koppen_geiger.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Process climate classification data ‚Äî process_koppen_geiger","text":"Insang Song","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_koppen_geiger.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Process climate classification data ‚Äî process_koppen_geiger","text":"","code":"## NOTE: Example is wrapped in `\\dontrun{}` as function requires a large ##       amount of data which is not included in the package. if (FALSE) { # \\dontrun{ kg <- process_koppen_geiger(   path = \"./data/koppen_geiger_data.tif\" ) } # }"},{"path":"https://niehs.github.io/amadeus/reference/process_locs_radius.html","id":null,"dir":"Reference","previous_headings":"","what":"Process locations buffer ‚Äî process_locs_radius","title":"Process locations buffer ‚Äî process_locs_radius","text":"Create circular buffer around locations based user defined radius. Creates circular buffer around points radius > 0. Returns points radius 0.","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_locs_radius.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Process locations buffer ‚Äî process_locs_radius","text":"","code":"process_locs_radius(locs, radius)"},{"path":"https://niehs.github.io/amadeus/reference/process_locs_radius.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Process locations buffer ‚Äî process_locs_radius","text":"locs SpatVector(1). SpatVector object point geometry radius integer(1). Circular buffer size (meters).","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_locs_radius.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Process locations buffer ‚Äî process_locs_radius","text":"SpatVector object","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_locs_vector.html","id":null,"dir":"Reference","previous_headings":"","what":"Process locations as SpatVector ‚Äî process_locs_vector","title":"Process locations as SpatVector ‚Äî process_locs_vector","text":"Detect SpatVector object, convert locations class sf, data.frame data.table SpatVector object, project coordinate reference system, apply circular buffer.","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_locs_vector.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Process locations as SpatVector ‚Äî process_locs_vector","text":"","code":"process_locs_vector(locs, crs, radius)"},{"path":"https://niehs.github.io/amadeus/reference/process_locs_vector.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Process locations as SpatVector ‚Äî process_locs_vector","text":"locs data.frame(1). Data frame containing columns unique identifier, latitude, longitude. Latitude longitude columns must named \"lat\" \"lon\", respectively. crs Coordinate reference system (CRS) description utilizing terra::crs(). radius integer(1). Circular buffer size (meters).","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_locs_vector.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Process locations as SpatVector ‚Äî process_locs_vector","text":"SpatVector object","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_merra2.html","id":null,"dir":"Reference","previous_headings":"","what":"Process meteorological and atmospheric data ‚Äî process_merra2","title":"Process meteorological and atmospheric data ‚Äî process_merra2","text":"process_merra2() function imports cleans raw atmospheric composition data, returning single SpatRaster object.","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_merra2.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Process meteorological and atmospheric data ‚Äî process_merra2","text":"","code":"process_merra2(   date = c(\"2018-01-01\", \"2018-01-10\"),   variable = NULL,   path = NULL,   extent = NULL,   ... )"},{"path":"https://niehs.github.io/amadeus/reference/process_merra2.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Process meteorological and atmospheric data ‚Äî process_merra2","text":"date character(1 2). Date (1) start end dates (2). Format YYYY-MM-DD (ex. September 1, 2023 = \"2023-09-01\"). variable character(1). MERRA2 variable name(s). path character(1). Directory downloaded netCDF (.nc4) files. extent numeric(4) SpatExtent giving extent raster NULL (default), entire raster loaded ... Placeholders.","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_merra2.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Process meteorological and atmospheric data ‚Äî process_merra2","text":"SpatRaster object;","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_merra2.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Process meteorological and atmospheric data ‚Äî process_merra2","text":"Layer names returned SpatRaster object contain variable, pressure level, date, hour. Pressure level values utilized layer names taken directly raw data edited retain pressure level information.","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_merra2.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Process meteorological and atmospheric data ‚Äî process_merra2","text":"Mitchell Manware","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_merra2.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Process meteorological and atmospheric data ‚Äî process_merra2","text":"","code":"## NOTE: Example is wrapped in `\\dontrun{}` as function requires a large ##       amount of data which is not included in the package. if (FALSE) { # \\dontrun{ merra2 <- process_merra2(   date = c(\"2024-01-01\", \"2024-01-10\"),   variable = \"CPT\",   path = \"./data/inst1_2d_int_Nx\" ) } # }"},{"path":"https://niehs.github.io/amadeus/reference/process_merra2_time.html","id":null,"dir":"Reference","previous_headings":"","what":"Process MERRA2 time steps ‚Äî process_merra2_time","title":"Process MERRA2 time steps ‚Äî process_merra2_time","text":"Identify time step data observations based MERRA2 collection filter time values .","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_merra2_time.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Process MERRA2 time steps ‚Äî process_merra2_time","text":"","code":"process_merra2_time(collection, from)"},{"path":"https://niehs.github.io/amadeus/reference/process_merra2_time.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Process MERRA2 time steps ‚Äî process_merra2_time","text":"collection character(1). MERRA2 collection name. SpatRaster(1). Object extract time values .","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_merra2_time.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Process MERRA2 time steps ‚Äî process_merra2_time","text":"character","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_modis_merge.html","id":null,"dir":"Reference","previous_headings":"","what":"Process MODIS .hdf files ‚Äî process_modis_merge","title":"Process MODIS .hdf files ‚Äî process_modis_merge","text":"Get mosaicked merged raster multiple MODIS hdf files.","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_modis_merge.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Process MODIS .hdf files ‚Äî process_modis_merge","text":"","code":"process_modis_merge(   path = NULL,   date = NULL,   subdataset = NULL,   fun_agg = \"mean\",   ... )"},{"path":"https://niehs.github.io/amadeus/reference/process_modis_merge.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Process MODIS .hdf files ‚Äî process_modis_merge","text":"path character. Full list hdf file paths. preferably recursive search result base::list.files. date character(1). date query. \"YYYY-MM-DD\" format. subdataset character(1). subdataset names extract. conform regular expression. See base::regex details. Default NULL, result errors. Users specify subdatasets imported. fun_agg Function name custom function aggregate overlapping cell values. See fun description terra::tapp details. ... internal use.","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_modis_merge.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Process MODIS .hdf files ‚Äî process_modis_merge","text":"SpatRaster object","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_modis_merge.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Process MODIS .hdf files ‚Äî process_modis_merge","text":"Curvilinear products (.e., swaths) accepted. MODIS products downloaded functions amadeus, MODISTools, luna accepted.","code":""},{"path":[]},{"path":"https://niehs.github.io/amadeus/reference/process_modis_merge.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Process MODIS .hdf files ‚Äî process_modis_merge","text":"Insang Song","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_modis_merge.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Process MODIS .hdf files ‚Äî process_modis_merge","text":"","code":"## NOTE: Example is wrapped in `\\dontrun{}` as function requires a large ##       amount of data which is not included in the package. if (FALSE) { # \\dontrun{ mod09ga_merge <- process_modis_merge(   path =     list.files(\"./data\", pattern = \"MOD09GA.\", full.names = TRUE),   date = \"2024-01-01\",   subdataset = \"sur_refl_b01_1\",   fun_agg = \"mean\" ) } # }"},{"path":"https://niehs.github.io/amadeus/reference/process_modis_sds.html","id":null,"dir":"Reference","previous_headings":"","what":"Process MODIS sub-datasets ‚Äî process_modis_sds","title":"Process MODIS sub-datasets ‚Äî process_modis_sds","text":"Selected MODIS sinusoidal grid product subdataset name selector. Four presets supported. custom_sel supersedes presets product values.","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_modis_sds.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Process MODIS sub-datasets ‚Äî process_modis_sds","text":"","code":"process_modis_sds(   product = c(\"MOD11A1\", \"MOD13A2\", \"MOD09GA\", \"MCD19A2\"),   custom_sel = NULL,   ... )"},{"path":"https://niehs.github.io/amadeus/reference/process_modis_sds.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Process MODIS sub-datasets ‚Äî process_modis_sds","text":"product character(1). Product code. custom_sel character(1). Custom filter. value NULL, preset filter overridden. ... Placeholders.","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_modis_sds.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Process MODIS sub-datasets ‚Äî process_modis_sds","text":"character object conforms regular expression. Details regular expression R can found regexp.","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_modis_sds.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Process MODIS sub-datasets ‚Äî process_modis_sds","text":"Preset product codes associated variables include \"MOD11A1\" - Land surface temperature (LST) \"MOD13A2\" - Normalized Difference Vegetation Index (NDVI) \"MOD09GA\" - Surface reflectance, \"MCD19A2\" - Aerosol optical depth (AOD). full list available MODIS product codes, see \"Short Name\" column NASA LP DAAC Search Data Catalog. utilizing product code \"Short Name\" column, include version number following period. example, \"Short Name\" = MCD12C1.006, product = \"MCD12C1\".","code":""},{"path":[]},{"path":"https://niehs.github.io/amadeus/reference/process_modis_sds.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Process MODIS sub-datasets ‚Äî process_modis_sds","text":"Insang Song","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_modis_sds.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Process MODIS sub-datasets ‚Äî process_modis_sds","text":"","code":"process_modis_sds(product = \"MOD09GA\") #> [1] \"(sur_refl_b0)\""},{"path":"https://niehs.github.io/amadeus/reference/process_modis_swath.html","id":null,"dir":"Reference","previous_headings":"","what":"Mosaic MODIS swaths ‚Äî process_modis_swath","title":"Mosaic MODIS swaths ‚Äî process_modis_swath","text":"function return SpatRaster object values selected subdatasets. Swath data include curvilinear grids, require warping/rectifying original curvilinear grids rectilinear grids. function internally warps inputs mosaic warped images one large SpatRaster object. Users need select subdataset process. full path looks like \"HDF4_EOS:EOS_SWATH:{file_path}:mod06:subdataset\", file_path full path hdf file.","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_modis_swath.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Mosaic MODIS swaths ‚Äî process_modis_swath","text":"","code":"process_modis_swath(   path = NULL,   date = NULL,   subdataset = NULL,   suffix = \":mod06:\",   resolution = 0.05,   ... )"},{"path":"https://niehs.github.io/amadeus/reference/process_modis_swath.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Mosaic MODIS swaths ‚Äî process_modis_swath","text":"path character. Full paths hdf files. date character(1). Date query. subdataset character. Subdatasets process. Unlike preprocessing functions, argument specify exact subdataset name. example, using MOD06_L2 product, one may specify c(\"Cloud_Fraction\", \"Cloud_Optical_Thickness\"), etc. subdataset names can found terra::describe() output. suffix character(1). formatted :{product}:, e.g., :mod06: resolution numeric(1). Resolution output raster. Unit degree (decimal degree WGS84). ... internal use.","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_modis_swath.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Mosaic MODIS swaths ‚Äî process_modis_swath","text":"SpatRaster object (crs = \"EPSG:4326\"): path single file full specification subdataset. SpatRaster object (crs = \"EPSG:4326\"): path list files. case, returned object maximal extent multiple warped layers","code":""},{"path":[]},{"path":"https://niehs.github.io/amadeus/reference/process_modis_swath.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Mosaic MODIS swaths ‚Äî process_modis_swath","text":"Insang Song","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_modis_swath.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Mosaic MODIS swaths ‚Äî process_modis_swath","text":"","code":"## NOTE: Example is wrapped in `\\dontrun{}` as function requires a large ##       amount of data which is not included in the package. if (FALSE) { # \\dontrun{ mod06l2_swath <- process_modis_swath(   path = list.files(     \"./data/mod06l2\",     full.names = TRUE,     pattern = \".hdf\"   ),   date = \"2024-01-01\",   subdataset = \"Cloud_Fraction\",   suffix = \":mod06:\",   resolution = 0.05 ) } # }"},{"path":"https://niehs.github.io/amadeus/reference/process_modis_warp.html","id":null,"dir":"Reference","previous_headings":"","what":"Warp MODIS swath data into rectilinear grid raster ‚Äî process_modis_warp","title":"Warp MODIS swath data into rectilinear grid raster ‚Äî process_modis_warp","text":"Swath data type MODIS data, curvilinear points stored varying resolution depending relative position sensor axis. type data typically work well planar spatial data, users warp rectify data rectilinear raster. Main procedure done stars::st_warp, users able customize threshold fill potential gaps appear target resolution finer local resolution curvilinear grid points.","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_modis_warp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Warp MODIS swath data into rectilinear grid raster ‚Äî process_modis_warp","text":"","code":"process_modis_warp(   path = NULL,   cellsize = 0.1,   threshold = cellsize * 4,   crs = 4326,   ... )"},{"path":"https://niehs.github.io/amadeus/reference/process_modis_warp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Warp MODIS swath data into rectilinear grid raster ‚Äî process_modis_warp","text":"path File path MODIS swath exact sub-dataset specification. cellsize numeric(1). Cell size (spatial resolution) output rectilinear grid raster. threshold numeric(1). Maximum distance fill gaps occur. crs integer(1)/character(1). Coordinate system definition. compatible EPSG codes WKT2. See terra::crs sf::st_crs / EPSG ... internal use.","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_modis_warp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Warp MODIS swath data into rectilinear grid raster ‚Äî process_modis_warp","text":"stars object","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_modis_warp.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Warp MODIS swath data into rectilinear grid raster ‚Äî process_modis_warp","text":"function handles one file time.","code":""},{"path":[]},{"path":"https://niehs.github.io/amadeus/reference/process_modis_warp.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Warp MODIS swath data into rectilinear grid raster ‚Äî process_modis_warp","text":"Insang Song","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_modis_warp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Warp MODIS swath data into rectilinear grid raster ‚Äî process_modis_warp","text":"","code":"## NOTE: Example is wrapped in `\\dontrun{}` as function requires a large ##       amount of data which is not included in the package. if (FALSE) { # \\dontrun{ mod06l2_warp <- process_modis_warp(   path = paste0(     \"HDF4_EOS:EOS_SWATH:\",     list.files(       \"./data/mod06l2\",       full.names = TRUE,       pattern = \".hdf\"     )[1],     \":mod06:Cloud_Fraction\"   ),   cellsize = 0.1,   threshold = 0.4,   crs = 4326 ) } # }"},{"path":"https://niehs.github.io/amadeus/reference/process_narr.html","id":null,"dir":"Reference","previous_headings":"","what":"Process meteorological data ‚Äî process_narr","title":"Process meteorological data ‚Äî process_narr","text":"process_narr() function imports cleans raw meteorological data, returning single SpatRaster object.","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_narr.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Process meteorological data ‚Äî process_narr","text":"","code":"process_narr(   date = \"2023-09-01\",   variable = NULL,   path = NULL,   extent = NULL,   ... )"},{"path":"https://niehs.github.io/amadeus/reference/process_narr.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Process meteorological data ‚Äî process_narr","text":"date character(1 2). Date (1) start end dates (2). Format YYYY-MM-DD (ex. September 1, 2023 = \"2023-09-01\"). variable character(1). Variable name acronym. See List Variables NARR Files variable names acronym codes. path character(1). Directory downloaded netCDF (.nc) files. extent numeric(4) SpatExtent giving extent raster NULL (default), entire raster loaded ... Placeholders.","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_narr.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Process meteorological data ‚Äî process_narr","text":"SpatRaster object","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_narr.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Process meteorological data ‚Äî process_narr","text":"Layer names returned SpatRaster object contain variable acronym, pressure level, date.","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_narr.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Process meteorological data ‚Äî process_narr","text":"Mitchell Manware","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_narr.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Process meteorological data ‚Äî process_narr","text":"","code":"## NOTE: Example is wrapped in `\\dontrun{}` as function requires a large ##       amount of data which is not included in the package. if (FALSE) { # \\dontrun{ process_narr(   date = c(\"2018-01-01\", \"2018-01-10\"),   variable = \"weasd\",   path = \"./tests/testdata/narr/weasd\" ) } # }"},{"path":"https://niehs.github.io/amadeus/reference/process_nei.html","id":null,"dir":"Reference","previous_headings":"","what":"Process road emissions data ‚Äî process_nei","title":"Process road emissions data ‚Äî process_nei","text":"process_nei() function imports cleans raw road emissions data, returning single SpatVector object. NEI data comprises multiple csv files emissions 50+ pollutants recorded county level. raw data files, function join combined table NEI data county boundary, perform spatial join target locations.","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_nei.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Process road emissions data ‚Äî process_nei","text":"","code":"process_nei(path = NULL, county = NULL, year = c(2017, 2020), ...)"},{"path":"https://niehs.github.io/amadeus/reference/process_nei.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Process road emissions data ‚Äî process_nei","text":"path character(1). Directory NEI csv files. county SpatVector/sf. County boundaries. year integer(1) Year use. Currently 2017 2020 accepted. ... Placeholders.","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_nei.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Process road emissions data ‚Äî process_nei","text":"SpatVector object","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_nei.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Process road emissions data ‚Äî process_nei","text":"Base files county argument can downloaded directly U.S. Census Bureau using tigris package. function reproject census boundaries. Users aware coordinate system census boundary data analyses.","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_nei.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Process road emissions data ‚Äî process_nei","text":"Insang Song","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_nei.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Process road emissions data ‚Äî process_nei","text":"","code":"## NOTE: Example is wrapped in `\\dontrun{}` as function requires a large ##       amount of data which is not included in the package. if (FALSE) { # \\dontrun{ nei <- process_nei(   path = \"./data\",   county = system.file(\"gpkg/nc.gpkg\", package = \"sf\"),   year = 2017 ) } # }"},{"path":"https://niehs.github.io/amadeus/reference/process_nlcd.html","id":null,"dir":"Reference","previous_headings":"","what":"Process land cover data ‚Äî process_nlcd","title":"Process land cover data ‚Äî process_nlcd","text":"process_nlcd() function imports cleans raw land cover data, returning single SpatRaster object. Reads NLCD file selected year.","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_nlcd.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Process land cover data ‚Äî process_nlcd","text":"","code":"process_nlcd(path = NULL, year = 2021, extent = NULL, ...)"},{"path":"https://niehs.github.io/amadeus/reference/process_nlcd.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Process land cover data ‚Äî process_nlcd","text":"path character giving nlcd data path year numeric giving year NLCD data used extent numeric(4) SpatExtent giving extent raster NULL (default), entire raster loaded ... Placeholders.","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_nlcd.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Process land cover data ‚Äî process_nlcd","text":"SpatRaster object","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_nlcd.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Process land cover data ‚Äî process_nlcd","text":"Eva Marques, Insang Song","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_nlcd.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Process land cover data ‚Äî process_nlcd","text":"","code":"## NOTE: Example is wrapped in `\\dontrun{}` as function requires a large ##       amount of data which is not included in the package. if (FALSE) { # \\dontrun{ nlcd <- process_nlcd(   path = \"./data/\",   year = 2021 ) } # }"},{"path":"https://niehs.github.io/amadeus/reference/process_population.html","id":null,"dir":"Reference","previous_headings":"","what":"Process population density data ‚Äî process_population","title":"Process population density data ‚Äî process_population","text":"process_secac_population() function imports cleans raw population density data, returning single SpatRaster object.","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_population.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Process population density data ‚Äî process_population","text":"","code":"process_population(path = NULL, extent = NULL, ...)"},{"path":"https://niehs.github.io/amadeus/reference/process_population.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Process population density data ‚Äî process_population","text":"path character(1). Path GeoTIFF (.tif) netCDF (.nc) file. extent numeric(4) SpatExtent giving extent raster NULL (default), entire raster loaded ... Placeholders.","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_population.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Process population density data ‚Äî process_population","text":"SpatRaster object","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_population.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Process population density data ‚Äî process_population","text":"Mitchell Manware","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_population.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Process population density data ‚Äî process_population","text":"","code":"## NOTE: Example is wrapped in `\\dontrun{}` as function requires a large ##       amount of data which is not included in the package. if (FALSE) { # \\dontrun{ pop <- process_population(   path = \"./data/sedac_population_example.tif\" ) } # }"},{"path":"https://niehs.github.io/amadeus/reference/process_prism.html","id":null,"dir":"Reference","previous_headings":"","what":"Process PRISM data ‚Äî process_prism","title":"Process PRISM data ‚Äî process_prism","text":"function imports cleans raw PRISM data, returning single SpatRaster object. Reads time series 30-year normal PRISM data.","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_prism.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Process PRISM data ‚Äî process_prism","text":"","code":"process_prism(path = NULL, element = NULL, time = NULL, extent = NULL, ...)"},{"path":"https://niehs.github.io/amadeus/reference/process_prism.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Process PRISM data ‚Äî process_prism","text":"path character giving PRISM data path file directory path acceptable. element character(1). PRISM element name time character(1). PRISM time name. character length 2, 4, 6, 8. \"annual\" acceptable. extent numeric(4) SpatExtent giving extent raster NULL (default), entire raster loaded ... Placeholders.","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_prism.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Process PRISM data ‚Äî process_prism","text":"SpatRaster object metadata time element.","code":""},{"path":[]},{"path":"https://niehs.github.io/amadeus/reference/process_prism.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Process PRISM data ‚Äî process_prism","text":"Insang Song","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_prism.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Process PRISM data ‚Äî process_prism","text":"","code":"## NOTE: Example is wrapped in `\\dontrun{}` as function requires a large ##       amount of data which is not included in the package. if (FALSE) { # \\dontrun{ prism <- process_prism(   path = \"./data/PRISM_ppt_stable_4kmM3_202104_nc.nc\",   element = \"ppt\",   time = \"202104\" ) } # }"},{"path":"https://niehs.github.io/amadeus/reference/process_sedac_codes.html","id":null,"dir":"Reference","previous_headings":"","what":"Process population resolution code ‚Äî process_sedac_codes","title":"Process population resolution code ‚Äî process_sedac_codes","text":"Convert full length resolution name /resolution code.","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_sedac_codes.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Process population resolution code ‚Äî process_sedac_codes","text":"","code":"process_sedac_codes(string, invert = FALSE)"},{"path":"https://niehs.github.io/amadeus/reference/process_sedac_codes.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Process population resolution code ‚Äî process_sedac_codes","text":"string character(1). Resolution name code. invert logical(1). Default = FALSE. invert = TRUE assumes string provides resolution code, returns full length resolution.","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_sedac_codes.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Process population resolution code ‚Äî process_sedac_codes","text":"character","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_terraclimate.html","id":null,"dir":"Reference","previous_headings":"","what":"Process TerraClimate data ‚Äî process_terraclimate","title":"Process TerraClimate data ‚Äî process_terraclimate","text":"process_terraclimate() function imports cleans climate water balance data, returning single SpatRaster object.","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_terraclimate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Process TerraClimate data ‚Äî process_terraclimate","text":"","code":"process_terraclimate(   date = c(\"2023-09-01\", \"2023-09-10\"),   variable = NULL,   path = NULL,   extent = NULL,   ... )"},{"path":"https://niehs.github.io/amadeus/reference/process_terraclimate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Process TerraClimate data ‚Äî process_terraclimate","text":"date character(1 2). Date (1) start end dates (2). Format YYYY-MM-DD (ex. September 1, 2023 = \"2023-09-01\"). variable character(1). Variable name acronym code. See TerraClimate Direct Downloads variable names acronym codes. path character(1). Directory downloaded netCDF (.nc) files. extent numeric(4) SpatExtent giving extent raster NULL (default), entire raster loaded ... Placeholders.","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_terraclimate.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Process TerraClimate data ‚Äî process_terraclimate","text":"SpatRaster object","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_terraclimate.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Process TerraClimate data ‚Äî process_terraclimate","text":"Layer names returned SpatRaster object contain variable acronym, year, month. TerraClimate data monthly temporal resolution, first day month used placeholder temporal value.","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_terraclimate.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Process TerraClimate data ‚Äî process_terraclimate","text":"Mitchell Manware","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_terraclimate.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Process TerraClimate data ‚Äî process_terraclimate","text":"","code":"## NOTE: Example is wrapped in `\\dontrun{}` as function requires a large ##       amount of data which is not included in the package. if (FALSE) { # \\dontrun{ terraclimate <- process_terraclimate(   date = c(\"2023-01-01\", \"2023-01-10\"),   variable = \"Precipitation\",   path = \"./data/ppt\" ) } # }"},{"path":"https://niehs.github.io/amadeus/reference/process_terraclimate_codes.html","id":null,"dir":"Reference","previous_headings":"","what":"Process terraClimate variable codes ‚Äî process_terraclimate_codes","title":"Process terraClimate variable codes ‚Äî process_terraclimate_codes","text":"Convert terraClimate variable names /variable codes.","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_terraclimate_codes.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Process terraClimate variable codes ‚Äî process_terraclimate_codes","text":"","code":"process_terraclimate_codes(string, invert = FALSE)"},{"path":"https://niehs.github.io/amadeus/reference/process_terraclimate_codes.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Process terraClimate variable codes ‚Äî process_terraclimate_codes","text":"string character(1). terraClimate variable name variable code. invert logical(1). Default = FALSE. invert = TRUE assumes string provides variable code returns full length variable name.","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_terraclimate_codes.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Process terraClimate variable codes ‚Äî process_terraclimate_codes","text":"character","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_tri.html","id":null,"dir":"Reference","previous_headings":"","what":"Process toxic release data ‚Äî process_tri","title":"Process toxic release data ‚Äî process_tri","text":"function imports cleans raw toxic release data, returning single SpatVector (points) object selected year.","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_tri.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Process toxic release data ‚Äî process_tri","text":"","code":"process_tri(   path = NULL,   year = 2018,   variables = c(1, 13, 12, 14, 20, 34, 36, 47, 48, 49),   extent = NULL,   ... )"},{"path":"https://niehs.github.io/amadeus/reference/process_tri.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Process toxic release data ‚Äî process_tri","text":"path character(1). Path directory TRI CSV files year integer(1). Single year select. variables integer. Column index TRI data. extent numeric(4) SpatExtent giving extent raster NULL (default), entire raster loaded ... Placeholders.","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_tri.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Process toxic release data ‚Äî process_tri","text":"SpatVector object (points) year year stored field named \"year\".","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_tri.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Process toxic release data ‚Äî process_tri","text":"Visit TRI Data Tools view available years variables.","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_tri.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Process toxic release data ‚Äî process_tri","text":"https://www.epa.gov/toxics-release-inventory-tri-program/tri-toolbox","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_tri.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Process toxic release data ‚Äî process_tri","text":"Insang Song, Mariana Kassien","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_tri.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Process toxic release data ‚Äî process_tri","text":"","code":"## NOTE: Example is wrapped in `\\dontrun{}` as function requires a large ##       amount of data which is not included in the package. if (FALSE) { # \\dontrun{ tri <- process_tri(   path = \"./data\",   year = 2020,   variables = c(1, 13, 12, 14, 20, 34, 36, 47, 48, 49) ) } # }"},{"path":"https://niehs.github.io/amadeus/reference/process_variable_codes.html","id":null,"dir":"Reference","previous_headings":"","what":"Filter gridMET and terraClimate variable names and variable codes ‚Äî process_variable_codes","title":"Filter gridMET and terraClimate variable names and variable codes ‚Äî process_variable_codes","text":"Check user defined variables gridMET TerraClimate functions.","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_variable_codes.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Filter gridMET and terraClimate variable names and variable codes ‚Äî process_variable_codes","text":"","code":"process_variable_codes(variables, source = c(\"gridmet\", \"terraclimate\"))"},{"path":"https://niehs.github.io/amadeus/reference/process_variable_codes.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Filter gridMET and terraClimate variable names and variable codes ‚Äî process_variable_codes","text":"variables character(1). Data variables. (Passed download_* process_*). source character(1). Data source selected variables (\"gridMET\" \"TerraClimate\").","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_variable_codes.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Filter gridMET and terraClimate variable names and variable codes ‚Äî process_variable_codes","text":"character","code":""},{"path":"https://niehs.github.io/amadeus/reference/read_commands.html","id":null,"dir":"Reference","previous_headings":"","what":"Import download commands ‚Äî read_commands","title":"Import download commands ‚Äî read_commands","text":"Read download commands .txt file convert character vector.","code":""},{"path":"https://niehs.github.io/amadeus/reference/read_commands.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Import download commands ‚Äî read_commands","text":"","code":"read_commands(commands_path = commands_path)"},{"path":"https://niehs.github.io/amadeus/reference/read_commands.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Import download commands ‚Äî read_commands","text":"commands_path file path wget/curl commands","code":""},{"path":"https://niehs.github.io/amadeus/reference/read_commands.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Import download commands ‚Äî read_commands","text":"character vector containing download commands","code":""},{"path":"https://niehs.github.io/amadeus/reference/rename_time.html","id":null,"dir":"Reference","previous_headings":"","what":"Rename $time ‚Äî rename_time","title":"Rename $time ‚Äî rename_time","text":"Rename $time column sftime object.","code":""},{"path":"https://niehs.github.io/amadeus/reference/rename_time.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Rename $time ‚Äî rename_time","text":"","code":"rename_time(x, newname)"},{"path":"https://niehs.github.io/amadeus/reference/rename_time.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Rename $time ‚Äî rename_time","text":"x sftime object newname character new time column name","code":""},{"path":"https://niehs.github.io/amadeus/reference/rename_time.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Rename $time ‚Äî rename_time","text":"sftime object","code":""},{"path":"https://niehs.github.io/amadeus/reference/rename_time.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Rename $time ‚Äî rename_time","text":"Eva Marques","code":""},{"path":"https://niehs.github.io/amadeus/reference/sf_as_mysftime.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert an sf to an sftime ‚Äî sf_as_mysftime","title":"Convert an sf to an sftime ‚Äî sf_as_mysftime","text":"Convert sf object sftime object. x must contain time-defining column, identified timename.","code":""},{"path":"https://niehs.github.io/amadeus/reference/sf_as_mysftime.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert an sf to an sftime ‚Äî sf_as_mysftime","text":"","code":"sf_as_mysftime(x, timename)"},{"path":"https://niehs.github.io/amadeus/reference/sf_as_mysftime.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert an sf to an sftime ‚Äî sf_as_mysftime","text":"x sf object timename character: name time column x","code":""},{"path":"https://niehs.github.io/amadeus/reference/sf_as_mysftime.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert an sf to an sftime ‚Äî sf_as_mysftime","text":"sftime object","code":""},{"path":"https://niehs.github.io/amadeus/reference/sf_as_mysftime.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Convert an sf to an sftime ‚Äî sf_as_mysftime","text":"Eva Marques","code":""},{"path":"https://niehs.github.io/amadeus/reference/sftime_as_mysftime.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert an sftime to a mysftime ‚Äî sftime_as_mysftime","title":"Convert an sftime to a mysftime ‚Äî sftime_as_mysftime","text":"Convert sftime object mysftime object. x must contain time-defining column, identified timename.","code":""},{"path":"https://niehs.github.io/amadeus/reference/sftime_as_mysftime.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert an sftime to a mysftime ‚Äî sftime_as_mysftime","text":"","code":"sftime_as_mysftime(x, timename)"},{"path":"https://niehs.github.io/amadeus/reference/sftime_as_mysftime.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert an sftime to a mysftime ‚Äî sftime_as_mysftime","text":"x sftime object timename character: name time column x","code":""},{"path":"https://niehs.github.io/amadeus/reference/sftime_as_mysftime.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert an sftime to a mysftime ‚Äî sftime_as_mysftime","text":"sftime object specific format","code":""},{"path":[]},{"path":"https://niehs.github.io/amadeus/reference/sftime_as_mysftime.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Convert an sftime to a mysftime ‚Äî sftime_as_mysftime","text":"Eva Marques","code":""},{"path":"https://niehs.github.io/amadeus/reference/sftime_as_sf.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert an sftime to an sf ‚Äî sftime_as_sf","title":"Convert an sftime to an sf ‚Äî sftime_as_sf","text":"Convert sftime object sf object. x must contain time-defining column, identified timename.","code":""},{"path":"https://niehs.github.io/amadeus/reference/sftime_as_sf.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert an sftime to an sf ‚Äî sftime_as_sf","text":"","code":"sftime_as_sf(x, keeptime = TRUE)"},{"path":"https://niehs.github.io/amadeus/reference/sftime_as_sf.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert an sftime to an sf ‚Äî sftime_as_sf","text":"x sftime object keeptime boolean: TRUE user wants keep time column simple column (default = TRUE)","code":""},{"path":"https://niehs.github.io/amadeus/reference/sftime_as_sf.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert an sftime to an sf ‚Äî sftime_as_sf","text":"sf object","code":""},{"path":"https://niehs.github.io/amadeus/reference/sftime_as_sf.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Convert an sftime to an sf ‚Äî sftime_as_sf","text":"Eva Marques","code":""},{"path":"https://niehs.github.io/amadeus/reference/sftime_as_spatraster.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert an sftime to a SpatRaster ‚Äî sftime_as_spatraster","title":"Convert an sftime to a SpatRaster ‚Äî sftime_as_spatraster","text":"Convert sftime object SpatRaster object. Returns SpatRatser one layer time step x.","code":""},{"path":"https://niehs.github.io/amadeus/reference/sftime_as_spatraster.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert an sftime to a SpatRaster ‚Äî sftime_as_spatraster","text":"","code":"sftime_as_spatraster(x, varname)"},{"path":"https://niehs.github.io/amadeus/reference/sftime_as_spatraster.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert an sftime to a SpatRaster ‚Äî sftime_as_spatraster","text":"x sftime object varname variable rasterize","code":""},{"path":"https://niehs.github.io/amadeus/reference/sftime_as_spatraster.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert an sftime to a SpatRaster ‚Äî sftime_as_spatraster","text":"SpatRaster object","code":""},{"path":"https://niehs.github.io/amadeus/reference/sftime_as_spatraster.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Convert an sftime to a SpatRaster ‚Äî sftime_as_spatraster","text":"Running sftime_as_spatraster can take long time x spatially structured.","code":""},{"path":[]},{"path":"https://niehs.github.io/amadeus/reference/sftime_as_spatraster.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Convert an sftime to a SpatRaster ‚Äî sftime_as_spatraster","text":"Eva Marques","code":""},{"path":"https://niehs.github.io/amadeus/reference/sftime_as_spatrds.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert an sftime to a SpatRasterDataset ‚Äî sftime_as_spatrds","title":"Convert an sftime to a SpatRasterDataset ‚Äî sftime_as_spatrds","text":"Convert sftime object SpatRasterDataset object.","code":""},{"path":"https://niehs.github.io/amadeus/reference/sftime_as_spatrds.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert an sftime to a SpatRasterDataset ‚Äî sftime_as_spatrds","text":"","code":"sftime_as_spatrds(x)"},{"path":"https://niehs.github.io/amadeus/reference/sftime_as_spatrds.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert an sftime to a SpatRasterDataset ‚Äî sftime_as_spatrds","text":"x sftime object","code":""},{"path":"https://niehs.github.io/amadeus/reference/sftime_as_spatrds.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert an sftime to a SpatRasterDataset ‚Äî sftime_as_spatrds","text":"SpatRasterDataset object","code":""},{"path":"https://niehs.github.io/amadeus/reference/sftime_as_spatrds.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Convert an sftime to a SpatRasterDataset ‚Äî sftime_as_spatrds","text":"Running sftime_as_spatrds can take long time x spatially temporally structured.","code":""},{"path":[]},{"path":"https://niehs.github.io/amadeus/reference/sftime_as_spatrds.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Convert an sftime to a SpatRasterDataset ‚Äî sftime_as_spatrds","text":"Eva Marques","code":""},{"path":"https://niehs.github.io/amadeus/reference/sftime_as_spatvector.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert an sftime to a SpatVector ‚Äî sftime_as_spatvector","title":"Convert an sftime to a SpatVector ‚Äî sftime_as_spatvector","text":"Convert sftime object SpatVector object.","code":""},{"path":"https://niehs.github.io/amadeus/reference/sftime_as_spatvector.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert an sftime to a SpatVector ‚Äî sftime_as_spatvector","text":"","code":"sftime_as_spatvector(x)"},{"path":"https://niehs.github.io/amadeus/reference/sftime_as_spatvector.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert an sftime to a SpatVector ‚Äî sftime_as_spatvector","text":"x sftime object","code":""},{"path":"https://niehs.github.io/amadeus/reference/sftime_as_spatvector.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert an sftime to a SpatVector ‚Äî sftime_as_spatvector","text":"SpatVector object","code":""},{"path":[]},{"path":"https://niehs.github.io/amadeus/reference/sftime_as_spatvector.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Convert an sftime to a SpatVector ‚Äî sftime_as_spatvector","text":"Eva Marques","code":""},{"path":"https://niehs.github.io/amadeus/reference/spatraster_as_sftime.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert a SpatRaster to an sftime ‚Äî spatraster_as_sftime","title":"Convert a SpatRaster to an sftime ‚Äî spatraster_as_sftime","text":"Convert SpatRaster object sftime object. x must contain time-defining column, identified timename.","code":""},{"path":"https://niehs.github.io/amadeus/reference/spatraster_as_sftime.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert a SpatRaster to an sftime ‚Äî spatraster_as_sftime","text":"","code":"spatraster_as_sftime(x, varname, timename = \"time\")"},{"path":"https://niehs.github.io/amadeus/reference/spatraster_as_sftime.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert a SpatRaster to an sftime ‚Äî spatraster_as_sftime","text":"x SpatRaster object varname character variable column name sftime timename character time column name sftime (default: \"time\")","code":""},{"path":"https://niehs.github.io/amadeus/reference/spatraster_as_sftime.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert a SpatRaster to an sftime ‚Äî spatraster_as_sftime","text":"sftime object","code":""},{"path":[]},{"path":"https://niehs.github.io/amadeus/reference/spatraster_as_sftime.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Convert a SpatRaster to an sftime ‚Äî spatraster_as_sftime","text":"Eva Marques","code":""},{"path":"https://niehs.github.io/amadeus/reference/spatrds_as_sftime.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert a SpatRasterDataset to an sftime ‚Äî spatrds_as_sftime","title":"Convert a SpatRasterDataset to an sftime ‚Äî spatrds_as_sftime","text":"Convert SpatRasterDataset object sftime object. x must contain time-defining column, identified timename.","code":""},{"path":"https://niehs.github.io/amadeus/reference/spatrds_as_sftime.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert a SpatRasterDataset to an sftime ‚Äî spatrds_as_sftime","text":"","code":"spatrds_as_sftime(x, timename = \"time\")"},{"path":"https://niehs.github.io/amadeus/reference/spatrds_as_sftime.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert a SpatRasterDataset to an sftime ‚Äî spatrds_as_sftime","text":"x SpatRasterDataset object (~ list named SpatRasters) timename character time column name sftime (default: \"time\")","code":""},{"path":"https://niehs.github.io/amadeus/reference/spatrds_as_sftime.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert a SpatRasterDataset to an sftime ‚Äî spatrds_as_sftime","text":"sftime object","code":""},{"path":[]},{"path":"https://niehs.github.io/amadeus/reference/spatrds_as_sftime.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Convert a SpatRasterDataset to an sftime ‚Äî spatrds_as_sftime","text":"Eva Marques","code":""},{"path":"https://niehs.github.io/amadeus/reference/spatvector_as_sftime.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert a SpatVector to an sftime ‚Äî spatvector_as_sftime","title":"Convert a SpatVector to an sftime ‚Äî spatvector_as_sftime","text":"Convert SpatVector object sftime object. x must contain time-defining column, identified timename.","code":""},{"path":"https://niehs.github.io/amadeus/reference/spatvector_as_sftime.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert a SpatVector to an sftime ‚Äî spatvector_as_sftime","text":"","code":"spatvector_as_sftime(x, timename = \"time\")"},{"path":"https://niehs.github.io/amadeus/reference/spatvector_as_sftime.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert a SpatVector to an sftime ‚Äî spatvector_as_sftime","text":"x SpatVector object timename character time column name x (default: \"time\")","code":""},{"path":"https://niehs.github.io/amadeus/reference/spatvector_as_sftime.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert a SpatVector to an sftime ‚Äî spatvector_as_sftime","text":"sftime object","code":""},{"path":[]},{"path":"https://niehs.github.io/amadeus/reference/spatvector_as_sftime.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Convert a SpatVector to an sftime ‚Äî spatvector_as_sftime","text":"Eva Marques","code":""},{"path":"https://niehs.github.io/amadeus/reference/sum_edc.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate isotropic Sum of Exponentially Decaying Contributions (SEDC) covariates ‚Äî sum_edc","title":"Calculate isotropic Sum of Exponentially Decaying Contributions (SEDC) covariates ‚Äî sum_edc","text":"Calculate isotropic Sum Exponentially Decaying Contributions (SEDC) covariates","code":""},{"path":"https://niehs.github.io/amadeus/reference/sum_edc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate isotropic Sum of Exponentially Decaying Contributions (SEDC) covariates ‚Äî sum_edc","text":"","code":"sum_edc(   from = NULL,   locs = NULL,   locs_id = NULL,   sedc_bandwidth = NULL,   target_fields = NULL,   geom = FALSE )"},{"path":"https://niehs.github.io/amadeus/reference/sum_edc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate isotropic Sum of Exponentially Decaying Contributions (SEDC) covariates ‚Äî sum_edc","text":"SpatVector(1). Point locations contain point-source covariate data. locs sf/SpatVector(1). Locations sum exponentially decaying contributions calculated. locs_id character(1). Name unique id field point_to. sedc_bandwidth numeric(1). Distance source concentration reduced exp(-3) (approximately -95 %) target_fields character(varying). Field names characters. geom FALSE/\"sf\"/\"terra\".. function return geometry? Default FALSE, options geometry \"sf\" \"terra\". coordinate reference system sf SpatVector .","code":""},{"path":"https://niehs.github.io/amadeus/reference/sum_edc.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate isotropic Sum of Exponentially Decaying Contributions (SEDC) covariates ‚Äî sum_edc","text":"data.frame (tibble) SpatVector object input field names suffix \"_sedc\" sums EDC stored. Additional attributes attached EDC information. `attr(result, \"sedc_bandwidth\")‚Äú: bandwidth concentration reduces approximately five percent `attr(result, \"sedc_threshold\")‚Äú: threshold distance emission source points excluded beyond ","code":""},{"path":"https://niehs.github.io/amadeus/reference/sum_edc.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Calculate isotropic Sum of Exponentially Decaying Contributions (SEDC) covariates ‚Äî sum_edc","text":"function originally chopin Distance calculation done terra functions internally. Thus, function internally converts sf objects point_* arguments terra. threshold carefully chosen users.","code":""},{"path":"https://niehs.github.io/amadeus/reference/sum_edc.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Calculate isotropic Sum of Exponentially Decaying Contributions (SEDC) covariates ‚Äî sum_edc","text":"Messier KP, Akita Y, Serre ML (2012). ‚ÄúIntegrating Address Geocoding, Land Use Regression, Spatiotemporal Geostatistical Estimation Groundwater Tetrachloroethylene.‚Äù Environmental Science & Technology, 46(5), 2772‚Äì2780. ISSN 0013-936X, doi:10.1021/es203152a . Wiesner C (????). ‚ÄúEuclidean Sum Exponentially Decaying Contributions Tutorial.‚Äù","code":""},{"path":"https://niehs.github.io/amadeus/reference/sum_edc.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Calculate isotropic Sum of Exponentially Decaying Contributions (SEDC) covariates ‚Äî sum_edc","text":"Insang Song","code":""},{"path":"https://niehs.github.io/amadeus/reference/sum_edc.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate isotropic Sum of Exponentially Decaying Contributions (SEDC) covariates ‚Äî sum_edc","text":"","code":"set.seed(101) ncpath <- system.file(\"gpkg/nc.gpkg\", package = \"sf\") nc <- terra::vect(ncpath) nc <- terra::project(nc, \"EPSG:5070\") pnt_locs <- terra::centroids(nc, inside = TRUE) pnt_locs <- pnt_locs[, \"NAME\"] pnt_from <- terra::spatSample(nc, 10L) pnt_from$pid <- seq(1, 10) pnt_from <- pnt_from[, \"pid\"] pnt_from$val1 <- rgamma(10L, 1, 0.05) pnt_from$val2 <- rgamma(10L, 2, 1)  vals <- c(\"val1\", \"val2\") sum_edc(pnt_locs, pnt_from, \"NAME\", 1e4, vals) #> Joining with `by = join_by(from_id)` #> Joining with `by = join_by(to_id)` #> Joining with `by = join_by(from_id, to_id)` #>         NAME        val1         val2 #> 1  Currituck 0.396806821 0.1194879800 #> 2   Franklin 0.007670679 0.0009627225 #> 3    Madison 0.008587220 0.0039990182 #> 4       Polk 0.060334402 0.0036680841 #> 5   Randolph 0.034332984 0.0468172020 #> 6 Rutherford 0.116429976 0.0070784648 #> 7     Stokes 0.044323594 0.0049338077 #> 8     Yancey 0.055883024 0.0260243982"},{"path":"https://niehs.github.io/amadeus/reference/test.html","id":null,"dir":"Reference","previous_headings":"","what":"Run all tests within a single file from tests/testthat/ directory with the container.sif container. ‚Äî test","title":"Run all tests within a single file from tests/testthat/ directory with the container.sif container. ‚Äî test","text":"Run tests within single file tests/testthat/ directory container.sif container.","code":""},{"path":"https://niehs.github.io/amadeus/reference/test.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Run all tests within a single file from tests/testthat/ directory with the container.sif container. ‚Äî test","text":"","code":"test(pattern = NULL)"},{"path":"https://niehs.github.io/amadeus/reference/test.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Run all tests within a single file from tests/testthat/ directory with the container.sif container. ‚Äî test","text":"pattern regular expression match test file name.","code":""},{"path":"https://niehs.github.io/amadeus/reference/test.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Run all tests within a single file from tests/testthat/ directory with the container.sif container. ‚Äî test","text":"NULL; Prints output testthat tests.","code":""},{"path":[]},{"path":"https://niehs.github.io/amadeus/reference/test_download_functions.html","id":null,"dir":"Reference","previous_headings":"","what":"Download unit tests ‚Äî test_download_functions","title":"Download unit tests ‚Äî test_download_functions","text":"Implement directory, file, download URL unit tests.","code":""},{"path":"https://niehs.github.io/amadeus/reference/test_download_functions.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Download unit tests ‚Äî test_download_functions","text":"","code":"test_download_functions(   directory_to_save = directory_to_save,   commands_path = commands_path,   url_status = url_status )"},{"path":"https://niehs.github.io/amadeus/reference/test_download_functions.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Download unit tests ‚Äî test_download_functions","text":"directory_to_save directory test saving commands_path file path download commands url_status logical vector URL status = 200","code":""},{"path":"https://niehs.github.io/amadeus/reference/test_download_functions.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Download unit tests ‚Äî test_download_functions","text":"NULL; returns stop error one tests fail","code":""}]
