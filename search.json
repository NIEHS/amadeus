[{"path":"https://niehs.github.io/amadeus/articles/download_functions.html","id":"motivation","dir":"Articles","previous_headings":"","what":"Motivation","title":"download_data","text":"download_data function developed improve researchers’ access publicly available environmental data. Although data already available online, using web browser manually download hundreds thousands data files slow, arduous, efficiently repeatable. Additionally, users may familiar creating download recipes Bash (Unix shell), download_data allows researchers download data directly R, common coding language field environmental health research. Finally, function-izing data downloads useful repeated code automated analysis pipelines.","code":""},{"path":"https://niehs.github.io/amadeus/articles/download_functions.html","id":"download_data","dir":"Articles","previous_headings":"","what":"download_data","title":"download_data","text":"download_data acccesses downloads environmental datasets, collections, variables variety sources. wrapper function calls source-specific data download functions, utilizing unique combination input parameters, host URL, naming convention, data formats. Source-specific download functions data sources important note download_data calls source-specific function based dataset_name parameter. Using source-specific function directly return data parameters , error messages produced differ slightly.","code":""},{"path":"https://niehs.github.io/amadeus/articles/download_functions.html","id":"parameters","dir":"Articles","previous_headings":"download_data","what":"Parameters","title":"download_data","text":"User-defined parameters differ based data source. Required parameters source can checked names(formals()). two functions different required parameters download_hms uses daily temporal resolution download_narr uses yearly, share common, standard parameters.","code":"names(formals(download_hms)) ## [1] \"data_format\"       \"date\"              \"directory_to_save\" ## [4] \"acknowledgement\"   \"download\"          \"remove_command\"    ## [7] \"unzip\"             \"remove_zip\" names(formals(download_narr)) ## [1] \"variables\"         \"year\"              \"directory_to_save\" ## [4] \"acknowledgement\"   \"download\"          \"remove_command\""},{"path":"https://niehs.github.io/amadeus/articles/download_functions.html","id":"standard-parameters","dir":"Articles","previous_headings":"download_data > Parameters","what":"Standard parameters","title":"download_data","text":"Four parameters included data download functions. Additionally, dataset_name parameter must specified using download_data, assumed using source-specific download function.","code":""},{"path":"https://niehs.github.io/amadeus/articles/download_functions.html","id":"function-structure","dir":"Articles","previous_headings":"download_data","what":"Function Structure","title":"download_data","text":"Although source-specific download function unique, follow general structure. following chunks code adopted download_hms demonstrate functions’ structure. 1. Clean Parameters 2. Generate Download URLs 3. Generate download file names 4. Initiate “…commands.txt” 5. Concatenate download commands 6. Finalize “…commands.txt” 7. Run commands “…commands.txt” 8. Zip files (applicable)","code":""},{"path":"https://niehs.github.io/amadeus/articles/download_functions.html","id":"clean-parameters","dir":"Articles","previous_headings":"download_data > Function Structure","what":"1. Clean parameters","title":"download_data","text":"Cleaning user-defined parameters highly dependent parameters desired URL created. common parameter cleaning step creating date-time sequence based given temporal range required format, case YYYYMMDD.","code":"# user defined parameters dates <- c(\"2023-12-28\", \"2024-01-02\") date_sequence <- seq(   as.Date(dates[1], format = \"%Y-%m-%d\"),   as.Date(dates[2], format = \"%Y-%m-%d\"),   \"day\" ) date_sequence <- gsub(\"-\", \"\", as.character(date_sequence)) date_sequence ## [1] \"20231228\" \"20231229\" \"20231230\" \"20231231\" \"20240101\" \"20240102\""},{"path":"https://niehs.github.io/amadeus/articles/download_functions.html","id":"generate-download-urls","dir":"Articles","previous_headings":"download_data > Function Structure","what":"2. Generate download URLs","title":"download_data","text":"URL base pattern identified manually inspecting download link source-specific web page. download_hms utilizes year, month, date, data format generate download url. download URL created date date_sequence based fixed pattern.","code":"# user defined parameters data_format <- \"Shapefile\" suffix <- \".zip\" urls <- NULL for (d in seq_along(date_sequence)) {   year <- substr(date_sequence[d], 1, 4)   month <- substr(date_sequence[d], 5, 6)   base <- \"https://satepsanone.nesdis.noaa.gov/pub/FIRE/web/HMS/Smoke_Polygons/\"   url <- paste0(     base,     data_format,     \"/\",     year,     \"/\",     month,     \"/hms_smoke\",     date_sequence[d],     suffix   )   urls <- c(urls, url) } urls ## [1] \"https://satepsanone.nesdis.noaa.gov/pub/FIRE/web/HMS/Smoke_Polygons/Shapefile/2023/12/hms_smoke20231228.zip\" ## [2] \"https://satepsanone.nesdis.noaa.gov/pub/FIRE/web/HMS/Smoke_Polygons/Shapefile/2023/12/hms_smoke20231229.zip\" ## [3] \"https://satepsanone.nesdis.noaa.gov/pub/FIRE/web/HMS/Smoke_Polygons/Shapefile/2023/12/hms_smoke20231230.zip\" ## [4] \"https://satepsanone.nesdis.noaa.gov/pub/FIRE/web/HMS/Smoke_Polygons/Shapefile/2023/12/hms_smoke20231231.zip\" ## [5] \"https://satepsanone.nesdis.noaa.gov/pub/FIRE/web/HMS/Smoke_Polygons/Shapefile/2024/01/hms_smoke20240101.zip\" ## [6] \"https://satepsanone.nesdis.noaa.gov/pub/FIRE/web/HMS/Smoke_Polygons/Shapefile/2024/01/hms_smoke20240102.zip\""},{"path":"https://niehs.github.io/amadeus/articles/download_functions.html","id":"generate-download-file-names","dir":"Articles","previous_headings":"download_data > Function Structure","what":"3. Generate download file names","title":"download_data","text":"generation download file names also follows fixed pattern, typically combination user-defined download directory, dataset name, spatiotemporal characteristic, data type, , applicable, specific variable name. Unlike download URLs, download file names can defined way writer function, using previously defined characteristics useful identification. download URL created date date_sequence based fixed pattern.","code":"# user defined parameters directory_to_download <- \"./data/\" download_file_names <- NULL for (d in seq_along(date_sequence)) {   download_file_name <- paste0(     directory_to_download,     \"hms_smoke_\",     data_format,     \"_\",     date_sequence[d],     suffix   )   download_file_names <- c(download_file_names, download_file_name) } download_file_names ## [1] \"./data/hms_smoke_Shapefile_20231228.zip\" ## [2] \"./data/hms_smoke_Shapefile_20231229.zip\" ## [3] \"./data/hms_smoke_Shapefile_20231230.zip\" ## [4] \"./data/hms_smoke_Shapefile_20231231.zip\" ## [5] \"./data/hms_smoke_Shapefile_20240101.zip\" ## [6] \"./data/hms_smoke_Shapefile_20240102.zip\""},{"path":"https://niehs.github.io/amadeus/articles/download_functions.html","id":"initiate-commands-txt","dir":"Articles","previous_headings":"download_data > Function Structure","what":"4. Initiate “…commands.txt”","title":"download_data","text":"important aspect data download function sink...cat...sink structure. Rather using utils::download.file function, text file created store download commands generated URLs file names. structure utilized several reasons: Consistent structure source-specific download functions. download.file function accept vectors URLs destination files downloading. additional loop download data increase function complexity may reduce performance. Writing commands Bash (Unix shell) script allows specific arguments flags. Storing download URLs without immediately running download allows unit testing URL checking (Unit Tests). text file containing download commands named based dataset, temporal range, data transfer method. Create sink text file.","code":"commands_txt <- paste0(   directory_to_download,   \"hms_smoke_\",   head(date_sequence, n = 1),   \"_\",   tail(date_sequence, n = 1),   \"_curl_commands.txt\" ) sink(commands_txt)"},{"path":"https://niehs.github.io/amadeus/articles/download_functions.html","id":"concatenate-download-commands","dir":"Articles","previous_headings":"download_data > Function Structure","what":"5. Concatenate download commands","title":"download_data","text":"Linux-based download commands written according data transfer method, download URL, download file name, additional arguments. additional arguments included, order, depend data transfer method URL type. information curl wget, two data transfer methods utilized data download functions, see curl.1 man page GNU Wget 1.21.1-dirty Manual (latest version January 8, 2024). cat() function store download commands written loop previously sunk commands text file (commands_txt).","code":"for (d in seq_along(date_sequence)) {   download_comamnd <- paste0(     \"curl -s -o \",     download_file_names[d],     \" --url \",     urls[d],     \"\\n\"   )   cat(download_comamnd) }"},{"path":"https://niehs.github.io/amadeus/articles/download_functions.html","id":"finalize-commands-txt","dir":"Articles","previous_headings":"download_data > Function Structure","what":"6. Finalize “…commands.txt”","title":"download_data","text":"download commands concatenated commands text file, second sink command run finalize file stop appending R output.","code":"sink()"},{"path":"https://niehs.github.io/amadeus/articles/download_functions.html","id":"run-commands-in-commands-txt","dir":"Articles","previous_headings":"download_data > Function Structure","what":"7. Run commands in “…commands.txt”","title":"download_data","text":"“system command” must created run download commands stored commands text file. bash script, . indicates run commands within given script. case, run commands within commands text file. Running system_command deploys “auxiliary” function, download_run, function created reduce repeated code across source-specific download functions. function takes two parameters, system_command, indicates command run, download, user-defined logical parameter. data download initiated running download_run system command identified download = TRUE. Checking download directory shows requested files downloaded.","code":"system_command <- paste0(   \". \",   commands_txt,   \"\\n\" ) system_command ## [1] \". ./data/hms_smoke_20231228_20240102_curl_commands.txt\\n\" download_run <- function(     download = FALSE,     system_command = NULL) {   if (download == TRUE) {     cat(paste0(\"Downloading requested files...\\n\"))     system(command = system_command)     cat(paste0(\"Requested files have been downloaded.\\n\"))   } else {     cat(paste0(\"Skipping data download.\\n\"))     return(NULL)   } } download_run(   download = TRUE,   system_command = system_command ) list.files(path = directory_to_download) ## [1] \"hms_smoke_Shapefile_20231228.zip\" \"hms_smoke_Shapefile_20231229.zip\" ## [3] \"hms_smoke_Shapefile_20231230.zip\" \"hms_smoke_Shapefile_20231231.zip\" ## [5] \"hms_smoke_Shapefile_20240101.zip\" \"hms_smoke_Shapefile_20240102.zip\""},{"path":"https://niehs.github.io/amadeus/articles/download_functions.html","id":"zip-files-if-applicable","dir":"Articles","previous_headings":"download_data > Function Structure","what":"8. Zip files (if applicable)","title":"download_data","text":"source-specific data download functions follow general pattern, functions download zip files require additional steps inflate remove downloaded zip files, desired. two steps run helper functions, run user-defined unzip remove_zip parameters download_data. download_unzip inflates zip files unzip = TRUE, skips inflation unzip = FALSE. download_remove_zips removes downloaded zip files remove = TRUE, skips removal remove = FALSE. demonstration unzip (inflate) downloaded zip files delete . Listing files shows contents zip files inflated zip files retained. download function structured successfully.","code":"download_unzip <-   function(file_name,            directory_to_unzip,            unzip = TRUE) {     if (!unzip) {       cat(paste0(\"Downloaded files will not be unzipped.\\n\"))       return(NULL)     }     cat(paste0(\"Unzipping files...\\n\"))     unzip(file_name,       exdir = directory_to_unzip     )     cat(paste0(       \"Files unzipped and saved in \",       directory_to_unzip,       \".\\n\"     ))   } download_remove_zips <-   function(remove = FALSE,            download_name) {     if (remove) {       cat(paste0(\"Removing download files...\\n\"))       file.remove(download_name)       cat(paste0(\"Download files removed.\\n\"))     }   } for (f in seq_along(download_file_names)) {   download_unzip(     file_name = download_file_names[f],     directory_to_unzip = directory_to_download,     unzip = TRUE   ) } download_remove_zips(   download_name = download_file_names,   remove = FALSE ) ## Unzipping files... ## Files unzipped and saved in ./data/. ## Unzipping files... ## Files unzipped and saved in ./data/. ## Unzipping files... ## Files unzipped and saved in ./data/. ## Unzipping files... ## Files unzipped and saved in ./data/. ## Unzipping files... ## Files unzipped and saved in ./data/. ## Unzipping files... ## Files unzipped and saved in ./data/. list.files(path = directory_to_download) ##  [1] \"hms_smoke_Shapefile_20231228.zip\" \"hms_smoke_Shapefile_20231229.zip\" ##  [3] \"hms_smoke_Shapefile_20231230.zip\" \"hms_smoke_Shapefile_20231231.zip\" ##  [5] \"hms_smoke_Shapefile_20240101.zip\" \"hms_smoke_Shapefile_20240102.zip\" ##  [7] \"hms_smoke20231228.dbf\"            \"hms_smoke20231228.prj\"            ##  [9] \"hms_smoke20231228.shp\"            \"hms_smoke20231228.shx\"            ## [11] \"hms_smoke20231229.dbf\"            \"hms_smoke20231229.prj\"            ## [13] \"hms_smoke20231229.shp\"            \"hms_smoke20231229.shx\"            ## [15] \"hms_smoke20231230.dbf\"            \"hms_smoke20231230.prj\"            ## [17] \"hms_smoke20231230.shp\"            \"hms_smoke20231230.shx\"            ## [19] \"hms_smoke20231231.dbf\"            \"hms_smoke20231231.prj\"            ## [21] \"hms_smoke20231231.shp\"            \"hms_smoke20231231.shx\"            ## [23] \"hms_smoke20240101.dbf\"            \"hms_smoke20240101.prj\"            ## [25] \"hms_smoke20240101.shp\"            \"hms_smoke20240101.shx\"            ## [27] \"hms_smoke20240102.dbf\"            \"hms_smoke20240102.prj\"            ## [29] \"hms_smoke20240102.shp\"            \"hms_smoke20240102.shx\""},{"path":"https://niehs.github.io/amadeus/articles/download_functions.html","id":"unit-tests","dir":"Articles","previous_headings":"","what":"Unit Tests","title":"download_data","text":"previous outline successfully cleaned parameters, generated URLs, downloaded data, can sure continue work different temporal ranges data types? end, unit tests implemented ensure data download function runs properly URLs produced 2. Generate download URLs valid accessible. Like download functions, unit tests rely “helper” functions reduce repeated code across tests.","code":""},{"path":"https://niehs.github.io/amadeus/articles/download_functions.html","id":"helper-functions","dir":"Articles","previous_headings":"Unit Tests","what":"Helper functions","title":"download_data","text":"read_commands imports commands text file converts data frame vector. extract_urls extracts download URL vector commands. position URL within download command determined 5. Concatenate download commands. check_url_status important download test “helper” functions. function utilizes httr::HEAD httr::GET check HTTP response status given URL. desired HTTP response status 200, means URL valid accessible. check_url_status returns logical value indicate whether URL returns HTTP status 200 (TRUE) (FALSE). information HTTP status’, see HTTP response status codes. check_urls applies check_url_status random sample URLs extracted extract_urls. sample size vary based dataset spatio-temporal parameters tested. function returns logical vector containing output check_url_status.","code":"read_commands <- function(     commands_path = commands_path) {   commands <- utils::read.csv(commands_path, header = FALSE)   commands <- commands[seq_len(nrow(commands)), ]   return(commands) } # function to extract URLs from vector extract_urls <- function(     commands = commands,     position = NULL) {   if (is.null(position)) {     cat(paste0(\"URL position in command is not defined.\\n\"))     return(NULL)   }   url_list <- NULL   for (c in seq_along(commands)) {     url <- stringr::str_split_i(commands[c], \" \", position)     url_list <- c(url_list, url)   }   return(url_list) } check_url_status <- function(     url,     method = \"HEAD\") {   http_status_ok <- 200   if (method == \"HEAD\") {     hd <- httr::HEAD(url)   } else if (method == \"GET\") {     hd <- httr::GET(url)   }   status <- hd$status_code   return(status == http_status_ok) } check_urls <- function(     urls = urls,     size = NULL,     method = \"HEAD\") {   if (is.null(size)) {     cat(paste0(\"URL sample size is not defined.\\n\"))     return(NULL)   }   if (length(urls) < size) {     size <- length(urls)   }   url_sample <- sample(urls, size, replace = FALSE)   url_status <- sapply(url_sample,     check_url_status,     method = method   )   return(url_status) }"},{"path":"https://niehs.github.io/amadeus/articles/download_functions.html","id":"testthat","dir":"Articles","previous_headings":"Unit Tests","what":"testthat","title":"download_data","text":"demonstrate test action, test URLs generated download_data NOAA HMS Smoke dataset. information see testthat. Although testthat::test_that(...) chunk contains 32 lines code, unit test performed expect_true((url_status)). words, line expecting (expect_true) () sampled URLs return HTTP response status 200 (url_status). Since expectation met, test passed! alternate example, can use start end date known data. URLs associated dates exist, expect function fail. test utilizes expect_error() download_data wrapper function returns error message underlying source-specific download function returns error. test utilizes testthat::expect_error download_data wrapper function returns error message underlying source-specific download function returns error. directly used download_hms function, expect receive error. expected, test passes NOAA HMS Smoke dataset contain data January 1-2, 1800. unit tests just two many implemented download_data accompanying source-specific download functions, demonstrate unit testing helps build stable code.","code":"library(testthat) testthat::test_that(   \"Valid dates return HTTP response status = 200.\",   {     # parameters     test_start <- \"2023-12-28\"     test_end <- \"2024-01-02\"     test_directory <- \"./data/\"     # download     download_data(       dataset_name = \"hms\",       date = c(test_start, test_end),       data_format = \"Shapefile\",       directory_to_save = test_directory,       acknowledgement = TRUE,       download = FALSE,       remove_command = FALSE,       unzip = FALSE,       remove_zip = FALSE     )     commands_path <- paste0(       test_directory,       \"hms_smoke_\",       gsub(\"-\", \"\", test_start),       \"_\",       gsub(\"-\", \"\", test_end),       \"_curl_commands.txt\"     )     # helpers     commands <- read_commands(commands_path = commands_path)     urls <- extract_urls(commands = commands, position = 6)     url_status <- check_urls(urls = urls, size = 6, method = \"HEAD\")     # test for true     expect_true(all(url_status))   } ) ## Test passed 🎊 testthat::test_that(   \"Invalid dates cause function to fail.\",   {     # parameters     test_start <- \"1800-01-01\"     test_end <- \"1800-01-02\"     test_directory <- \"../inst/extdata/\"     # test for error     testthat::expect_error(       download_data(         dataset_name = \"hms\",         date = c(test_start, test_end),         data_format = \"Shapefile\",         directory_to_download = test_directory,         directory_to_save = test_directory,         acknowledgement = TRUE,         download = FALSE,         remove_command = FALSE,         unzip = FALSE,         remove_zip = FALSE       )     )   } ) ## <simpleError in what_to_run(directory_to_save = directory_to_save, acknowledgement = acknowledgement,     ...): unused argument (directory_to_download = \"../inst/extdata/\")> ## function (data_format = \"Shapefile\", date = c(\"2018-01-01\", \"2018-01-01\"),  ##     directory_to_save = NULL, acknowledgement = FALSE, download = FALSE,  ##     remove_command = FALSE, unzip = TRUE, remove_zip = FALSE)  ## NULL ## Test passed 🎊 testthat::test_that(   \"Invalid dates cause function to fail.\",   {     # parameters     test_start <- \"1800-01-01\"     test_end <- \"1800-01-02\"     test_directory <- \"../inst/extdata/\"     # test for error     testthat::expect_error(       download_hms(         date = c(test_start, test_end),         data_format = \"Shapefile\",         directory_to_download = test_directory,         directory_to_save = test_directory,         acknowledgement = TRUE,         download = FALSE,         remove_command = FALSE,         unzip = FALSE,         remove_zip = FALSE       )     )   } ) ## Test passed 🌈"},{"path":"https://niehs.github.io/amadeus/articles/download_functions.html","id":"download-example","dir":"Articles","previous_headings":"","what":"Download Example","title":"download_data","text":"function structure outlined unit tests place, can now perform data download. begin, check parameters required source-specific data download function. Define parameters. Download data. Checking directory shows desired data downloaded inflated, original zip files retained.","code":"names(formals(download_hms)) ## [1] \"data_format\"       \"date\"              \"directory_to_save\" ## [4] \"acknowledgement\"   \"download\"          \"remove_command\"    ## [7] \"unzip\"             \"remove_zip\" dates <- c(\"2023-12-28\", \"2024-01-02\") data_format <- \"Shapefile\" data_directory <- \"./download_example/\" acknowledgement <- TRUE download <- TRUE # run data download remove_command <- TRUE # delete \"...commands.txt\" file unzip <- TRUE # inflate (unzip) downloaded zip files remove_zip <- FALSE # retain downloaded zip files download_data(   dataset_name = \"hms\",   date = dates,   directory_to_save = data_directory,   acknowledgement = acknowledgement,   download = download,   remove_command = remove_command,   unzip = unzip,   remove_zip = remove_zip ) ## Downloading requested files... ## Requested files have been downloaded. ## Unzipping files... ## Files unzipped and saved in ./download_example/. ## Unzipping files... ## Files unzipped and saved in ./download_example/. ## Unzipping files... ## Files unzipped and saved in ./download_example/. ## Unzipping files... ## Files unzipped and saved in ./download_example/. ## Unzipping files... ## Files unzipped and saved in ./download_example/. ## Unzipping files... ## Files unzipped and saved in ./download_example/. list.files(data_directory) ##  [1] \"hms_smoke_Shapefile_20231228.zip\" \"hms_smoke_Shapefile_20231229.zip\" ##  [3] \"hms_smoke_Shapefile_20231230.zip\" \"hms_smoke_Shapefile_20231231.zip\" ##  [5] \"hms_smoke_Shapefile_20240101.zip\" \"hms_smoke_Shapefile_20240102.zip\" ##  [7] \"hms_smoke20231228.dbf\"            \"hms_smoke20231228.prj\"            ##  [9] \"hms_smoke20231228.shp\"            \"hms_smoke20231228.shx\"            ## [11] \"hms_smoke20231229.dbf\"            \"hms_smoke20231229.prj\"            ## [13] \"hms_smoke20231229.shp\"            \"hms_smoke20231229.shx\"            ## [15] \"hms_smoke20231230.dbf\"            \"hms_smoke20231230.prj\"            ## [17] \"hms_smoke20231230.shp\"            \"hms_smoke20231230.shx\"            ## [19] \"hms_smoke20231231.dbf\"            \"hms_smoke20231231.prj\"            ## [21] \"hms_smoke20231231.shp\"            \"hms_smoke20231231.shx\"            ## [23] \"hms_smoke20240101.dbf\"            \"hms_smoke20240101.prj\"            ## [25] \"hms_smoke20240101.shp\"            \"hms_smoke20240101.shx\"            ## [27] \"hms_smoke20240102.dbf\"            \"hms_smoke20240102.prj\"            ## [29] \"hms_smoke20240102.shp\"            \"hms_smoke20240102.shx\""},{"path":"https://niehs.github.io/amadeus/articles/download_functions.html","id":"download_hms-function-code","dir":"Articles","previous_headings":"","what":"download_hms function code","title":"download_data","text":"following entire R code used create download_hms.","code":"download_hms ## function( ##     data_format = \"Shapefile\", ##     date = c(\"2018-01-01\", \"2018-01-01\"), ##     directory_to_save = NULL, ##     acknowledgement = FALSE, ##     download = FALSE, ##     remove_command = FALSE, ##     unzip = TRUE, ##     remove_zip = FALSE) { ##   #### 1. check for data download acknowledgement ##   download_permit(acknowledgement = acknowledgement) ##   #### 2. check for null parameters ##   check_for_null_parameters(mget(ls())) ##   #### check dates ##   stopifnot(length(date) == 2) ##   date <- date[order(as.Date(date))] ##   #### 3. directory setup ##   directory_original <- download_sanitize_path(directory_to_save) ##   directories <- download_setup_dir(directory_original, zip = TRUE) ##   directory_to_download <- directories[1] ##   directory_to_save <- directories[2] ##   #### 4. check for unzip == FALSE && remove_zip == TRUE ##   if (unzip == FALSE && remove_zip == TRUE) { ##     stop(paste0( ##       \"Arguments unzip = FALSE and remove_zip = TRUE are not \", ##       \"acceptable together. Please change one.\\n\" ##     )) ##   } ##   #### 5. define date sequence ##   date_sequence <- generate_date_sequence( ##     date[1], ##     date[2], ##     sub_hyphen = TRUE ##   ) ##   #### 6. define URL base ##   base <- \"https://satepsanone.nesdis.noaa.gov/pub/FIRE/web/HMS/Smoke_Polygons/\" ##   #### 7. initiate \"..._curl_commands.txt\" ##   commands_txt <- paste0( ##     directory_original, ##     \"hms_smoke_\", ##     utils::head(date_sequence, n = 1), ##     \"_\", ##     utils::tail(date_sequence, n = 1), ##     \"_curl_commands.txt\" ##   ) ##   download_sink(commands_txt) ##   #### 8. concatenate and print download commands to \"..._curl_commands.txt\" ##   download_names <- NULL ##   for (f in seq_along(date_sequence)) { ##     year <- substr(date_sequence[f], 1, 4) ##     month <- substr(date_sequence[f], 5, 6) ##     if (tolower(data_format) == \"shapefile\") { ##       data_format <- \"Shapefile\" ##       suffix <- \".zip\" ##       directory_to_cat <- directory_to_download ##     } else if (tolower(data_format) == \"kml\") { ##       data_format <- \"KML\" ##       suffix <- \".kml\" ##       directory_to_cat <- directory_to_save ##     } ##     url <- paste0( ##       base, ##       data_format, ##       \"/\", ##       year, ##       \"/\", ##       month, ##       \"/hms_smoke\", ##       date_sequence[f], ##       suffix ##     ) ##     if (f == 1) { ##       if (!(check_url_status(url))) { ##         sink() ##         file.remove(commands_txt) ##         stop(paste0( ##           \"Invalid date returns HTTP code 404. \", ##           \"Check `date` parameter.\\n\" ##         )) ##       } ##     } ##     destfile <- paste0( ##       directory_to_cat, ##       \"hms_smoke_\", ##       data_format, ##       \"_\", ##       date_sequence[f], ##       suffix ##     ) ##     download_names <- c(download_names, destfile) ##     command <- paste0( ##       \"curl -s -o \", ##       destfile, ##       \" --url \", ##       url, ##       \"\\n\" ##     ) ##     if (!file.exists(destfile)) { ##       #### cat command only if file does not already exist ##       cat(command) ##     } ##   } ##   #### 9. finish \"..._curl_commands.txt\" ##   sink() ##   #### 10. build system command ##   system_command <- paste0( ##     \". \", ##     commands_txt, ##     \"\\n\" ##   ) ##   #### 11. download data ##   download_run( ##     download = download, ##     system_command = system_command ##   ) ##   #### 12. remove command file ##   download_remove_command( ##     remove = remove_command, ##     commands_txt = commands_txt ##   ) ##   #### 13. end if data_format == \"KML\" ##   if (data_format == \"KML\") { ##     unlink(directory_to_download, recursive = TRUE) ##     message(paste0(\"KML files cannot be unzipped.\\n\")) ##     return(TRUE) ##   } ##   #### 14. unzip downloaded zip files ##   for (d in seq_along(download_names)) { ##     download_unzip( ##       file_name = download_names[d], ##       directory_to_unzip = directory_to_save, ##       unzip = unzip ##     ) ##   } ##   #### 15. remove zip files ##   download_remove_zips( ##     remove = remove_zip, ##     download_name = download_names ##   ) ## } ## <environment: namespace:amadeus>"},{"path":"https://niehs.github.io/amadeus/articles/epa_download.html","id":"downloading-and-pre-processing-pre-generated-epa-aqs-data-from-their-website","dir":"Articles","previous_headings":"","what":"Downloading and pre-processing pre-generated EPA AQS data from their website","title":"Downloading EPA Daily Data","text":"script downloads pre-processed data EPA’s AQS data desired variable, year(s), temporal resolution. script also joins multiple years’ data single data frame, downloads file metadata monitors included dataset. first version script (August 2023) written download daily PM2.5 data period 2018-2022. Available datasets can found website https://aqs.epa.gov/aqsweb/airdata/download_files.html.","code":""},{"path":"https://niehs.github.io/amadeus/articles/epa_download.html","id":"setting-up-for-data-download","dir":"Articles","previous_headings":"Downloading and pre-processing pre-generated EPA AQS data from their website","what":"1. Setting up for data download","title":"Downloading EPA Daily Data","text":"Specifying temporal resolution, parameter interest, year Create list file URLs Specify download folder desired name downloaded zip files","code":"resolution <- \"daily\" parameter_code <- 88101 # Parameter Code for PM2.5 local conditions startyear <- 2018 endyear <- 2022 file_urls <- sprintf(   paste(\"https://aqs.epa.gov/aqsweb/airdata/\", resolution,     \"_\", parameter_code, \"_%.0f.zip\",     sep = \"\"   ),   startyear:endyear ) file_urls ## [1] \"https://aqs.epa.gov/aqsweb/airdata/daily_88101_2018.zip\" ## [2] \"https://aqs.epa.gov/aqsweb/airdata/daily_88101_2019.zip\" ## [3] \"https://aqs.epa.gov/aqsweb/airdata/daily_88101_2020.zip\" ## [4] \"https://aqs.epa.gov/aqsweb/airdata/daily_88101_2021.zip\" ## [5] \"https://aqs.epa.gov/aqsweb/airdata/daily_88101_2022.zip\" download_dir <- \"../input/aqs/\" download_names <- sprintf(   paste(download_dir,     \"download_output_%.0f.zip\",     sep = \"\"   ),   startyear:endyear ) download_names ## [1] \"../input/aqs/download_output_2018.zip\" ## [2] \"../input/aqs/download_output_2019.zip\" ## [3] \"../input/aqs/download_output_2020.zip\" ## [4] \"../input/aqs/download_output_2021.zip\" ## [5] \"../input/aqs/download_output_2022.zip\""},{"path":"https://niehs.github.io/amadeus/articles/epa_download.html","id":"downloading-data","dir":"Articles","previous_headings":"Downloading and pre-processing pre-generated EPA AQS data from their website","what":"2. Downloading data","title":"Downloading EPA Daily Data","text":"Download zip files website Construct string unzipped file names","code":"download.file(file_urls, download_names, method = \"libcurl\") csv_names <- sprintf(   paste(download_dir, resolution, \"_\",     parameter_code, \"_%.0f.csv\",     sep = \"\"   ),   startyear:endyear )"},{"path":"https://niehs.github.io/amadeus/articles/epa_download.html","id":"processing-data","dir":"Articles","previous_headings":"Downloading and pre-processing pre-generated EPA AQS data from their website","what":"3. Processing data","title":"Downloading EPA Daily Data","text":"Unzip read .csv files, process join one dataframe. unique site identifier “ID.Code” string structure State-County-Site-Parameter-POC","code":"for (n in seq_along(file_urls)) {   # Unzips file to same folder it was downloaded to   unzip(download_names[n], exdir = download_dir)    # Read in dataframe   print(paste(\"reading and processing file:\", csv_names[n], \"...\"))   data <- read.csv(csv_names[n], stringsAsFactors = FALSE)    # Make unique site identifier: State-County-Site-Parameter-POC   data$ID.Code <- paste(data$State.Code, data$County.Code,     data$Site.Num, data$Parameter.Code,     data$POC,     sep = \"-\"   )    # Concatenate with other years   if (n == 1) {     data_all <- data   } else {     data_all <- rbind(data_all, data)   } } ## [1] \"reading and processing file:../input/aqs/daily_88101_2018.csv...\" ## [1] \"reading and processing file:../input/aqs/daily_88101_2019.csv...\" ## [1] \"reading and processing file:../input/aqs/daily_88101_2020.csv...\" ## [1] \"reading and processing file:../input/aqs/daily_88101_2021.csv...\" ## [1] \"reading and processing file:../input/aqs/daily_88101_2022.csv...\""},{"path":"https://niehs.github.io/amadeus/articles/epa_download.html","id":"downloading-monitor-metadata-file-and-filter-for-relevant-sites","dir":"Articles","previous_headings":"Downloading and pre-processing pre-generated EPA AQS data from their website","what":"4. Downloading monitor metadata file and filter for relevant sites","title":"Downloading EPA Daily Data","text":"Download monitors file Unzip read Create site identifier Filter monitors file include monitors csv","code":"destfile <- paste(download_dir, \"aqs_monitors.zip\", sep = \"\") download.file(\"https://aqs.epa.gov/aqsweb/airdata/aqs_monitors.zip\", destfile) unzip(destfile, exdir = download_dir) monitors <- read.csv(\"../input/aqs/aqs_monitors.csv\", stringsAsFactors = FALSE) # Convert from string to numeric to get rid of leading zeros, # the NAs introduced are from monitors in Canada with site number=\"CC\" monitors$State.Code <- as.numeric(monitors$State.Code) monitors$ID.Code <- paste(monitors$State.Code, monitors$County.Code,   monitors$Site.Num, monitors$Parameter.Code,   monitors$POC,   sep = \"-\" ) monitors <- read.csv(\"../input/aqs/aqs_monitors.csv\",   stringsAsFactors = FALSE ) monitors_filter <- monitors[which(monitors$ID.Code %in% data_all$ID.Code), ]"},{"path":"https://niehs.github.io/amadeus/articles/epa_download.html","id":"uploading-data-to-desired-folder","dir":"Articles","previous_headings":"Downloading and pre-processing pre-generated EPA AQS data from their website","what":"5. Uploading data to desired folder","title":"Downloading EPA Daily Data","text":"","code":"savepath <- \"../input/aqs/\"  write.csv(data_all, paste(savepath, resolution, \"_\", parameter_code, \"_\",   startyear, \"-\", endyear, \".csv\",   sep = \"\" )) write.csv(monitors_filter, paste(savepath, \"monitors_\", parameter_code, \"_\",   startyear, \"-\", endyear, \".csv\",   sep = \"\" ))"},{"path":"https://niehs.github.io/amadeus/articles/protected_datasets.html","id":"motivation","dir":"Articles","previous_headings":"","what":"Motivation","title":"Protected Data Sources","text":"vignette demonstrate create log NASA EarthData Account, generate prerequisite files R code.","code":""},{"path":"https://niehs.github.io/amadeus/articles/protected_datasets.html","id":"nasa-earthdata-account","dir":"Articles","previous_headings":"","what":"NASA EarthData Account","title":"Protected Data Sources","text":"Visit https://urs.earthdata.nasa.gov/ register log NASA EarthData account. Account registration provides access NASA’s Earth Observing System Data Information System (EOSDIS) twelve Distributed Active Archive Centers (DAAC), including: Alaska Satellite Facility (ASF) DAAC Atmospheric Science Data Center (ASDC) Crustal Dynamics Data Information System (CDDIS) Global Hydrometeorology Resource Center (GHRC) Goddard Earth Sciences Data Information Services Center (GES DISC) Land Processes DAAC (LP DAAC) Level 1 Atmosphere Archive Distribution System (LAADS) DAAC National Snow Ice Data Center (NSIDC) DAAC Oak Ridge National Laboratory (ORNL) DAAC Ocean Biology DAAC (OB.DAAC) Physical Oceanography DAAC (PO.DAAC) Socioeconomic Data Applications Center (SEDAC) See https://www.earthdata.nasa.gov/eosdis/daacs information.","code":""},{"path":"https://niehs.github.io/amadeus/articles/protected_datasets.html","id":"approved-applications","dir":"Articles","previous_headings":"NASA EarthData Account","what":"Approved applications","title":"Protected Data Sources","text":"creating account, navigate “Profile”(https://urs.earthdata.nasa.gov/profile), “Applications > Authorized Apps”. “Authorized Apps” page specifies NASA EarthData applications can use login credentials. example, ensure authorization enabled “SEDAC Website”, “SEDAC Website (Alpha)”, “SEDAC Website (Beta)”.","code":""},{"path":"https://niehs.github.io/amadeus/articles/protected_datasets.html","id":"prerequisite-files","dir":"Articles","previous_headings":"","what":"Prerequisite files","title":"Protected Data Sources","text":"NASA EarthData Account required applications authorized use credentials, time create prerequisite files. following examples utilize UN WPP-Adjusted population density data NASA Socioeconomic Data Applications Center (SEDAC). generating prerequisite, try download population data download_data. error message indicates, downloaded file unzipped data file accessed properly. able download protected NASA data download_data, .netrc, .urs_cookies, .dodsrc must generated. Note following code adopted Generate Earthdata Prerequisite Files NASA GES DISC’s “-’s” webpage. folowing steps assume Mac Linux operating system. Instructions generating prerequisite files Windows operating system R developed.","code":"download_data(   dataset_name = \"sedac_population\",   year = \"2020\",   data_format = \"GeoTIFF\",   data_resolution = \"60 minute\",   directory_to_save = \"./sedac_population\",   acknowledgement = TRUE,   download = TRUE,   unzip = TRUE,   remove_zip = FALSE,   remove_command = TRUE ) ## Downloading requested files... ## Requested files have been downloaded. ## Unzipping files... ##  ## Warning in unzip(file_name, exdir = directory_to_unzip): error 1 in extracting from zip file ##  ## Files unzipped and saved in ./sedac_population/."},{"path":"https://niehs.github.io/amadeus/articles/protected_datasets.html","id":"netrc","dir":"Articles","previous_headings":"Prerequisite files","what":".netrc","title":"Protected Data Sources","text":"following commands create .netrc file, contains NASA EarthData Account credentials. First, set working directory home directory. Create file named .netrc file.create. Open connection .netrc sink. Write line machine urs... replacing YOUR_USERNAME YOUR_PASSWORD NASA EarthData username password, respectively. writing line, close connection sink . Edit settings , owner file, can read write .netrc. , check ensure file created properly.","code":"setwd(\"~/\") file.create(\".netrc\") sink(\".netrc\") writeLines(   \"machine urs.earthdata.nasa.gov login YOUR_USERNAME password YOUR_PASSWORD\" ) sink() system(\"chmod 0600 .netrc\") file.exists(\".netrc\") ## [1] TRUE readLines(\".netrc\") ## [1] \"machine urs.earthdata.nasa.gov login YOUR_USERNAME password YOUR_PASSWORD\""},{"path":"https://niehs.github.io/amadeus/articles/protected_datasets.html","id":"urs_cookies","dir":"Articles","previous_headings":"Prerequisite files","what":".urs_cookies","title":"Protected Data Sources","text":"following commands create .urs_cookies file. First, set working directory home directory. Create file named .netrc file.create. , check ensure file created properly.","code":"setwd(\"~/\") file.create(\".urs_cookies\") file.exists(\".urs_cookies\") ## [1] TRUE"},{"path":"https://niehs.github.io/amadeus/articles/protected_datasets.html","id":"dodsrc","dir":"Articles","previous_headings":"Prerequisite files","what":".dodsrc","title":"Protected Data Sources","text":"following commands create .urs_cookies file. First, set working directory home directory. Create file named “.dodsrc” file.create. Open connection .dodsrc sink. Write lines beginning HTTP., replacing YOUR_USERNAME YOUR_PASSWORD NASA EarthData username password, respectively. writing line, close connection sink . , check ensure file created properly. important ensure commands, well username, password, home directory, typed without error, single problem files result failed download. files created correctly, UN WPP-Adjusted population density data NASA Socioeconomic Data Applications Center (SEDAC) downloaded unzipped without returning error. Check downloaded data files. indicated files ./sedac_population, data files downloaded properly.","code":"setwd(\"~/\") file.create(\".dodsrc\") sink(\".dodsrc\") writeLines(   paste0(     \"HTTP.NETRC=YOUR_HOME_DIRECTORY/.netrc\\n\",     \"HTTP.COOKIE.JAR=YOUR_HOME_DIRECTORY/.urs_cookies\"   ) ) sink() file.exists(\".dodsrc\") ## [1] TRUE readLines(\".dodsrc\") ## [1] \"HTTP.NETRC=YOUR_HOME_DIRECTORY/.netrc\"            ## [2] \"HTTP.COOKIE.JAR=YOUR_HOME_DIRECTORY/.urs_cookies\" download_data(   dataset_name = \"sedac_population\",   year = \"2020\",   data_format = \"GeoTIFF\",   data_resolution = \"60 minute\",   directory_to_save = \"./sedac_population\",   acknowledgement = TRUE,   download = TRUE,   unzip = TRUE,   remove_zip = FALSE,   remove_command = TRUE ) ## Downloading requested files... ## Requested files have been downloaded. ## Unzipping files... ## Files unzipped and saved in ./sedac_population/. list.files(\"./sedac_population\") ## [1] \"gpw_v4_population_density_adjusted_to_2015_unwpp_country_totals_rev11_2020_1_deg_tif_readme.txt\" ## [2] \"gpw_v4_population_density_adjusted_to_2015_unwpp_country_totals_rev11_2020_1_deg_tif.zip\"        ## [3] \"gpw_v4_population_density_adjusted_to_2015_unwpp_country_totals_rev11_2020_1_deg.tif\""},{"path":"https://niehs.github.io/amadeus/articles/protected_datasets.html","id":"references","dir":"Articles","previous_headings":"","what":"References","title":"Protected Data Sources","text":"EOSDIS Distributed Active Archive Centers (DAAC). National Aeronautics Space Administration (NASA). Date accessed: January 3, 2024. https://www.earthdata.nasa.gov/eosdis/daacs. Generate Earthdata Prerequisite Files. National Aeronautics Space Administration (NASA). Date accessed: January 3, 2024. https://disc.gsfc.nasa.gov/information/howto?title=%20to%20Generate%20Earthdata%20Prerequisite%20Files.","code":""},{"path":"https://niehs.github.io/amadeus/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Mitchell Manware. Author, contributor. Insang Song. Author, contributor. Eva Marques. Author, contributor. Mariana Alifa Kassien. Author, contributor. Kyle Messier. Author, maintainer.","code":""},{"path":"https://niehs.github.io/amadeus/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Manware M, Song , Marques E, Alifa Kassien M, Messier K (2024). amadeus: Machine Data, Environments, User Setup Common Environmental Climate Health Datasets. R package version 1.0.0,, https://github.com/NIEHS/amadeus.","code":"@Manual{,   title = {amadeus: A Machine for Data, Environments, and User Setup for Common Environmental and Climate Health Datasets},   author = {Mitchell Manware and Insang Song and Eva Marques and Mariana {Alifa Kassien} and Kyle Messier},   year = {2024},   note = {R package version 1.0.0,},   url = {https://github.com/NIEHS/amadeus}, }"},{"path":"https://niehs.github.io/amadeus/index.html","id":"amadeus-","dir":"","previous_headings":"","what":"A Machine for Data, Environments, and User Setup for Common Environmental and Climate Health Datasets","title":"A Machine for Data, Environments, and User Setup for Common Environmental and Climate Health Datasets","text":"amadeus mechanism data, environments, user setup common environmental climate health datasets R. amadeus developed improve access utility large scale, publicly available environmental data R.","code":""},{"path":"https://niehs.github.io/amadeus/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"A Machine for Data, Environments, and User Setup for Common Environmental and Climate Health Datasets","text":"amadeus yet available CRAN, can installed devtools, remotes, pak packages.","code":"devtools::install_github(\"NIEHS/amadeus\") remotes::install_github(\"NIEHS/amadeus\") pak::pak(\"NIEHS/amadeus\")"},{"path":"https://niehs.github.io/amadeus/index.html","id":"contribution","dir":"","previous_headings":"","what":"Contribution","title":"A Machine for Data, Environments, and User Setup for Common Environmental and Climate Health Datasets","text":"add edit functionality new data sources datasets, open Pull request main branch detailed description proposed changes. Pull requests must pass status checks, approved rejected amadeus’s authors. Utilize Issues notify authors bugs, questions, recommendations. Identify issue appropriate label help ensure timely response.","code":""},{"path":"https://niehs.github.io/amadeus/index.html","id":"download","dir":"","previous_headings":"","what":"Download","title":"A Machine for Data, Environments, and User Setup for Common Environmental and Climate Health Datasets","text":"download_data accesses downloads raw geospatial data variety open source data repositories. function wrapper calls source-specific download functions, account source’s unique combination URL, file naming conventions, data types. Download functions cover following sources: See “download_data” vignette detailed description source-specific download functions. Example use download_data using NOAA NCEP North American Regional Reanalysis’s (NARR) “weasd” (Daily Accumulated Snow Surface) variable.","code":"directory <- \"/  EXAMPLE  /  FILE  /  PATH  /\" download_data(   dataset_name = \"narr\",   year = c(2022, 2022),   variable = \"weasd\",   directory_to_save = directory,   acknowledgement = TRUE,   download = TRUE ) Downloading requested files... Requested files have been downloaded. list.files(paste0(directory, \"weasd\")) [1] \"weasd.2022.nc\""},{"path":"https://niehs.github.io/amadeus/index.html","id":"process","dir":"","previous_headings":"","what":"Process","title":"A Machine for Data, Environments, and User Setup for Common Environmental and Climate Health Datasets","text":"process_covariates imports cleans raw geospatial data (downloaded download_data), returns single SpatRaster SpatVector user’s R environment. process_covariates “cleans” data defining interpretable layer names, ensuring coordinate reference system present, managing `timedata (applicable). avoid errors using process_covariates, edit raw downloaded data files. Passing user-generated edited data process_covariates may result errors underlying functions adapted sources’ raw data file type. Example use process_covariates using downloaded “weasd” data.","code":"weasd <- process_covariates(   covariate = \"narr\",   date = c(\"2022-01-01\", \"2022-01-05\"),   variable = \"weasd\",   path = paste0(directory, \"weasd\"),   extent = NULL ) Cleaning weasd data for January, 2022... Detected monolevel data... Returning daily weasd data from 2022-01-01 to 2022-01-05. weasd class       : SpatRaster dimensions  : 277, 349, 5  (nrow, ncol, nlyr) resolution  : 32462.99, 32463  (x, y) extent      : -16231.49, 11313351, -16231.5, 8976020  (xmin, xmax, ymin, ymax) coord. ref. : +proj=lcc +lat_0=50 +lon_0=-107 +lat_1=50 +lat_2=50 +x_0=5632642.22547 +y_0=4612545.65137 +datum=WGS84 +units=m +no_defs source      : weasd.2022.nc:weasd varname     : weasd (Daily Accumulated Snow at Surface) names       : weasd_20220101, weasd_20220102, weasd_20220103, weasd_20220104, weasd_20220105 unit        :         kg/m^2,         kg/m^2,         kg/m^2,         kg/m^2,         kg/m^2 time        : 2022-01-01 to 2022-01-05 UTC"},{"path":"https://niehs.github.io/amadeus/index.html","id":"calculate-covariates","dir":"","previous_headings":"","what":"Calculate Covariates","title":"A Machine for Data, Environments, and User Setup for Common Environmental and Climate Health Datasets","text":"calc_covariates stems beethoven project’s need various types data extracted precise locations. calc_covariates, therefore, extracts data “cleaned” SpatRaster SpatVector object user defined locations. Users can choose buffer locations. function returns data.frame SpatVector data extracted locations layer row SpatRaster SpatVector object, respectively. Example calc_covariates using processed “weasd” data.","code":"locs <- data.frame(id = \"001\", lon = -78.8277, lat = 35.95013) weasd_covar <- calc_covariates(   covariate = \"narr\",   from = weasd_process,   locs = locs,   locs_id = \"id\",   radius = 0,   geom = FALSE ) Detected `data.frame` extraction locations... Calculating weasd covariates for 2022-01-01... Calculating weasd covariates for 2022-01-02... Calculating weasd covariates for 2022-01-03... Calculating weasd covariates for 2022-01-04... Calculating weasd covariates for 2022-01-05... Returning extracted covariates. weasd_covar id       time     weasd_0 1 0001 2022-01-01 0.000000000 2 0001 2022-01-02 0.000000000 3 0001 2022-01-03 0.000000000 4 0001 2022-01-04 0.000000000 5 0001 2022-01-05 0.001953125"},{"path":"https://niehs.github.io/amadeus/index.html","id":"additional-resources","dir":"","previous_headings":"","what":"Additional Resources","title":"A Machine for Data, Environments, and User Setup for Common Environmental and Climate Health Datasets","text":"following R packages can also used access climate weather data R, differs amadeus data sources covered type functionality provided.","code":""},{"path":"https://niehs.github.io/amadeus/reference/apply_extent.html","id":null,"dir":"Reference","previous_headings":"","what":"Apply extent to the processed data — apply_extent","title":"Apply extent to the processed data — apply_extent","text":"User-defined extent used filter data.","code":""},{"path":"https://niehs.github.io/amadeus/reference/apply_extent.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Apply extent to the processed data — apply_extent","text":"","code":"apply_extent(data, extent, geom)"},{"path":"https://niehs.github.io/amadeus/reference/apply_extent.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Apply extent to the processed data — apply_extent","text":"data sf/terra object. extent numeric(4). Extent filter data. ordered c(xmin, xmax, ymin, ymax). geom character(1 2). Geometry type data data.frame. One \"geometry\" c(\"lon\", \"lat\").","code":""},{"path":"https://niehs.github.io/amadeus/reference/apply_extent.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Apply extent to the processed data — apply_extent","text":"sf/terra object extent applied.","code":""},{"path":"https://niehs.github.io/amadeus/reference/as_mysftime.html","id":null,"dir":"Reference","previous_headings":"","what":"Create an sftime object — as_mysftime","title":"Create an sftime object — as_mysftime","text":"Create sftime object one data.frame, data.table, sf, sftime, SpatRaster, SpatRasterDataset, SpatVector","code":""},{"path":"https://niehs.github.io/amadeus/reference/as_mysftime.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create an sftime object — as_mysftime","text":"","code":"as_mysftime(x, ...)"},{"path":"https://niehs.github.io/amadeus/reference/as_mysftime.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create an sftime object — as_mysftime","text":"x object class data.frame, data.table, sf, sftime, SpatRaster, SpatRasterDataset SpatVector ... x data.frame data.table: lonname, latname, timename crs arguments required. x sf sftime, timename argument required. x terra::SpatRaster, varname argument required.","code":""},{"path":"https://niehs.github.io/amadeus/reference/as_mysftime.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create an sftime object — as_mysftime","text":"sftime object constrained time column name","code":""},{"path":[]},{"path":"https://niehs.github.io/amadeus/reference/as_mysftime.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Create an sftime object — as_mysftime","text":"Eva Marques","code":""},{"path":"https://niehs.github.io/amadeus/reference/calc_check_time.html","id":null,"dir":"Reference","previous_headings":"","what":"Check time values — calc_check_time","title":"Check time values — calc_check_time","text":"Check time values within calculated covariates data.frame","code":""},{"path":"https://niehs.github.io/amadeus/reference/calc_check_time.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check time values — calc_check_time","text":"","code":"calc_check_time(covar, POSIXt = TRUE)"},{"path":"https://niehs.github.io/amadeus/reference/calc_check_time.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check time values — calc_check_time","text":"covar data.frame(1). Calculated covariates data.frame. POSIXt logical(1). time values covar class POSIXt? FALSE, time values checked integer class (year year-month).","code":""},{"path":"https://niehs.github.io/amadeus/reference/calc_covariates.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate covariates wrapper function — calc_covariates","title":"Calculate covariates wrapper function — calc_covariates","text":"calculate_covariates() function extracts values point locations SpatRaster SpatVector object returned process_covariates(). calculate_covariates() underlying source-specific covariate functions designed operate processed objects. avoid errors, edit processed SpatRaster SpatVector objects passing calculate_covariates().","code":""},{"path":"https://niehs.github.io/amadeus/reference/calc_covariates.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate covariates wrapper function — calc_covariates","text":"","code":"calc_covariates(   covariate = c(\"modis\", \"koppen-geiger\", \"koeppen-geiger\", \"koppen\", \"koeppen\", \"geos\",     \"dummies\", \"gmted\", \"sedac_groads\", \"groads\", \"roads\", \"ecoregions\", \"ecoregion\",     \"hms\", \"smoke\", \"gmted\", \"narr\", \"geos\", \"sedac_population\", \"population\", \"nlcd\",     \"merra\", \"merra2\", \"gridmet\", \"terraclimate\", \"tri\", \"nei\"),   from,   locs,   locs_id = \"site_id\",   ... )"},{"path":"https://niehs.github.io/amadeus/reference/calc_covariates.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate covariates wrapper function — calc_covariates","text":"covariate character(1). Covariate type. character. Single multiple strings. locs sf/SpatVector. Unique locations. include unique identifier field named locs_id locs_id character(1). Name unique identifier. Default \"site_id\". ... Arguments passed covariate calculation function.","code":""},{"path":"https://niehs.github.io/amadeus/reference/calc_covariates.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate covariates wrapper function — calc_covariates","text":"Calculated covariates data.frame SpatVector object","code":""},{"path":"https://niehs.github.io/amadeus/reference/calc_covariates.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Calculate covariates wrapper function — calc_covariates","text":"covariate argument value converted lowercase.","code":""},{"path":[]},{"path":"https://niehs.github.io/amadeus/reference/calc_covariates.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Calculate covariates wrapper function — calc_covariates","text":"Insang Song","code":""},{"path":"https://niehs.github.io/amadeus/reference/calc_covariates.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate covariates wrapper function — calc_covariates","text":"","code":"if (FALSE) { # \\dontrun{ loc <- data.frame(id = \"001\", lon = -78.90, lat = 35.97) calc_covariates(   covariate = \"narr\",   from = narr, # derived from process_covariates() example   locs = loc,   locs_id = \"id\",   geom = FALSE ) } # }"},{"path":"https://niehs.github.io/amadeus/reference/calc_ecoregion.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate ecoregions covariates — calc_ecoregion","title":"Calculate ecoregions covariates — calc_ecoregion","text":"Extract ecoregions covariates (U.S. EPA Ecoregions Level 2/3) point locations. Returns data.frame object containing locs_id binary (0 = point ecoregion; 1 = point ecoregion) variables ecoregion.","code":""},{"path":"https://niehs.github.io/amadeus/reference/calc_ecoregion.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate ecoregions covariates — calc_ecoregion","text":"","code":"calc_ecoregion(from = NULL, locs, locs_id = \"site_id\", geom = FALSE, ...)"},{"path":"https://niehs.github.io/amadeus/reference/calc_ecoregion.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate ecoregions covariates — calc_ecoregion","text":"SpatVector(1). Output process_ecoregion. locs sf/SpatVector. Unique locs. include unique identifier field named locs_id locs_id character(1). Name unique identifier. geom logical(1). function return SpatVector? Default FALSE. coordinate reference system SpatVector . ... Placeholders.","code":""},{"path":"https://niehs.github.io/amadeus/reference/calc_ecoregion.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate ecoregions covariates — calc_ecoregion","text":"data.frame SpatVector object object dummy variables attributes : attr(., \"ecoregion2_code\"): Ecoregion lv.2 code key attr(., \"ecoregion3_code\"): Ecoregion lv.3 code key","code":""},{"path":[]},{"path":"https://niehs.github.io/amadeus/reference/calc_ecoregion.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Calculate ecoregions covariates — calc_ecoregion","text":"Insang Song","code":""},{"path":"https://niehs.github.io/amadeus/reference/calc_ecoregion.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate ecoregions covariates — calc_ecoregion","text":"","code":"if (FALSE) { # \\dontrun{ loc <- data.frame(id = \"001\", lon = -78.90, lat = 35.97) calc_ecoregion(   from = ecoregion, # derived from process_ecoregion() example   locs = loc,   locs_id = \"id\",   geom = FALSE ) } # }"},{"path":"https://niehs.github.io/amadeus/reference/calc_geos.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate atmospheric composition covariates — calc_geos","title":"Calculate atmospheric composition covariates — calc_geos","text":"Extract atmospheric composition values point locations. Returns data.frame object containing locs_id, date hour, vertical pressure level, atmospheric composition variable. Atmospheric composition variable column name reflects variable circular buffer radius.","code":""},{"path":"https://niehs.github.io/amadeus/reference/calc_geos.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate atmospheric composition covariates — calc_geos","text":"","code":"calc_geos(   from,   locs,   locs_id = NULL,   radius = 0,   fun = \"mean\",   geom = FALSE,   ... )"},{"path":"https://niehs.github.io/amadeus/reference/calc_geos.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate atmospheric composition covariates — calc_geos","text":"SpatRaster(1). Output process_geos(). locs data.frame, characater file path, SpatVector, sf object. locs_id character(1). Column within locations CSV file containing identifier unique coordinate location. radius integer(1). Circular buffer distance around site locations. (Default = 0). fun character(1). Function used summarize multiple raster cells within sites location buffer (Default = mean). geom logical(1). function return SpatVector? Default FALSE. coordinate reference system SpatVector . ... Placeholders.","code":""},{"path":"https://niehs.github.io/amadeus/reference/calc_geos.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate atmospheric composition covariates — calc_geos","text":"data.frame SpatVector object","code":""},{"path":[]},{"path":"https://niehs.github.io/amadeus/reference/calc_geos.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Calculate atmospheric composition covariates — calc_geos","text":"Mitchell Manware","code":""},{"path":"https://niehs.github.io/amadeus/reference/calc_geos.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate atmospheric composition covariates — calc_geos","text":"","code":"if (FALSE) { # \\dontrun{ loc <- data.frame(id = \"001\", lon = -78.90, lat = 35.97) calc_geos(   from = geos, # derived from process_geos() example   locs = loc,   locs_id = \"id\",   radius = 0,   fun = \"mean\",   geom = FALSE ) } # }"},{"path":"https://niehs.github.io/amadeus/reference/calc_gmted.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate elevation covariates — calc_gmted","title":"Calculate elevation covariates — calc_gmted","text":"Extract elevation values point locations. Returns data.frame object containing locs_id, year release, elevation variable. Elevation variable column name reflects elevation statistic, spatial resolution , circular buffer radius (ie. Breakline Emphasis 7.5 arc-second resolution 0 meter buffer: breakline_emphasis_r75_0).","code":""},{"path":"https://niehs.github.io/amadeus/reference/calc_gmted.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate elevation covariates — calc_gmted","text":"","code":"calc_gmted(   from,   locs,   locs_id = NULL,   radius = 0,   fun = \"mean\",   geom = FALSE,   ... )"},{"path":"https://niehs.github.io/amadeus/reference/calc_gmted.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate elevation covariates — calc_gmted","text":"SpatRaster(1). Output process_gmted(). locs data.frame. character file path, SpatVector, sf object. locs_id character(1). Column within locations CSV file containing identifier unique coordinate location. radius integer(1). Circular buffer distance around site locations. (Default = 0). fun character(1). Function used summarize multiple raster cells within sites location buffer (Default = mean). geom logical(1). function return SpatVector? Default FALSE. coordinate reference system SpatVector . ... Placeholders","code":""},{"path":"https://niehs.github.io/amadeus/reference/calc_gmted.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate elevation covariates — calc_gmted","text":"data.frame SpatVector object","code":""},{"path":[]},{"path":"https://niehs.github.io/amadeus/reference/calc_gmted.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Calculate elevation covariates — calc_gmted","text":"Mitchell Manware","code":""},{"path":"https://niehs.github.io/amadeus/reference/calc_gmted.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate elevation covariates — calc_gmted","text":"","code":"if (FALSE) { # \\dontrun{ loc <- data.frame(id = \"001\", lon = -78.90, lat = 35.97) calc_gmted(   from = gmted, # derived from process_gmted() example   locs = loc,   locs_id = \"id\",   radius = 0,   fun = \"mean\",   geom = FALSE ) } # }"},{"path":"https://niehs.github.io/amadeus/reference/calc_gridmet.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate gridMET covariates — calc_gridmet","title":"Calculate gridMET covariates — calc_gridmet","text":"Extract gridMET values point locations. Returns data.frame object containing locs_id gridMET variable. gridMET variable column name reflects gridMET variable circular buffer radius.","code":""},{"path":"https://niehs.github.io/amadeus/reference/calc_gridmet.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate gridMET covariates — calc_gridmet","text":"","code":"calc_gridmet(   from,   locs,   locs_id = NULL,   radius = 0,   fun = \"mean\",   geom = FALSE,   ... )"},{"path":"https://niehs.github.io/amadeus/reference/calc_gridmet.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate gridMET covariates — calc_gridmet","text":"SpatRaster(1). Output process_gridmet(). locs data.frame. character file path, SpatVector, sf object. locs_id character(1). Column within locations CSV file containing identifier unique coordinate location. radius integer(1). Circular buffer distance around site locations. (Default = 0). fun character(1). Function used summarize multiple raster cells within sites location buffer (Default = mean). geom logical(1). function return SpatVector? Default FALSE. coordinate reference system SpatVector . ... Placeholders.","code":""},{"path":"https://niehs.github.io/amadeus/reference/calc_gridmet.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate gridMET covariates — calc_gridmet","text":"data.frame SpatVector object","code":""},{"path":[]},{"path":"https://niehs.github.io/amadeus/reference/calc_gridmet.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Calculate gridMET covariates — calc_gridmet","text":"Mitchell Manware","code":""},{"path":"https://niehs.github.io/amadeus/reference/calc_gridmet.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate gridMET covariates — calc_gridmet","text":"","code":"if (FALSE) { # \\dontrun{ loc <- data.frame(id = \"001\", lon = -78.90, lat = 35.97) calc_gridmet(   from = gridmet, # derived from process_gridmet() example   locs = loc,   locs_id = \"id\",   radius = 0,   fun = \"mean\",   geom = FALSE ) } # }"},{"path":"https://niehs.github.io/amadeus/reference/calc_hms.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate wildfire smoke covariates — calc_hms","title":"Calculate wildfire smoke covariates — calc_hms","text":"Extract wildfire smoke plume values point locations. Returns data.frame object containing locs_id, date, binary variable wildfire smoke plume density inherited (0 = point covered wildfire smoke plume; 1 = point covered wildfire smoke plume).","code":""},{"path":"https://niehs.github.io/amadeus/reference/calc_hms.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate wildfire smoke covariates — calc_hms","text":"","code":"calc_hms(from, locs, locs_id = NULL, radius = 0, geom = FALSE, ...)"},{"path":"https://niehs.github.io/amadeus/reference/calc_hms.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate wildfire smoke covariates — calc_hms","text":"SpatVector(1). Output process_hms(). locs data.frame, characater file path, SpatVector, sf object. locs_id character(1). Column within locations CSV file containing identifier unique coordinate location. radius integer(1). Circular buffer distance around site locations. (Default = 0). geom logical(1). function return SpatVector? Default FALSE. coordinate reference system SpatVector . ... Placeholders.","code":""},{"path":"https://niehs.github.io/amadeus/reference/calc_hms.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate wildfire smoke covariates — calc_hms","text":"data.frame SpatVector object","code":""},{"path":[]},{"path":"https://niehs.github.io/amadeus/reference/calc_hms.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Calculate wildfire smoke covariates — calc_hms","text":"Mitchell Manware","code":""},{"path":"https://niehs.github.io/amadeus/reference/calc_hms.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate wildfire smoke covariates — calc_hms","text":"","code":"if (FALSE) { # \\dontrun{ loc <- data.frame(id = \"001\", lon = -78.90, lat = 35.97) calc_hms(   from = hms, # derived from process_hms() example   locs = loc,   locs_id = \"id\",   radius = 0,   geom = FALSE ) } # }"},{"path":"https://niehs.github.io/amadeus/reference/calc_koppen_geiger.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate climate classification covariates — calc_koppen_geiger","title":"Calculate climate classification covariates — calc_koppen_geiger","text":"Extract climate classification values point locations. Returns data.frame object containing locs_id binary (0 = point climate region; 1 = point climate region) variables climate classification region.","code":""},{"path":"https://niehs.github.io/amadeus/reference/calc_koppen_geiger.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate climate classification covariates — calc_koppen_geiger","text":"","code":"calc_koppen_geiger(   from = NULL,   locs = NULL,   locs_id = \"site_id\",   geom = FALSE,   ... )"},{"path":"https://niehs.github.io/amadeus/reference/calc_koppen_geiger.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate climate classification covariates — calc_koppen_geiger","text":"SpatVector(1). Output process_koppen_geiger(). locs sf/SpatVector. Unique locs. include unique identifier field named locs_id locs_id character(1). Name unique identifier. geom logical(1). function return SpatVector? Default FALSE. coordinate reference system SpatVector . ... Placeholders.","code":""},{"path":"https://niehs.github.io/amadeus/reference/calc_koppen_geiger.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate climate classification covariates — calc_koppen_geiger","text":"data.frame SpatVector object","code":""},{"path":"https://niehs.github.io/amadeus/reference/calc_koppen_geiger.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Calculate climate classification covariates — calc_koppen_geiger","text":"returned object contains $description column represent temporal range covered dataset. information, see https://www.nature.com/articles/sdata2018214.","code":""},{"path":[]},{"path":"https://niehs.github.io/amadeus/reference/calc_koppen_geiger.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Calculate climate classification covariates — calc_koppen_geiger","text":"Insang Song","code":""},{"path":"https://niehs.github.io/amadeus/reference/calc_koppen_geiger.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate climate classification covariates — calc_koppen_geiger","text":"","code":"if (FALSE) { # \\dontrun{ loc <- data.frame(id = \"001\", lon = -78.90, lat = 35.97) calc_koppen_geiger(   from = kg, # derived from process_koppen_geiger() example   locs = loc,   locs_id = \"id\",   geom = FALSE ) } # }"},{"path":"https://niehs.github.io/amadeus/reference/calc_lagged.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate temporally lagged covariates — calc_lagged","title":"Calculate temporally lagged covariates — calc_lagged","text":"calc_lagged() function calculates daily temporal lagged covariates output calculate_covariates() calc_*().","code":""},{"path":"https://niehs.github.io/amadeus/reference/calc_lagged.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate temporally lagged covariates — calc_lagged","text":"","code":"calc_lagged(from, date, lag, locs_id, time_id = \"time\", geom = FALSE)"},{"path":"https://niehs.github.io/amadeus/reference/calc_lagged.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate temporally lagged covariates — calc_lagged","text":"data.frame(1). data.frame containing calculated covariates returned calculate_covariates() calc_*(). date character(2). Start end dates desired lagged covariates. Length 10 , format YYYY-MM-DD (ex. September 1, 2023 = \"2023-09-01\"). lag integer(1). Number lag days. locs_id character(1). Name unique identifier. time_id character(1). Column containing time values. geom logical(1). function return SpatVector? Default FALSE. coordinate reference system SpatVector . return SpatVector, must also SpatVector","code":""},{"path":"https://niehs.github.io/amadeus/reference/calc_lagged.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate temporally lagged covariates — calc_lagged","text":"data.frame object","code":""},{"path":"https://niehs.github.io/amadeus/reference/calc_lagged.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Calculate temporally lagged covariates — calc_lagged","text":"order calculate temporally lagged covariates, must contain least number lag days desired start date. example, date = c(\"2024-01-01\", \"2024-01-31) lag = 1, must contain data starting 2023-12-31. contains geometry features, calc_lagged return column geometry features name. calc_lagged() assumes columns time_id, locs_id, fixed columns \"lat\" \"lon\", follow genre, variable, lag, buffer radius format adopted calc_setcolumns().","code":""},{"path":[]},{"path":"https://niehs.github.io/amadeus/reference/calc_lagged.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate temporally lagged covariates — calc_lagged","text":"","code":"if (FALSE) { # \\dontrun{ loc <- data.frame(id = \"001\", lon = -78.90, lat = 35.97) terracliamte_covar <- calc_terraclimate(   from = terraclimate, # derived from process_terraclimate() example   locs = loc,   locs_id = \"id\",   radius = 0,   fun = \"mean\",   geom = FALSE ) calc_lagged(   from = terracliamte_covar,   locs_id = \"id\",   date = c(\"2023-01-02\", \"2023-01-10\"),   lag = 1,   time_id = \"time\" ) } # }"},{"path":"https://niehs.github.io/amadeus/reference/calc_merra2.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate meteorological and atmospheric covariates — calc_merra2","title":"Calculate meteorological and atmospheric covariates — calc_merra2","text":"Extract meteorological atmospheric values point locations. Returns data.frame object containing locs_id, date hour, vertical pressure level, meteorological atmospheric variable. Variable column name reflects variable circular buffer radius.","code":""},{"path":"https://niehs.github.io/amadeus/reference/calc_merra2.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate meteorological and atmospheric covariates — calc_merra2","text":"","code":"calc_merra2(   from,   locs,   locs_id = NULL,   radius = 0,   fun = \"mean\",   geom = FALSE,   ... )"},{"path":"https://niehs.github.io/amadeus/reference/calc_merra2.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate meteorological and atmospheric covariates — calc_merra2","text":"SpatRaster(1). Output process_merra2(). locs data.frame, characater file path, SpatVector, sf object. locs_id character(1). Column within locations CSV file containing identifier unique coordinate location. radius integer(1). Circular buffer distance around site locations. (Default = 0). fun character(1). Function used summarize multiple raster cells within sites location buffer (Default = mean). geom logical(1). function return SpatVector? Default FALSE. coordinate reference system SpatVector . ... Placeholders","code":""},{"path":"https://niehs.github.io/amadeus/reference/calc_merra2.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate meteorological and atmospheric covariates — calc_merra2","text":"data.frame SpatVector object","code":""},{"path":[]},{"path":"https://niehs.github.io/amadeus/reference/calc_merra2.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Calculate meteorological and atmospheric covariates — calc_merra2","text":"Mitchell Manware","code":""},{"path":"https://niehs.github.io/amadeus/reference/calc_merra2.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate meteorological and atmospheric covariates — calc_merra2","text":"","code":"if (FALSE) { # \\dontrun{ loc <- data.frame(id = \"001\", lon = -78.90, lat = 35.97) calc_merra2(   from = merra2, # derived from process_merra2() example   locs = loc,   locs_id = \"id\",   radius = 0,   fun = \"mean\",   geom = FALSE ) } # }"},{"path":"https://niehs.github.io/amadeus/reference/calc_message.html","id":null,"dir":"Reference","previous_headings":"","what":"Send progress messages — calc_message","title":"Send progress messages — calc_message","text":"Send messages updating covariate extraction progress.","code":""},{"path":"https://niehs.github.io/amadeus/reference/calc_message.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Send progress messages — calc_message","text":"","code":"calc_message(dataset, variable, time, time_type, level)"},{"path":"https://niehs.github.io/amadeus/reference/calc_message.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Send progress messages — calc_message","text":"dataset character(1). Data source. variable placeholder time placeholder time_type placeholder level placeholder","code":""},{"path":"https://niehs.github.io/amadeus/reference/calc_modis_daily.html","id":null,"dir":"Reference","previous_headings":"","what":"A single-date MODIS worker for parallelization — calc_modis_daily","title":"A single-date MODIS worker for parallelization — calc_modis_daily","text":"function operates MODIS/VIIRS products daily basis. Given raw hdf files downloaded NASA, standard file names include data retrieval date flag starting letter \"\". Leveraging piece information, function select files scope date interest. Please note function provide function filter swaths tiles, strongly recommended check pre-filter file names users' discretion.","code":""},{"path":"https://niehs.github.io/amadeus/reference/calc_modis_daily.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A single-date MODIS worker for parallelization — calc_modis_daily","text":"","code":"calc_modis_daily(   from = NULL,   locs = NULL,   locs_id = \"site_id\",   radius = 0L,   date = NULL,   name_extracted = NULL,   fun_summary = \"mean\",   max_cells = 3e+07,   geom = FALSE,   ... )"},{"path":"https://niehs.github.io/amadeus/reference/calc_modis_daily.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"A single-date MODIS worker for parallelization — calc_modis_daily","text":"SpatRaster. Preprocessed objects. locs SpatVector/sf/sftime object. Locations MODIS values summarized. locs_id character(1). Field name unique site identifiers stored. Default \"site_id\" radius numeric. Radius generate circular buffers. date Date(1). date query. name_extracted character. Names calculated covariates. fun_summary function. Summary function multilayer rasters. Passed foo. See exactextractr::exact_extract details. max_cells integer(1). Maximum number cells read . Higher values expedite processing, increase memory usage. Maximum possible value 2^31 - 1. geom logical(1). function return SpatVector? Default FALSE. coordinate reference system SpatVector . See exactextractr::exact_extract details. ... Placeholders.","code":""},{"path":"https://niehs.github.io/amadeus/reference/calc_modis_daily.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"A single-date MODIS worker for parallelization — calc_modis_daily","text":"data.frame SpatVector object.","code":""},{"path":[]},{"path":"https://niehs.github.io/amadeus/reference/calc_modis_daily.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"A single-date MODIS worker for parallelization — calc_modis_daily","text":"Insang Song","code":""},{"path":"https://niehs.github.io/amadeus/reference/calc_modis_daily.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"A single-date MODIS worker for parallelization — calc_modis_daily","text":"","code":"if (FALSE) { # \\dontrun{ locs <- data.frame(lon = -78.8277, lat = 35.95013, id = \"001\") calc_modis_daily(   from = mod06l2_warp,   locs = locs,   locs_id = \"id\",   radius = 0,   date = \"2024-01-01\",   name_extracted = \"cloud_fraction_0\",   fun_summary = \"mean\",   max_cells = 3e7 ) } # }"},{"path":"https://niehs.github.io/amadeus/reference/calc_modis_par.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate MODIS product covariates in multiple CPU threads — calc_modis_par","title":"Calculate MODIS product covariates in multiple CPU threads — calc_modis_par","text":"calc_modis_par essentially runs calc_modis_daily function thread (subprocess). Based daily resolution, day's workload distributed thread. product argument, files processed customized function unique structure /characteristics products considered. nthreads argument carefully selected consideration machine's CPU memory capacities products memory pressure. locs sf object exportable parallel workers.","code":""},{"path":"https://niehs.github.io/amadeus/reference/calc_modis_par.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate MODIS product covariates in multiple CPU threads — calc_modis_par","text":"","code":"calc_modis_par(   from = NULL,   locs = NULL,   locs_id = \"site_id\",   radius = c(0L, 1000L, 10000L, 50000L),   preprocess = process_modis_merge,   name_covariates = NULL,   subdataset = NULL,   fun_summary = \"mean\",   nthreads = floor(length(parallelly::availableWorkers())/2),   package_list_add = NULL,   export_list_add = NULL,   max_cells = 3e+07,   geom = FALSE,   ... )"},{"path":"https://niehs.github.io/amadeus/reference/calc_modis_par.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate MODIS product covariates in multiple CPU threads — calc_modis_par","text":"character. List paths MODIS/VIIRS files. locs sf/SpatVector object. Unique locs covariates calculated. locs_id character(1). Site identifier. Default \"site_id\" radius numeric. Radii calculate covariates. Default c(0, 1000, 10000, 50000). preprocess function. Function handle HDF files. name_covariates character. Name header covariates. e.g., \"MOD_NDVIF_0_\". calculated covariate names form \"{name_covariates}{zero-padded buffer radius meters}\", e.g., 'MOD_NDVIF_0_50000' 50 km radius circular buffer used calculate mean NDVI value. subdataset Indices, names, search patterns subdatasets. Find detail usage argument notes. fun_summary character function. Function summarize extracted raster values. nthreads integer(1). Number threads used calculate covariates. package_list_add character. vector package names load thread. Note sf, terra, exactextractr, doParallel, parallelly dplyr default packages loaded. export_list_add character. vector object names export thread. minimized spare memory. max_cells integer(1). Maximum number cells read . Higher values expedite processing, increase memory usage. Maximum possible value 2^31 - 1. See exactextractr::exact_extract details. geom logical(1). function return SpatVector? Default FALSE. coordinate reference system SpatVector . ... Arguments passed preprocess.","code":""},{"path":"https://niehs.github.io/amadeus/reference/calc_modis_par.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate MODIS product covariates in multiple CPU threads — calc_modis_par","text":"data.frame SpatVector attribute: attr(., \"dates_dropped\"): Dates insufficient tiles. Note dates mean dates insufficient tiles, dates without available tiles.","code":""},{"path":"https://niehs.github.io/amadeus/reference/calc_modis_par.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Calculate MODIS product covariates in multiple CPU threads — calc_modis_par","text":"Overall, function dependent routines assume file system can handle concurrent access (network) disk multiple processes. File system characteristics, package versions, hardware settings specification can affect processing efficiency. locs expected convertible sf object. sf, SpatVector, class objects converted sf can used. Common arguments preprocess functions date path automatically detected passed function. Please note locs path preprocess functions assumed standard naming convention raw files NASA. argument subdataset proper format depending preprocess function: process_modis_merge(): Regular expression pattern. e.g., \"^LST_\" process_modis_swath(): Subdataset names. e.g., c(\"Cloud_Fraction_Day\", \"Cloud_Fraction_Night\") process_blackmarble(): Subdataset number. e.g., VNP46A2 product, 3L. Dates less 80 percent expected number tiles, determined mode number tiles, removed. Users informed dates insufficient tiles. result data.frame attribute dates insufficient tiles.","code":""},{"path":[]},{"path":"https://niehs.github.io/amadeus/reference/calc_modis_par.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate MODIS product covariates in multiple CPU threads — calc_modis_par","text":"","code":"if (FALSE) { # \\dontrun{ locs <- data.frame(lon = -78.8277, lat = 35.95013, id = \"001\") locs <- terra::vect(locs, geom = c(\"lon\", \"lat\"), crs = \"EPSG:4326\") calc_modis_par(   from =     list.files(\"./data\", pattern = \"VNP46A2.\", full.names = TRUE),   locs = locs,   locs_id = \"site_id\",   radius = c(0L, 1000L),   preprocess = process_modis_merge,   name_covariates = \"cloud_fraction_0\",   subdataset = \"Cloud_Fraction\",   fun_summary = \"mean\",   nthreads = 1 ) } # }"},{"path":"https://niehs.github.io/amadeus/reference/calc_narr.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate meteorological covariates — calc_narr","title":"Calculate meteorological covariates — calc_narr","text":"Extract meteorological values point locations. Returns data.frame object containing locs_id, date, vertical pressure level, meteorological variable. Meteorological variable column name reflects variable circular buffer radius.","code":""},{"path":"https://niehs.github.io/amadeus/reference/calc_narr.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate meteorological covariates — calc_narr","text":"","code":"calc_narr(   from,   locs,   locs_id = NULL,   radius = 0,   fun = \"mean\",   geom = FALSE,   ... )"},{"path":"https://niehs.github.io/amadeus/reference/calc_narr.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate meteorological covariates — calc_narr","text":"SpatRaster(1). Output process_narr(). locs data.frame, characater file path, SpatVector, sf object. locs_id character(1). Column within locations CSV file containing identifier unique coordinate location. radius integer(1). Circular buffer distance around site locations. (Default = 0). fun character(1). Function used summarize multiple raster cells within sites location buffer (Default = mean). geom logical(1). function return SpatVector? Default FALSE. coordinate reference system SpatVector . ... Placeholders","code":""},{"path":"https://niehs.github.io/amadeus/reference/calc_narr.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate meteorological covariates — calc_narr","text":"data.frame SpatVector object","code":""},{"path":[]},{"path":"https://niehs.github.io/amadeus/reference/calc_narr.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Calculate meteorological covariates — calc_narr","text":"Mitchell Manware","code":""},{"path":"https://niehs.github.io/amadeus/reference/calc_narr.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate meteorological covariates — calc_narr","text":"","code":"if (FALSE) { # \\dontrun{ loc <- data.frame(id = \"001\", lon = -78.90, lat = 35.97) calc_narr(   from = narr, # derived from process_narr() example   locs = loc,   locs_id = \"id\",   radius = 0,   fun = \"mean\",   geom = FALSE ) } # }"},{"path":"https://niehs.github.io/amadeus/reference/calc_nei.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate road emissions covariates — calc_nei","title":"Calculate road emissions covariates — calc_nei","text":"Calculate road emissions covariates","code":""},{"path":"https://niehs.github.io/amadeus/reference/calc_nei.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate road emissions covariates — calc_nei","text":"","code":"calc_nei(from = NULL, locs = NULL, locs_id = \"site_id\", geom = FALSE, ...)"},{"path":"https://niehs.github.io/amadeus/reference/calc_nei.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate road emissions covariates — calc_nei","text":"SpatVector(1). Output process_nei(). locs sf/SpatVector. Locations NEI values joined. locs_id character(1). Unique site identifier column name. Unused kept compatibility. geom logical(1). function return SpatVector? Default FALSE. coordinate reference system SpatVector . ... Placeholders.","code":""},{"path":"https://niehs.github.io/amadeus/reference/calc_nei.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate road emissions covariates — calc_nei","text":"data.frame SpatVector object","code":""},{"path":[]},{"path":"https://niehs.github.io/amadeus/reference/calc_nei.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Calculate road emissions covariates — calc_nei","text":"Insang Song, Ranadeep Daw","code":""},{"path":"https://niehs.github.io/amadeus/reference/calc_nei.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate road emissions covariates — calc_nei","text":"","code":"if (FALSE) { # \\dontrun{ loc <- data.frame(id = \"001\", lon = -78.90, lat = 35.97) calc_nei(   from = nei, # derived from process_nei example,   locs = loc,   locs_id = \"id\" ) } # }"},{"path":"https://niehs.github.io/amadeus/reference/calc_nlcd.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate land cover covariates — calc_nlcd","title":"Calculate land cover covariates — calc_nlcd","text":"Compute ratio land cover class circle buffers around points. Returns data.frame object containing locs_id, longitude, latitude, time (year), computed ratio land cover class.","code":""},{"path":"https://niehs.github.io/amadeus/reference/calc_nlcd.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate land cover covariates — calc_nlcd","text":"","code":"calc_nlcd(   from,   locs,   locs_id = \"site_id\",   mode = c(\"exact\", \"terra\"),   radius = 1000,   max_cells = 5e+07,   geom = FALSE,   nthreads = 1L,   ... )"},{"path":"https://niehs.github.io/amadeus/reference/calc_nlcd.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate land cover covariates — calc_nlcd","text":"SpatRaster(1). Output process_nlcd(). locs terra::SpatVector points geometry locs_id character(1). Unique identifier locations mode character(1). One \"exact\" (using exactextractr::exact_extract()) \"terra\" (using terra::freq()). radius numeric (non-negative) giving radius buffer around points max_cells integer(1). Maximum number cells read . Higher values may expedite processing, increase memory usage. Maximum possible value 2^31 - 1. valid mode = \"exact\". See exactextractr::exact_extract details. geom logical(1). function return SpatVector? Default FALSE. coordinate reference system SpatVector . nthreads integer(1). Number threads used ... Placeholders.","code":""},{"path":"https://niehs.github.io/amadeus/reference/calc_nlcd.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate land cover covariates — calc_nlcd","text":"data.frame SpatVector object","code":""},{"path":"https://niehs.github.io/amadeus/reference/calc_nlcd.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Calculate land cover covariates — calc_nlcd","text":"NLCD available U.S. . Users aware spatial extent data. results different depending mode argument. \"terra\" mode less memory intensive less accurate counts number cells intersecting buffer. \"exact\" may accurate uses memory account partial overlap buffer.","code":""},{"path":[]},{"path":"https://niehs.github.io/amadeus/reference/calc_nlcd.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate land cover covariates — calc_nlcd","text":"","code":"if (FALSE) { # \\dontrun{ loc <- data.frame(id = \"001\", lon = -78.90, lat = 35.97) calc_nlcd(   from = nlcd, # derived from process_nlcd() example   locs = loc,   locs_id = \"id\",   mode = \"exact\",   geom = FALSE ) } # }"},{"path":"https://niehs.github.io/amadeus/reference/calc_prepare_locs.html","id":null,"dir":"Reference","previous_headings":"","what":"Prepare extraction locations — calc_prepare_locs","title":"Prepare extraction locations — calc_prepare_locs","text":"Prepare point locations extracting data transforming locs SpatVector, projecting coordinate reference system , creating data.frame containing locs_id retaining extracted values.","code":""},{"path":"https://niehs.github.io/amadeus/reference/calc_prepare_locs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Prepare extraction locations — calc_prepare_locs","text":"","code":"calc_prepare_locs(from, locs, locs_id, radius, geom = FALSE)"},{"path":"https://niehs.github.io/amadeus/reference/calc_prepare_locs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Prepare extraction locations — calc_prepare_locs","text":"SpatRaster(1) SpatVector(1). Output process_\\*(). Passed calc_\\*(). locs data.frame. character file path, SpatVector, sf object. Passed calc_\\*(). locs_id character(1). Column within locations CSV file containing identifier unique coordinate location. Passed calc_\\*(). radius integer(1). Circular buffer distance around site locations. (Default = 0). Passed calc_\\*(). geom logical(1). geometry locs returned data.frame? Default FALSE.","code":""},{"path":"https://niehs.github.io/amadeus/reference/calc_prepare_locs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Prepare extraction locations — calc_prepare_locs","text":"list containing SpatVector data.frame objects","code":""},{"path":[]},{"path":"https://niehs.github.io/amadeus/reference/calc_return_locs.html","id":null,"dir":"Reference","previous_headings":"","what":"Prepare covariates for return — calc_return_locs","title":"Prepare covariates for return — calc_return_locs","text":"Check time column proper class , geom = TRUE, transform data.frame SpatVector object.","code":""},{"path":"https://niehs.github.io/amadeus/reference/calc_return_locs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Prepare covariates for return — calc_return_locs","text":"","code":"calc_return_locs(covar, POSIXt = TRUE, geom, crs)"},{"path":"https://niehs.github.io/amadeus/reference/calc_return_locs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Prepare covariates for return — calc_return_locs","text":"covar data.frame(1). Calculated covariates data.frame. POSIXt logical(1). time values covar class POSIXt? FALSE, time values checked integer class (year year-month). geom logical(1). covar returned data.frame? Default FALSE. crs terra::crs(1). Coordinate reference system (inherited ).","code":""},{"path":"https://niehs.github.io/amadeus/reference/calc_return_locs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Prepare covariates for return — calc_return_locs","text":"data.frame SpatVector object (depending geom paramter)","code":""},{"path":"https://niehs.github.io/amadeus/reference/calc_return_locs.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Prepare covariates for return — calc_return_locs","text":"Mitchell Manware","code":""},{"path":"https://niehs.github.io/amadeus/reference/calc_sedac_groads.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate roads covariates — calc_sedac_groads","title":"Calculate roads covariates — calc_sedac_groads","text":"Prepared groads data clipped buffer polygons radius. total length roads calculated. density roads calculated dividing total length area buffer. terra::linearUnits() used convert unit length meters.","code":""},{"path":"https://niehs.github.io/amadeus/reference/calc_sedac_groads.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate roads covariates — calc_sedac_groads","text":"","code":"calc_sedac_groads(   from = NULL,   locs = NULL,   locs_id = NULL,   radius = 1000,   fun = \"sum\",   geom = FALSE,   ... )"},{"path":"https://niehs.github.io/amadeus/reference/calc_sedac_groads.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate roads covariates — calc_sedac_groads","text":"SpatVector(1). Output process_sedac_groads. locs data.frame, characater file path, SpatVector, sf object. locs_id character(1). Column within locations CSV file containing identifier unique coordinate location. radius integer(1). Circular buffer distance around site locations. (Default = 1000). fun function(1). Function used summarize length roads within sites location buffer (Default sum). geom logical(1). function return SpatVector? Default FALSE. coordinate reference system SpatVector . ... Placeholders.","code":""},{"path":"https://niehs.github.io/amadeus/reference/calc_sedac_groads.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate roads covariates — calc_sedac_groads","text":"data.frame SpatVector object","code":""},{"path":"https://niehs.github.io/amadeus/reference/calc_sedac_groads.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Calculate roads covariates — calc_sedac_groads","text":"Unit km / sq km. returned data.frame object contains $time column represent temporal range covered dataset. information, see https://sedac.ciesin.columbia.edu/data/set/groads-global-roads-open-access-v1/metadata.","code":""},{"path":[]},{"path":"https://niehs.github.io/amadeus/reference/calc_sedac_groads.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Calculate roads covariates — calc_sedac_groads","text":"Insang Song","code":""},{"path":"https://niehs.github.io/amadeus/reference/calc_sedac_groads.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate roads covariates — calc_sedac_groads","text":"","code":"if (FALSE) { # \\dontrun{ loc <- data.frame(id = \"001\", lon = -78.90, lat = 35.97) calc_sedac_groads(   from = groads, # derived from process_sedac_groads() example   locs = loc,   locs_id = \"id\",   radius = 1000,   fun = \"sum\",   geom = FALSE ) } # }"},{"path":"https://niehs.github.io/amadeus/reference/calc_sedac_population.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate population density covariates — calc_sedac_population","title":"Calculate population density covariates — calc_sedac_population","text":"Extract population density values point locations. Returns data.frame object containing locs_id, year, population density variable. Population density variable column name reflects spatial resolution circular buffer radius.","code":""},{"path":"https://niehs.github.io/amadeus/reference/calc_sedac_population.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate population density covariates — calc_sedac_population","text":"","code":"calc_sedac_population(   from,   locs,   locs_id = NULL,   radius = 0,   fun = \"mean\",   geom = FALSE,   ... )"},{"path":"https://niehs.github.io/amadeus/reference/calc_sedac_population.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate population density covariates — calc_sedac_population","text":"SpatRaster(1). Output process_sedac_population(). locs data.frame, characater file path, SpatVector, sf object. locs_id character(1). Column within locations CSV file containing identifier unique coordinate location. radius integer(1). Circular buffer distance around site locations. (Default = 0). fun character(1). Function used summarize multiple raster cells within sites location buffer (Default = mean). geom logical(1). function return SpatVector? Default FALSE. coordinate reference system SpatVector . ... Placeholders","code":""},{"path":"https://niehs.github.io/amadeus/reference/calc_sedac_population.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate population density covariates — calc_sedac_population","text":"data.frame SpatVector object","code":""},{"path":[]},{"path":"https://niehs.github.io/amadeus/reference/calc_sedac_population.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Calculate population density covariates — calc_sedac_population","text":"Mitchell Manware","code":""},{"path":"https://niehs.github.io/amadeus/reference/calc_sedac_population.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate population density covariates — calc_sedac_population","text":"","code":"if (FALSE) { # \\dontrun{ loc <- data.frame(id = \"001\", lon = -78.90, lat = 35.97) calc_sedac_population(   from = pop, # derived from process_sedac_population() example   locs = loc,   locs_id = \"id\",   radius = 0,   fun = \"mean\",   geom = FALSE ) } # }"},{"path":"https://niehs.github.io/amadeus/reference/calc_sedc.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate Sum of Exponentially Decaying Contributions (SEDC) covariates — calc_sedc","title":"Calculate Sum of Exponentially Decaying Contributions (SEDC) covariates — calc_sedc","text":"Calculate Sum Exponentially Decaying Contributions (SEDC) covariates","code":""},{"path":"https://niehs.github.io/amadeus/reference/calc_sedc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate Sum of Exponentially Decaying Contributions (SEDC) covariates — calc_sedc","text":"","code":"calc_sedc(   from = NULL,   locs = NULL,   locs_id = NULL,   sedc_bandwidth = NULL,   target_fields = NULL,   geom = FALSE )"},{"path":"https://niehs.github.io/amadeus/reference/calc_sedc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate Sum of Exponentially Decaying Contributions (SEDC) covariates — calc_sedc","text":"SpatVector object. Locations SEDC calculated. locs SpatVector object. Locations sum SEDCs calculated. locs_id character(1). Name unique id field point_to. sedc_bandwidth numeric(1). Distance source concentration reduced exp(-3) (approximately -95 %) target_fields character(varying). Field names characters. geom logical(1). function return SpatVector? Default FALSE. coordinate reference system SpatVector .","code":""},{"path":"https://niehs.github.io/amadeus/reference/calc_sedc.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate Sum of Exponentially Decaying Contributions (SEDC) covariates — calc_sedc","text":"data.frame (tibble) SpatVector object input field names suffix \"_sedc\" sums EDC stored. Additional attributes attached EDC information. `attr(result, \"sedc_bandwidth\")“: bandwidth concentration reduces approximately five percent `attr(result, \"sedc_threshold\")“: threshold distance emission source points excluded beyond ","code":""},{"path":"https://niehs.github.io/amadeus/reference/calc_sedc.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Calculate Sum of Exponentially Decaying Contributions (SEDC) covariates — calc_sedc","text":"function originally chopin Distance calculation done terra functions internally. Thus, function internally converts sf objects point_* arguments terra. threshold carefully chosen users.","code":""},{"path":"https://niehs.github.io/amadeus/reference/calc_sedc.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Calculate Sum of Exponentially Decaying Contributions (SEDC) covariates — calc_sedc","text":"Messier KP, Akita Y, Serre ML (2012). “Integrating Address Geocoding, Land Use Regression, Spatiotemporal Geostatistical Estimation Groundwater Tetrachloroethylene.” Environmental Science & Technology, 46(5), 2772–2780. ISSN 0013-936X, doi:10.1021/es203152a .  Wiesner C (????). “Euclidean Sum Exponentially Decaying Contributions Tutorial.” https://mserre.sph.unc.edu/BMElab_web/SEDCtutorial/index.html.","code":""},{"path":"https://niehs.github.io/amadeus/reference/calc_sedc.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Calculate Sum of Exponentially Decaying Contributions (SEDC) covariates — calc_sedc","text":"Insang Song","code":""},{"path":"https://niehs.github.io/amadeus/reference/calc_sedc.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate Sum of Exponentially Decaying Contributions (SEDC) covariates — calc_sedc","text":"","code":"library(terra) #> terra 1.7.78 library(sf) #> Linking to GEOS 3.10.2, GDAL 3.4.1, PROJ 8.2.1; sf_use_s2() is TRUE set.seed(101) ncpath <- system.file(\"gpkg/nc.gpkg\", package = \"sf\") nc <- terra::vect(ncpath) nc <- terra::project(nc, \"EPSG:5070\") pnt_locs <- terra::centroids(nc, inside = TRUE) pnt_locs <- pnt_locs[, \"NAME\"] pnt_from <- terra::spatSample(nc, 100L) pnt_from$pid <- seq(1, 100) pnt_from <- pnt_from[, \"pid\"] pnt_from$val1 <- rgamma(100L, 1, 0.05) pnt_from$val2 <- rgamma(100L, 2, 1)  vals <- c(\"val1\", \"val2\") calc_sedc(pnt_locs, pnt_from, \"NAME\", 1e5, vals) #> Joining with `by = join_by(from_id)` #> Joining with `by = join_by(to_id)` #> Joining with `by = join_by(from_id, to_id)` #>             NAME       val1       val2 #> 1       Alamance  66.306697  6.7116902 #> 2      Alexander  97.987170 11.6645958 #> 3      Alleghany 135.316205  8.5703397 #> 4          Anson  50.005415  5.2276410 #> 5           Ashe 143.015620  8.4157319 #> 6          Avery  76.088990  8.7578666 #> 7       Beaufort  58.759937  6.2939195 #> 8         Bertie  70.112408  7.8469177 #> 9         Bladen  79.513358  6.8157166 #> 10     Brunswick  54.292706  5.3356971 #> 11      Buncombe  57.603317  9.6687275 #> 12         Burke  91.378099 13.5219825 #> 13      Cabarrus  64.421536  7.2742864 #> 14      Caldwell 103.478357 11.6921332 #> 15        Camden  77.730226  4.5635043 #> 16      Carteret  45.586379  6.0638371 #> 17       Caswell  46.799679  4.7822705 #> 18       Catawba  77.542299 12.2965447 #> 19       Chatham  81.981947  8.1190512 #> 20      Cherokee   3.915403  0.9588335 #> 21        Chowan  64.504924  6.0186155 #> 22          Clay   9.749667  2.4724810 #> 23     Cleveland  67.458061  9.8771979 #> 24      Columbus  48.414701  5.1153279 #> 25        Craven  61.597042  4.9988722 #> 26    Cumberland  96.540752  8.2064850 #> 27     Currituck  63.140911  4.0256414 #> 28          Dare  41.540511  3.4968348 #> 29      Davidson  87.860462 12.1240335 #> 30         Davie  90.343496 13.6229310 #> 31        Duplin  68.001564  5.3855035 #> 32        Durham  79.049439  6.2339198 #> 33     Edgecombe  70.147137  6.9895227 #> 34       Forsyth  71.195554 13.3624413 #> 35      Franklin  66.157171  6.4014195 #> 36        Gaston  48.671028  7.6455348 #> 37         Gates  64.098198  5.5317312 #> 38        Graham   7.198239  1.6872974 #> 39     Granville  49.656550  4.7207362 #> 40        Greene  90.485199  5.7627158 #> 41      Guilford  57.173967  8.4095114 #> 42       Halifax  73.885565  7.7264226 #> 43       Harnett  98.976569  8.5364366 #> 44       Haywood  38.540767  6.6754283 #> 45     Henderson  53.566765  6.8870803 #> 46      Hertford  76.272095  7.1651027 #> 47          Hoke 103.981765  8.3039185 #> 48          Hyde  67.876877  6.0577500 #> 49       Iredell  80.189217 11.8598788 #> 50       Jackson  21.292017  6.0767266 #> 51      Johnston  93.203340  7.1667761 #> 52         Jones  66.025083  4.9071098 #> 53           Lee  97.560011  9.4921343 #> 54        Lenoir  77.550455  5.1551243 #> 55       Lincoln  63.939958  9.9774137 #> 56         Macon  15.059649  4.2463505 #> 57       Madison  70.241627 10.2826394 #> 58        Martin  66.537364  7.5693036 #> 59      McDowell  67.787551 10.2585459 #> 60   Mecklenburg  50.862565  7.7914928 #> 61      Mitchell  65.031353  8.5814715 #> 62    Montgomery  59.749763  6.0405602 #> 63         Moore  78.615922  7.3924314 #> 64          Nash  64.385415  6.4241311 #> 65   New Hanover  67.931926  4.6333534 #> 66   Northampton 118.738765  9.2546833 #> 67        Onslow  77.084563  5.0114996 #> 68        Orange  72.966060  6.0369847 #> 69       Pamlico  50.073396  5.3901503 #> 70    Pasquotank  74.974591  4.7458824 #> 71        Pender  79.062124  5.6213647 #> 72    Perquimans  66.431520  5.0567758 #> 73        Person  52.598860  4.1839645 #> 74          Pitt  79.072691  5.8360247 #> 75          Polk  50.487473  7.5159326 #> 76      Randolph  70.147697  7.7840601 #> 77      Richmond  61.478506  6.1899525 #> 78       Robeson  86.300294  6.6178460 #> 79    Rockingham  44.705144  8.4209078 #> 80         Rowan  76.998697 10.2729658 #> 81    Rutherford  62.626215 10.1472106 #> 82       Sampson  70.487687  6.6277097 #> 83      Scotland  76.605109  6.8632094 #> 84        Stanly  62.852360  6.4087924 #> 85        Stokes  62.166361 16.0572751 #> 86         Surry  81.764284 12.2180431 #> 87         Swain  13.035910  2.6972329 #> 88  Transylvania  30.106402  5.9152072 #> 89       Tyrrell  67.837730  5.6893818 #> 90         Union  40.905040  5.1267190 #> 91         Vance  47.201872  5.9009680 #> 92          Wake 102.424634  7.3683230 #> 93        Warren  41.919319  6.5553331 #> 94    Washington  59.440806  5.7795964 #> 95       Watauga 108.967001 10.6908618 #> 96         Wayne  87.168169  6.2273127 #> 97        Wilkes 143.398693 11.2777982 #> 98        Wilson  74.670837  6.1711863 #> 99        Yadkin  95.006796 14.9158944 #> 100       Yancey  62.559665  9.3954516"},{"path":"https://niehs.github.io/amadeus/reference/calc_setcolumns.html","id":null,"dir":"Reference","previous_headings":"","what":"Set column names — calc_setcolumns","title":"Set column names — calc_setcolumns","text":"Apply standard column names calculated covariates consistent requirements beethoven package. Column names follow fixed format 3 character data genre, 2 - 15 character variable code, 1 digit temporal lag, 5 digit buffer radius (meters). Variable code character range required retain interpretable column names across datasets.","code":""},{"path":"https://niehs.github.io/amadeus/reference/calc_setcolumns.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Set column names — calc_setcolumns","text":"","code":"calc_setcolumns(from, lag, dataset, locs_id)"},{"path":"https://niehs.github.io/amadeus/reference/calc_setcolumns.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Set column names — calc_setcolumns","text":"data.frame(1) SpatVector(1). Calculated covariates returned calc_covariates() source specific covariate function. lag integer(1). Temporal lag. dataset character(1). Covariate parent dataset. locs_id character(1). Column containing identifier unique coordinate location.","code":""},{"path":"https://niehs.github.io/amadeus/reference/calc_setcolumns.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Set column names — calc_setcolumns","text":"data.frame SpatVector object (depending )","code":""},{"path":"https://niehs.github.io/amadeus/reference/calc_setcolumns.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Set column names — calc_setcolumns","text":"beethoven utilizes point, 1km, 10km radius buffer distance covariate calculation, therefore buffer radius column padded 5 digits. provided buffer radius greater 5 digits, calc_setcolumns() expand number digits. (ie. buffer radius 100km = CCC_CCCCC_I_100000).","code":""},{"path":"https://niehs.github.io/amadeus/reference/calc_temporal_dummies.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate temporal dummy covariates — calc_temporal_dummies","title":"Calculate temporal dummy covariates — calc_temporal_dummies","text":"Calculate temporal dummy covariates point locations. Returns data.frame object locs_id, year binary variable value year, month day week binary variables.","code":""},{"path":"https://niehs.github.io/amadeus/reference/calc_temporal_dummies.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate temporal dummy covariates — calc_temporal_dummies","text":"","code":"calc_temporal_dummies(   locs,   locs_id = \"site_id\",   year = seq(2018L, 2022L),   geom = FALSE,   ... )"},{"path":"https://niehs.github.io/amadeus/reference/calc_temporal_dummies.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate temporal dummy covariates — calc_temporal_dummies","text":"locs data.frame temporal field named \"time\" locs_id character(1). Unique site identifier column name. Default \"site_id\". year integer. Year domain dummify. Default seq(2018L, 2022L). geom logical(1). function return SpatVector? Default FALSE. coordinate reference system SpatVector . ... Placeholders.","code":""},{"path":"https://niehs.github.io/amadeus/reference/calc_temporal_dummies.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate temporal dummy covariates — calc_temporal_dummies","text":"data.frame SpatVector object","code":""},{"path":"https://niehs.github.io/amadeus/reference/calc_temporal_dummies.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Calculate temporal dummy covariates — calc_temporal_dummies","text":"Insang Song","code":""},{"path":"https://niehs.github.io/amadeus/reference/calc_temporal_dummies.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate temporal dummy covariates — calc_temporal_dummies","text":"","code":"if (FALSE) { # \\dontrun{ loc <- data.frame(id = \"001\", lon = -78.90, lat = 35.97) calc_temporal_dummies(   locs = loc,   locs_id = \"id\",   year = seq(2018L, 2022L) ) } # }"},{"path":"https://niehs.github.io/amadeus/reference/calc_terraclimate.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate TerraClimate covariates — calc_terraclimate","title":"Calculate TerraClimate covariates — calc_terraclimate","text":"Extract TerraClimate values point locations. Returns data.frame object containing locs_id TerraClimate variable. TerraClimate variable column name reflects TerraClimate variable circular buffer radius.","code":""},{"path":"https://niehs.github.io/amadeus/reference/calc_terraclimate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate TerraClimate covariates — calc_terraclimate","text":"","code":"calc_terraclimate(   from = NULL,   locs = NULL,   locs_id = NULL,   radius = 0,   fun = \"mean\",   geom = FALSE,   ... )"},{"path":"https://niehs.github.io/amadeus/reference/calc_terraclimate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate TerraClimate covariates — calc_terraclimate","text":"SpatRaster(1). Output process_terraclimate(). locs data.frame. character file path, SpatVector, sf object. locs_id character(1). Column within locations CSV file containing identifier unique coordinate location. radius integer(1). Circular buffer distance around site locations. (Default = 0). fun character(1). Function used summarize multiple raster cells within sites location buffer (Default = mean). geom logical(1). function return SpatVector? Default FALSE. coordinate reference system SpatVector . ... Placeholders.","code":""},{"path":"https://niehs.github.io/amadeus/reference/calc_terraclimate.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate TerraClimate covariates — calc_terraclimate","text":"data.frame SpatVector object","code":""},{"path":"https://niehs.github.io/amadeus/reference/calc_terraclimate.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Calculate TerraClimate covariates — calc_terraclimate","text":"TerraClimate data monthly temporal resolution, $time column contain year month YYYYMM format (ie. January, 2018 = 201801).","code":""},{"path":[]},{"path":"https://niehs.github.io/amadeus/reference/calc_terraclimate.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Calculate TerraClimate covariates — calc_terraclimate","text":"Mitchell Manware","code":""},{"path":"https://niehs.github.io/amadeus/reference/calc_terraclimate.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate TerraClimate covariates — calc_terraclimate","text":"","code":"if (FALSE) { # \\dontrun{ loc <- data.frame(id = \"001\", lon = -78.90, lat = 35.97) calc_terraclimate(   from = terraclimate, # derived from process_terraclimate() example   locs = loc,   locs_id = \"id\",   radius = 0,   fun = \"mean\",   geom = FALSE ) } # }"},{"path":"https://niehs.github.io/amadeus/reference/calc_time.html","id":null,"dir":"Reference","previous_headings":"","what":"Prepare time values — calc_time","title":"Prepare time values — calc_time","text":"Prepare time values covariate calculation based type time value.","code":""},{"path":"https://niehs.github.io/amadeus/reference/calc_time.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Prepare time values — calc_time","text":"","code":"calc_time(time, format)"},{"path":"https://niehs.github.io/amadeus/reference/calc_time.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Prepare time values — calc_time","text":"time Time value format Type time return $time column. Can \"timeless\" (ie. Ecoregions data), \"date\" (ie. NARR data), \"hour\" (ie. GEOS data), \"year\" (ie. SEDAC population data), \"yearmonth\" (ie. TerraClimate data).","code":""},{"path":"https://niehs.github.io/amadeus/reference/calc_time.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Prepare time values — calc_time","text":"Date, POSIXt, integer object based format =","code":""},{"path":"https://niehs.github.io/amadeus/reference/calc_tri.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate toxic release covariates — calc_tri","title":"Calculate toxic release covariates — calc_tri","text":"Extract toxic release values point locations. Returns data.frame object containing locs_id variables chemical .","code":""},{"path":"https://niehs.github.io/amadeus/reference/calc_tri.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate toxic release covariates — calc_tri","text":"","code":"calc_tri(   from = NULL,   locs,   locs_id = \"site_id\",   radius = c(1000L, 10000L, 50000L),   geom = FALSE,   ... )"},{"path":"https://niehs.github.io/amadeus/reference/calc_tri.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate toxic release covariates — calc_tri","text":"SpatVector(1). Output process_tri(). locs sf/SpatVector. Locations TRI variables calculated. locs_id character(1). Unique site identifier column name. Default \"site_id\". radius Circular buffer radius. Default c(1000, 10000, 50000) (meters) geom logical(1). function return SpatVector? Default FALSE. coordinate reference system SpatVector . ... Placeholders.","code":""},{"path":"https://niehs.github.io/amadeus/reference/calc_tri.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate toxic release covariates — calc_tri","text":"data.frame SpatVector object","code":""},{"path":"https://niehs.github.io/amadeus/reference/calc_tri.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Calculate toxic release covariates — calc_tri","text":"U.S. context.","code":""},{"path":[]},{"path":"https://niehs.github.io/amadeus/reference/calc_tri.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Calculate toxic release covariates — calc_tri","text":"Insang Song, Mariana Kassien","code":""},{"path":"https://niehs.github.io/amadeus/reference/calc_tri.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate toxic release covariates — calc_tri","text":"","code":"if (FALSE) { # \\dontrun{ loc <- data.frame(id = \"001\", lon = -78.90, lat = 35.97) calc_tri(   from = tri, # derived from process_tri() example   locs = loc,   locs_id = \"id\",   radius = c(1e3L, 1e4L, 5e4L) ) } # }"},{"path":"https://niehs.github.io/amadeus/reference/calc_worker.html","id":null,"dir":"Reference","previous_headings":"","what":"Perform covariate extraction — calc_worker","title":"Perform covariate extraction — calc_worker","text":"Extract covariate values SpatRaster object passed process_*().","code":""},{"path":"https://niehs.github.io/amadeus/reference/calc_worker.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Perform covariate extraction — calc_worker","text":"","code":"calc_worker(   dataset,   from,   locs_vector,   locs_df,   fun,   variable = 1,   time,   time_type = c(\"date\", \"hour\", \"year\", \"yearmonth\", \"timeless\"),   radius,   level = NULL,   max_cells = 1e+08,   ... )"},{"path":"https://niehs.github.io/amadeus/reference/calc_worker.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Perform covariate extraction — calc_worker","text":"dataset character(1). Dataset name. SpatRaster(1). Cleaned SpatRaster object. locs_vector SpatVector(1). Cleaned SpatVector object passed calc_prepare_locs(). Contains location point/polygon values. locs_df data.frame(1). Cleaned data.frame object passed calc_prepare_locs(). Contains location identifiers. fun character(1). Summary function. Passed terra::extract(). variable integer. Position within layer name containing variable name/code. time integer. Position within layer name containing time value(s). time_type character(1). Type time observation. One \"date\", \"hour\", \"year\", \"yearmonth\", \"timeless\". radius integer(1). Buffer distance (m). Passed calc_prepare_locs(). Used column naming. level integer. Position within layer name containing vertical pressure level value (applicable). Default = NULL. max_cells integer(1). Maximum number cells read . Higher values expedite processing, increase memory usage. Maximum possible value 2^31 - 1. See exactextractr::exact_extract details. ... Placeholders.","code":""},{"path":"https://niehs.github.io/amadeus/reference/calc_worker.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Perform covariate extraction — calc_worker","text":"data.frame object","code":""},{"path":"https://niehs.github.io/amadeus/reference/check_for_null_parameters.html","id":null,"dir":"Reference","previous_headings":"","what":"Check parameters — check_for_null_parameters","title":"Check parameters — check_for_null_parameters","text":"Check parameters assigned value.","code":""},{"path":"https://niehs.github.io/amadeus/reference/check_for_null_parameters.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check parameters — check_for_null_parameters","text":"","code":"check_for_null_parameters(parameters)"},{"path":"https://niehs.github.io/amadeus/reference/check_for_null_parameters.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check parameters — check_for_null_parameters","text":"parameters parameters passed function (called mget(ls()).)","code":""},{"path":"https://niehs.github.io/amadeus/reference/check_mysf.html","id":null,"dir":"Reference","previous_headings":"","what":"Check sf object — check_mysf","title":"Check sf object — check_mysf","text":"Check sf object class, $geometry column, geometry class.","code":""},{"path":"https://niehs.github.io/amadeus/reference/check_mysf.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check sf object — check_mysf","text":"","code":"check_mysf(x)"},{"path":"https://niehs.github.io/amadeus/reference/check_mysf.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check sf object — check_mysf","text":"x sf object","code":""},{"path":"https://niehs.github.io/amadeus/reference/check_mysf.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Check sf object — check_mysf","text":"Eva Marques","code":""},{"path":"https://niehs.github.io/amadeus/reference/check_mysftime.html","id":null,"dir":"Reference","previous_headings":"","what":"Check sftime object — check_mysftime","title":"Check sftime object — check_mysftime","text":"Check sftime object class, $time column, $geometry column, geometry class.","code":""},{"path":"https://niehs.github.io/amadeus/reference/check_mysftime.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check sftime object — check_mysftime","text":"","code":"check_mysftime(x)"},{"path":"https://niehs.github.io/amadeus/reference/check_mysftime.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check sftime object — check_mysftime","text":"x sftime object","code":""},{"path":"https://niehs.github.io/amadeus/reference/check_mysftime.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Check sftime object — check_mysftime","text":"Eva Marques","code":""},{"path":"https://niehs.github.io/amadeus/reference/check_url_status.html","id":null,"dir":"Reference","previous_headings":"","what":"Check HTTP status — check_url_status","title":"Check HTTP status — check_url_status","text":"Check provided URL returns HTTP status 200 206.","code":""},{"path":"https://niehs.github.io/amadeus/reference/check_url_status.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check HTTP status — check_url_status","text":"","code":"check_url_status(url, method = c(\"HEAD\", \"GET\"))"},{"path":"https://niehs.github.io/amadeus/reference/check_url_status.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check HTTP status — check_url_status","text":"url Download URL checked. method httr method obtain URL (\"HEAD\" \"GET\")","code":""},{"path":"https://niehs.github.io/amadeus/reference/check_url_status.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check HTTP status — check_url_status","text":"logical object","code":""},{"path":"https://niehs.github.io/amadeus/reference/check_url_status.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Check HTTP status — check_url_status","text":"Insang Song; Mitchell Manware","code":""},{"path":"https://niehs.github.io/amadeus/reference/check_urls.html","id":null,"dir":"Reference","previous_headings":"","what":"Implement check_url_status — check_urls","title":"Implement check_url_status — check_urls","text":"Apply check_url_status() function sample download URLs.","code":""},{"path":"https://niehs.github.io/amadeus/reference/check_urls.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Implement check_url_status — check_urls","text":"","code":"check_urls(urls = urls, size = NULL, method = c(\"HEAD\", \"GET\", \"SKIP\"))"},{"path":"https://niehs.github.io/amadeus/reference/check_urls.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Implement check_url_status — check_urls","text":"urls character vector URLs size number observations sampled urls method httr method obtain URL (\"HEAD\" \"GET\"). set \"SKIP\", HTTP status checked returned.","code":""},{"path":"https://niehs.github.io/amadeus/reference/check_urls.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Implement check_url_status — check_urls","text":"logical vector URL status = 200","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_aqs.html","id":null,"dir":"Reference","previous_headings":"","what":"Download air quality data — download_aqs","title":"Download air quality data — download_aqs","text":"download_aqs() function accesses downloads Air Quality System (AQS) data U.S. Environmental Protection Agency's (EPA) Pre-Generated Data Files.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_aqs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Download air quality data — download_aqs","text":"","code":"download_aqs(   parameter_code = 88101,   resolution_temporal = \"daily\",   year = c(2018, 2022),   url_aqs_download = \"https://aqs.epa.gov/aqsweb/airdata/\",   directory_to_save = NULL,   acknowledgement = FALSE,   download = FALSE,   remove_command = FALSE,   unzip = TRUE,   remove_zip = FALSE )"},{"path":"https://niehs.github.io/amadeus/reference/download_aqs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Download air quality data — download_aqs","text":"parameter_code integer(1). length 5. EPA pollutant parameter code. details, please refer AQS parameter codes resolution_temporal character(1). Name column containing POC values. Currently, value \"daily\" works. year character(2). length 4 . Start/end years downloading data. url_aqs_download character(1). URL AQS pre-generated datasets. directory_to_save character(1). Directory save data. Two sub-directories created downloaded zip files (\"/zip_files\") unzipped data files (\"/data_files\"). acknowledgement logical(1). setting TRUE user acknowledges data downloaded using function may large use lots machine storage memory. download logical(1). FALSE generate *.txt file containing download commands. setting TRUE function download requested data files. remove_command logical(1). Remove (TRUE) keep (FALSE) text file containing download commands. Default FALSE. unzip logical(1). Unzip zip files. Default TRUE. remove_zip logical(1). Remove zip file directory_to_download. Default FALSE.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_aqs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Download air quality data — download_aqs","text":"NULL; Zip /data files downloaded stored directory_to_save.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_aqs.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Download air quality data — download_aqs","text":"U.S. Environmental Protection Agency (2023). “Air Quality System Data Mart [internet database].” https://www.epa.gov/outdoor-air-quality-data.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_aqs.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Download air quality data — download_aqs","text":"Mariana Kassien, Insang Song, Mitchell Manware","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_aqs.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Download air quality data — download_aqs","text":"","code":"if (FALSE) { # \\dontrun{ download_aqs(   parameter_code = 88101,   resolution_temporal = \"daily\",   year = c(2022, 2023),   directory_to_save = \"./data\",   acknowledgement = TRUE,   download = TRUE,   remove_command = TRUE ) } # }"},{"path":"https://niehs.github.io/amadeus/reference/download_cropscape.html","id":null,"dir":"Reference","previous_headings":"","what":"Download CropScape data — download_cropscape","title":"Download CropScape data — download_cropscape","text":"Accesses downloads United States Department Agriculture CropScape Cropland Data Layer data USDA National Agricultural Statistics Service George Mason University website.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_cropscape.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Download CropScape data — download_cropscape","text":"","code":"download_cropscape(   year = seq(1997, 2023),   source = c(\"USDA\", \"GMU\"),   directory_to_save = NULL,   acknowledgement = FALSE,   download = FALSE,   remove_command = FALSE,   unzip = TRUE )"},{"path":"https://niehs.github.io/amadeus/reference/download_cropscape.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Download CropScape data — download_cropscape","text":"year integer(1). Year data download. source character(1). Data source, one c(\"USDA\", \"GMU\"). \"USDA\" download national data USDA website (available 2008-last year). \"GMU\" download data George Mason University website (available 1997-last year). directory_to_save character(1). Directory download files. acknowledgement logical(1). setting TRUE user acknowledges data downloaded using function may large use lots machine storage memory. download logical(1). FALSE generate *.txt file containing download commands. setting TRUE function download requested data files. remove_command logical(1). Remove (TRUE) keep (FALSE) text file containing download commands. unzip logical(1). Unzip downloaded compressed files. Default FALSE.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_cropscape.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Download CropScape data — download_cropscape","text":"NULL; Yearly comma-separated value (CSV) files stored directory_to_save.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_cropscape.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Download CropScape data — download_cropscape","text":"JSON files found STAC catalog OpenLandMap","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_cropscape.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Download CropScape data — download_cropscape","text":"Insang Song","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_cropscape.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Download CropScape data — download_cropscape","text":"","code":"if (FALSE) { # \\dontrun{ download_cropscape(   year = 2020,   source = \"USDA\",   directory_to_save = \"./data\",   acknowledgement = TRUE,   download = TRUE,   remove_command = TRUE ) } # }"},{"path":"https://niehs.github.io/amadeus/reference/download_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Download raw data wrapper function — download_data","title":"Download raw data wrapper function — download_data","text":"download_data() function accesses downloads atmospheric, meteorological, environmental data various open-access data sources.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Download raw data wrapper function — download_data","text":"","code":"download_data(   dataset_name = c(\"aqs\", \"ecoregion\", \"ecoregions\", \"geos\", \"gmted\", \"koppen\",     \"koppengeiger\", \"merra2\", \"merra\", \"modis\", \"narr\", \"nlcd\", \"noaa\", \"sedac_groads\",     \"sedac_population\", \"groads\", \"population\", \"hms\", \"smoke\", \"tri\", \"nei\", \"gridmet\",     \"terraclimate\", \"huc\", \"cropscape\", \"cdl\", \"prism\", \"olm\", \"openlandmap\"),   directory_to_save = NULL,   acknowledgement = FALSE,   ... )"},{"path":"https://niehs.github.io/amadeus/reference/download_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Download raw data wrapper function — download_data","text":"dataset_name character(1). Dataset download. directory_to_save character(1). Directory save / unzip (zip files downloaded) data. acknowledgement logical(1). setting TRUE user acknowledges data downloaded using function may large use lots machine storage memory. ... Arguments passed download function.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_data.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Download raw data wrapper function — download_data","text":"download function names download_* formats","code":""},{"path":[]},{"path":"https://niehs.github.io/amadeus/reference/download_data.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Download raw data wrapper function — download_data","text":"Insang Song","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_data.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Download raw data wrapper function — download_data","text":"","code":"if (FALSE) { # \\dontrun{ download_data(   dataset_name = \"narr\",   variables = \"weasd\",   year = c(2023, 2023),   directory_to_save = \"./data\",   acknowledgement = TRUE,   download = TRUE,   remove_commands = TRUE ) } # }"},{"path":"https://niehs.github.io/amadeus/reference/download_ecoregion.html","id":null,"dir":"Reference","previous_headings":"","what":"Download ecoregion data — download_ecoregion","title":"Download ecoregion data — download_ecoregion","text":"download_ecoregion() function accesses downloads United States Ecoregions data U.S. Environmental Protection Agency's (EPA) Ecorgions. Level 3 data, pieces information higher levels included, downloaded.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_ecoregion.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Download ecoregion data — download_ecoregion","text":"","code":"download_ecoregion(   epa_certificate_path = system.file(\"extdata/cacert_gaftp_epa.pem\", package = \"amadeus\"),   certificate_url =     \"http://cacerts.digicert.com/DigiCertGlobalG2TLSRSASHA2562020CA1-1.crt\",   directory_to_save = NULL,   acknowledgement = FALSE,   download = FALSE,   remove_command = FALSE,   unzip = TRUE,   remove_zip = FALSE )"},{"path":"https://niehs.github.io/amadeus/reference/download_ecoregion.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Download ecoregion data — download_ecoregion","text":"epa_certificate_path character(1). Path certificate file EPA DataCommons. Default 'extdata/cacert_gaftp_epa.pem' package installation path. certificate_url character(1). URL certificate file. See notes details. directory_to_save character(1). Directory save data. Two sub-directories created downloaded zip files (\"/zip_files\") unzipped data files (\"/data_files\"). acknowledgement logical(1). setting TRUE user acknowledges data downloaded using function may large use lots machine storage memory. download logical(1). FALSE generate *.txt file containing download commands. setting TRUE function download requested data files. remove_command logical(1). Remove (TRUE) keep (FALSE) text file containing download commands. unzip logical(1). Unzip zip files. Default TRUE. remove_zip logical(1). Remove zip file directory_to_download. Default FALSE.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_ecoregion.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Download ecoregion data — download_ecoregion","text":"NULL; Zip /data files downloaded stored directory_to_save.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_ecoregion.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Download ecoregion data — download_ecoregion","text":"EPA Data Commons certificate errors, follow steps : Click Lock icon address bar https://gaftp.epa.gov Click Show Certificate Access Details Find URL *.crt extension Currently bundle pre-downloaded crt PEM (accepted wget command) file ./inst/extdata. instruction certificate updates future.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_ecoregion.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Download ecoregion data — download_ecoregion","text":"Omernik JM, Griffith GE (2014). “Ecoregions Conterminous United States: Evolution Hierarchical Spatial Framework.” Environmental Management, 54(6), 1249–1266. ISSN 0364-152X, 1432-1009, doi:10.1007/s00267-014-0364-1 , https://link.springer.com/article/10.1007/s00267-014-0364-1.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_ecoregion.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Download ecoregion data — download_ecoregion","text":"Insang Song","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_ecoregion.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Download ecoregion data — download_ecoregion","text":"","code":"if (FALSE) { # \\dontrun{ download_ecoregion(   directory_to_save = \"./data\",   acknowledgement = TRUE,   download = TRUE,   remove_command = TRUE ) } # }"},{"path":"https://niehs.github.io/amadeus/reference/download_epa_certificate.html","id":null,"dir":"Reference","previous_headings":"","what":"Check EPA certificate — download_epa_certificate","title":"Check EPA certificate — download_epa_certificate","text":"Check EPA certificate","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_epa_certificate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check EPA certificate — download_epa_certificate","text":"","code":"download_epa_certificate(   epa_certificate_path = \"cacert_gaftp_epa.pem\",   certificate_url =     \"http://cacerts.digicert.com/DigiCertGlobalG2TLSRSASHA2562020CA1-1.crt\" )"},{"path":"https://niehs.github.io/amadeus/reference/download_epa_certificate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check EPA certificate — download_epa_certificate","text":"epa_certificate_path character(1). Full path converted certificate EPA. end .pem certificate_url character(1). URL original certificate.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_epa_certificate.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check EPA certificate — download_epa_certificate","text":"file designated epa_certificate_path","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_epa_certificate.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Check EPA certificate — download_epa_certificate","text":"Insang Song","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_geos.html","id":null,"dir":"Reference","previous_headings":"","what":"Download atmospheric composition data — download_geos","title":"Download atmospheric composition data — download_geos","text":"download_geos() function accesses downloads various atmospheric composition collections NASA's Global Earth Observing System (GEOS) model.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_geos.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Download atmospheric composition data — download_geos","text":"","code":"download_geos(   collection = c(\"aqc_tavg_1hr_g1440x721_v1\", \"chm_tavg_1hr_g1440x721_v1\",     \"met_tavg_1hr_g1440x721_x1\", \"xgc_tavg_1hr_g1440x721_x1\",     \"chm_inst_1hr_g1440x721_p23\", \"met_inst_1hr_g1440x721_p23\"),   date = c(\"2018-01-01\", \"2018-01-01\"),   directory_to_save = NULL,   acknowledgement = FALSE,   download = FALSE,   remove_command = FALSE )"},{"path":"https://niehs.github.io/amadeus/reference/download_geos.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Download atmospheric composition data — download_geos","text":"collection character(1). GEOS-CF data collection file name. date character(2). length 10 . Start/end date downloading data. Format \"YYYY-MM-DD\" (ex. January 1, 2018 = \"2018-01-01\"). directory_to_save character(1). Directory save data. Sub-directories created within directory_to_save GEOS-CF collection. acknowledgement logical(1). setting TRUE user acknowledges data downloaded using function may large use lots machine storage memory. download logical(1). FALSE generate *.txt file containing download commands. setting TRUE function download requested data files. remove_command logical(1). Remove (TRUE) keep (FALSE) text file containing download commands.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_geos.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Download atmospheric composition data — download_geos","text":"NULL; netCDF (.nc4) files stored collection-specific folder within directory_to_save.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_geos.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Download atmospheric composition data — download_geos","text":"Keller CA, Knowland KE, Duncan BN, Liu J, Anderson DC, Das S, Lucchesi RA, Lundgren EW, Nicely JM, Nielsen E, Ott LE, Saunders E, Strode SA, Wales PA, Jacob DJ, Pawson S (2021). “Description NASA GEOS Composition Forecast Modeling System GEOS‐CF v1.0.” Journal Advances Modeling Earth Systems, 13(4), e2020MS002413. ISSN 1942-2466, 1942-2466, doi:10.1029/2020MS002413 , 2024-06-24.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_geos.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Download atmospheric composition data — download_geos","text":"Mitchell Manware, Insang Song","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_geos.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Download atmospheric composition data — download_geos","text":"","code":"if (FALSE) { # \\dontrun{ download_geos(   collection = \"aqc_tavg_1hr_g1440x721_v1\",   date = c(\"2024-01-01\", \"2024-01-05\"),   directory_to_save = \"./data\",   acknowledgement = TRUE,   download = TRUE,   remove_command = TRUE ) } # }"},{"path":"https://niehs.github.io/amadeus/reference/download_gmted.html","id":null,"dir":"Reference","previous_headings":"","what":"Download elevation data — download_gmted","title":"Download elevation data — download_gmted","text":"download_gmted() function accesses downloads Global Multi-resolution Terrain Elevation Data (GMTED2010) U.S. Geological Survey National Geospatial-Intelligence Agency.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_gmted.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Download elevation data — download_gmted","text":"","code":"download_gmted(   statistic = c(\"Breakline Emphasis\", \"Systematic Subsample\", \"Median Statistic\",     \"Minimum Statistic\", \"Mean Statistic\", \"Maximum Statistic\",     \"Standard Deviation Statistic\"),   resolution = c(\"7.5 arc-seconds\", \"15 arc-seconds\", \"30 arc-seconds\"),   directory_to_save = NULL,   acknowledgement = FALSE,   download = FALSE,   remove_command = FALSE,   unzip = TRUE,   remove_zip = FALSE )"},{"path":"https://niehs.github.io/amadeus/reference/download_gmted.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Download elevation data — download_gmted","text":"statistic character(1). Available statistics include \"Breakline Emphasis\", \"Systematic Subsample\", \"Median Statistic\", \"Minimum Statistic\", \"Mean Statistic\", \"Maximum Statistic\", \"Standard Deviation Statistic\". resolution character(1). Available resolutions include \"7.5 arc-seconds\", \"15 arc-seconds\", \"30 arc-seconds\". directory_to_save character(1). Directory save data. Two sub-directories created downloaded zip files (\"/zip_files\") unzipped data files (\"/data_files\"). acknowledgement logical(1). setting TRUE user acknowledges data downloaded using function may large use lots machine storage memory. download logical(1). FALSE generate *.txt file containing download commands. setting TRUE function download requested data files. remove_command logical(1). Remove (TRUE) keep (FALSE) text file containing download commands. Default FALSE. unzip logical(1). Unzip zip files. Default TRUE. remove_zip logical(1). Remove zip file directory_to_download. Default FALSE.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_gmted.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Download elevation data — download_gmted","text":"NULL; Zip /data files downloaded stored directory_to_save.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_gmted.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Download elevation data — download_gmted","text":"Danielson JJ, Gesch DB (2011). “Global multi-resolution terrain elevation data 2010 (GMTED2010).” Open-File Report 2011-1073, U.S. Geological Survey. Series: Open-File Report, https://doi.org/10.3133/ofr20111073.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_gmted.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Download elevation data — download_gmted","text":"Mitchell Manware, Insang Song","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_gmted.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Download elevation data — download_gmted","text":"","code":"if (FALSE) { # \\dontrun{ download_gmted(   statistic = \"Breakline Emphasis\",   resolution = \"7.5 arc-seconds\",   directory_to_save = \"./data\",   acknowledgement = TRUE,   download = TRUE,   remove_command = TRUE ) } # }"},{"path":"https://niehs.github.io/amadeus/reference/download_gridmet.html","id":null,"dir":"Reference","previous_headings":"","what":"Download gridMET data — download_gridmet","title":"Download gridMET data — download_gridmet","text":"download_gridmet function accesses downloads gridded surface meteorological data University California Merced Climatology Lab's gridMET dataset.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_gridmet.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Download gridMET data — download_gridmet","text":"","code":"download_gridmet(   variables = NULL,   year = c(2018, 2022),   directory_to_save = NULL,   acknowledgement = FALSE,   download = FALSE,   remove_command = FALSE )"},{"path":"https://niehs.github.io/amadeus/reference/download_gridmet.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Download gridMET data — download_gridmet","text":"variables character(1). Variable(s) name(s). See gridMET Generate Wget File variable names acronym codes. (Note: variable \"Burning Index\" code \"bi\" variable \"Energy Release Component\" code \"erc\"). year character(2). length 4 . Start/end years downloading data. directory_to_save character(1). Directory(s) save downloaded data files. acknowledgement logical(1). setting TRUE user acknowledges data downloaded using function may large use lots machine storage memory. download logical(1). FALSE generate *.txt file containing download commands. setting TRUE function download requested data files. remove_command logical(1). Remove (TRUE) keep (FALSE) text file containing download commands.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_gridmet.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Download gridMET data — download_gridmet","text":"NULL; netCDF (.nc) files stored variable-specific folder within directory_to_save.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_gridmet.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Download gridMET data — download_gridmet","text":"Abatzoglou JT (2013). “Development gridded surface meteorological data ecological applications modelling.” International journal climatology, 33(1), 121–131.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_gridmet.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Download gridMET data — download_gridmet","text":"Mitchell Manware","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_gridmet.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Download gridMET data — download_gridmet","text":"","code":"if (FALSE) { # \\dontrun{ download_gridmet(   variables = \"Precipitation\",   year = c(2023, 2024),   directory_to_save = \"./data\",   acknowledgement = TRUE,   download = TRUE,   remove_command = TRUE ) } # }"},{"path":"https://niehs.github.io/amadeus/reference/download_hms.html","id":null,"dir":"Reference","previous_headings":"","what":"Download wildfire smoke data — download_hms","title":"Download wildfire smoke data — download_hms","text":"download_hms() function accesses downloads wildfire smoke plume coverage data NOAA's Hazard Mapping System Fire Smoke Product.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_hms.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Download wildfire smoke data — download_hms","text":"","code":"download_hms(   data_format = \"Shapefile\",   date = c(\"2018-01-01\", \"2018-01-01\"),   directory_to_save = NULL,   acknowledgement = FALSE,   download = FALSE,   remove_command = FALSE,   unzip = TRUE,   remove_zip = FALSE )"},{"path":"https://niehs.github.io/amadeus/reference/download_hms.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Download wildfire smoke data — download_hms","text":"data_format character(1). \"Shapefile\" \"KML\". date character(2). length 10 . Start/end date downloading data. directory_to_save character(1). Directory save data. data_format = \"Shapefile\", two sub-directories created downloaded zip files (\"/zip_files\") unzipped shapefiles (\"/data_files\"). data_format = \"KML\", single sub-directory (\"/data_files\") created. acknowledgement logical(1). setting TRUE user acknowledges data downloaded using function may large use lots machine storage memory. download logical(1). FALSE generate *.txt file containing download commands. setting TRUE function download requested data files. remove_command logical(1). Remove (TRUE) keep (FALSE) text file containing download commands. unzip logical(1). Unzip zip files. Default TRUE. (Ignored data_format = \"KML\".) remove_zip logical(1). Remove zip files directory_to_download. Default FALSE. (Ignored data_format = \"KML\".)","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_hms.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Download wildfire smoke data — download_hms","text":"NULL; Zip /data files downloaded stored respective sub-directories within directory_to_save.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_hms.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Download wildfire smoke data — download_hms","text":"(????). “Hazard Mapping System Fire Smoke Product: Hazard Mapping System.” https://www.ospo.noaa.gov/products/land/hms.html#. https://www.ospo.noaa.gov/products/land/hms.html#.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_hms.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Download wildfire smoke data — download_hms","text":"Mitchell Manware, Insang Song","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_hms.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Download wildfire smoke data — download_hms","text":"","code":"if (FALSE) { # \\dontrun{ download_hms(   data_format = \"Shapefile\",   date = c(\"2024-01-01\", \"2024-01-05\"),   directory_to_save = \"./data\",   acknowledgement = TRUE,   download = TRUE,   remove_command = TRUE ) } # }"},{"path":"https://niehs.github.io/amadeus/reference/download_huc.html","id":null,"dir":"Reference","previous_headings":"","what":"Download National Hydrography Dataset (NHD) data — download_huc","title":"Download National Hydrography Dataset (NHD) data — download_huc","text":"NHDPlus data provides comprehensive high-resolution hydrography data. function downloads national dataset NHDPlus Version 2.1 USGS Amazon S3 storage.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_huc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Download National Hydrography Dataset (NHD) data — download_huc","text":"","code":"download_huc(   region = c(\"Lower48\", \"Islands\"),   type = c(\"Seamless\", \"OceanCatchment\"),   directory_to_save = NULL,   acknowledgement = FALSE,   download = FALSE,   remove_command = FALSE,   unzip = FALSE )"},{"path":"https://niehs.github.io/amadeus/reference/download_huc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Download National Hydrography Dataset (NHD) data — download_huc","text":"region character(1). One c(\"Lower48\", \"Islands\"). \"Islands\" selected, data downloaded Hawaii, Puerto Rico, Virgin Islands. type character(1). One c(\"Seamless\", \"OceanCatchment\"). directory_to_save character(1). Directory download files. acknowledgement logical(1). setting TRUE user acknowledges data downloaded using function may large use lots machine storage memory. download logical(1). FALSE generate *.txt file containing download commands. setting TRUE function download requested data files. remove_command logical(1). Remove (TRUE) keep (FALSE) text file containing download commands. unzip logical(1). Unzip downloaded compressed files. Default FALSE. working function since HUC data 7z format.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_huc.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Download National Hydrography Dataset (NHD) data — download_huc","text":"NULL. Downloaded files stored directory_to_save.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_huc.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Download National Hydrography Dataset (NHD) data — download_huc","text":"HUC, set type = \"Seamless\". HUC12 layer presents seamless geodatabase. Users can aggregate HUC12 layer make HUC6, HUC8, HUC10, etc. wants download specific region, please visit Get NHDPlus Data","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_huc.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Download National Hydrography Dataset (NHD) data — download_huc","text":"U.S. Geological Survey (2023). “National Hydrography Dataset (NHD) – USGS National Map Downloadable Data Collection.” https://www.sciencebase.gov/catalog/item/4f5545cce4b018de15819ca9.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_huc.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Download National Hydrography Dataset (NHD) data — download_huc","text":"Insang Song","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_huc.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Download National Hydrography Dataset (NHD) data — download_huc","text":"","code":"if (FALSE) { # \\dontrun{ download_huc(   region = \"Lower48\",   type = \"Seamless\",   directory_to_save = \"./data\",   acknowledgement = TRUE,   download = TRUE,   remove_command = TRUE ) } # }"},{"path":"https://niehs.github.io/amadeus/reference/download_koppen_geiger.html","id":null,"dir":"Reference","previous_headings":"","what":"Download climate classification data — download_koppen_geiger","title":"Download climate classification data — download_koppen_geiger","text":"download_koppen_geiger() function accesses downloads climate classification data Present future Köppen-Geiger climate classification maps 1-km resolution(link article; link data).","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_koppen_geiger.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Download climate classification data — download_koppen_geiger","text":"","code":"download_koppen_geiger(   data_resolution = c(\"0.0083\", \"0.083\", \"0.5\"),   time_period = c(\"Present\", \"Future\"),   directory_to_save = NULL,   acknowledgement = FALSE,   download = FALSE,   remove_command = FALSE,   unzip = TRUE,   remove_zip = FALSE )"},{"path":"https://niehs.github.io/amadeus/reference/download_koppen_geiger.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Download climate classification data — download_koppen_geiger","text":"data_resolution character(1). Available resolutions \"0.0083\" degrees (approx. 1 km), \"0.083\" degrees (approx. 10 km), \"0.5\" degrees (approx. 50 km). time_period character(1). Available times \"Present\" (1980-2016) \"Future\" (2071-2100). (\"Future\" classifications based scenario RCP8.5). directory_to_save character(1). Directory save data. Two sub-directories created downloaded zip files (\"/zip_files\") unzipped shapefiles (\"/data_files\"). acknowledgement logical(1). setting TRUE user acknowledges data downloaded using function may large use lots machine storage memory. download logical(1). FALSE generate *.txt file containing download commands. setting TRUE function download requested data files. remove_command logical(1). Remove (TRUE) keep (FALSE) text file containing download commands. unzip logical(1). Unzip zip files. Default TRUE. remove_zip logical(1). Remove zip files directory_to_download. Default FALSE.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_koppen_geiger.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Download climate classification data — download_koppen_geiger","text":"NULL; Zip /data files downloaded stored respective sub-directories within directory_to_save.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_koppen_geiger.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Download climate classification data — download_koppen_geiger","text":"Beck , McVicar TR, Vergopolan N, Berg , Lutsko NJ, Dufour , Zeng Z, Jiang X, Van Dijk AIJM, Miralles DG (2023). “High-resolution (1 km) Köppen-Geiger maps 1901–2099 based constrained CMIP6 projections.” Scientific Data, 10(1), 724. ISSN 2052-4463, doi:10.1038/s41597-023-02549-6 , https://www.nature.com/articles/s41597-023-02549-6.  Beck , Zimmermann NE, McVicar TR, Vergopolan N, Berg , Wood EF (2018). “Present future Köppen-Geiger climate classification maps 1-km resolution.” Scientific data, 5(1), 1–12. doi:10.1038/sdata.2018.214 .","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_koppen_geiger.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Download climate classification data — download_koppen_geiger","text":"Mitchell Manware, Insang Song","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_koppen_geiger.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Download climate classification data — download_koppen_geiger","text":"","code":"if (FALSE) { # \\dontrun{ download_koppen_geiger(   data_resolution = \"0.0083\",   time_period = \"Present\",   directory_to_save = \"./data\",   acknowledgement = TRUE,   download = TRUE,   remove_command = TRUE ) } # }"},{"path":"https://niehs.github.io/amadeus/reference/download_merra2.html","id":null,"dir":"Reference","previous_headings":"","what":"Download meteorological and atmospheric data — download_merra2","title":"Download meteorological and atmospheric data — download_merra2","text":"download_merra2() function accesses downloads various meteorological atmospheric collections NASA's Modern-Era Retrospective analysis Research Applications, Version 2 (MERRA-2) model.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_merra2.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Download meteorological and atmospheric data — download_merra2","text":"","code":"download_merra2(   collection = c(\"inst1_2d_asm_Nx\", \"inst1_2d_int_Nx\", \"inst1_2d_lfo_Nx\",     \"inst3_3d_asm_Np\", \"inst3_3d_aer_Nv\", \"inst3_3d_asm_Nv\", \"inst3_3d_chm_Nv\",     \"inst3_3d_gas_Nv\", \"inst3_2d_gas_Nx\", \"inst6_3d_ana_Np\", \"inst6_3d_ana_Nv\",     \"statD_2d_slv_Nx\", \"tavg1_2d_adg_Nx\", \"tavg1_2d_aer_Nx\", \"tavg1_2d_chm_Nx\",     \"tavg1_2d_csp_Nx\", \"tavg1_2d_flx_Nx\", \"tavg1_2d_int_Nx\", \"tavg1_2d_lfo_Nx\",     \"tavg1_2d_lnd_Nx\", \"tavg1_2d_ocn_Nx\", \"tavg1_2d_rad_Nx\", \"tavg1_2d_slv_Nx\",     \"tavg3_3d_mst_Ne\", \"tavg3_3d_trb_Ne\", \"tavg3_3d_nav_Ne\", \"tavg3_3d_cld_Np\",           \"tavg3_3d_mst_Np\", \"tavg3_3d_rad_Np\", \"tavg3_3d_tdt_Np\", \"tavg3_3d_trb_Np\",     \"tavg3_3d_udt_Np\", \"tavg3_3d_odt_Np\", \"tavg3_3d_qdt_Np\", \"tavg3_3d_asm_Nv\",     \"tavg3_3d_cld_Nv\", \"tavg3_3d_mst_Nv\", \"tavg3_3d_rad_Nv\", \"tavg3_2d_glc_Nx\"),   date = c(\"2018-01-01\", \"2018-01-01\"),   directory_to_save = NULL,   acknowledgement = FALSE,   download = FALSE,   remove_command = FALSE )"},{"path":"https://niehs.github.io/amadeus/reference/download_merra2.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Download meteorological and atmospheric data — download_merra2","text":"collection character(1). MERRA-2 data collection file name. date character(2). length 10 . Start/end date downloading data. Format \"YYYY-MM-DD\" (ex. January 1, 2018 = \"2018-01-01\"). directory_to_save character(1). Directory save data. acknowledgement logical(1). setting TRUE user acknowledges data downloaded using function may large use lots machine storage memory. download logical(1). FALSE generate *.txt file containing download commands. setting TRUE function download requested data files. remove_command logical(1). Remove (TRUE) keep (FALSE) text file containing download commands.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_merra2.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Download meteorological and atmospheric data — download_merra2","text":"NULL; netCDF (.nc4) files stored collection-specific folder within directory_to_save.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_merra2.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Download meteorological and atmospheric data — download_merra2","text":"Global Modeling Assimilation Office, Pawson S (2015). “MERRA-2 inst1_2d_ asm_ Nx: 2d,3-Hourly,Instantaneous,Single-Level,Assimilation,Single-Level Diagnostics V5.12.4.” doi:10.5067/3Z173KIE2TPD , https://disc.gsfc.nasa.gov/datasets/M2I1NXASM_5.12.4/summary.  Global Modeling Assimilation Office, Pawson S (2015). “MERRA-2 inst1_2d_ int_ Nx: 2d,1-Hourly,Instantaneous,Single-Level,Assimilation,Vertically Integrated Diagnostics V5.12.4.” doi:10.5067/G0U6NGQ3BLE0 , https://disc.gsfc.nasa.gov/datasets/M2I1NXINT_5.12.4/summary.  Global Modeling Assimilation Office, Pawson S (2015). “MERRA-2 inst1_2d_ lfo_ Nx: 2d,1-Hourly,Instantaneous,Single-Level,Assimilation,Land Surface Forcings V5.12.4.” doi:10.5067/RCMZA6TL70BG , https://disc.gsfc.nasa.gov/datasets/M2I1NXLFO_5.12.4/summary.  Global Modeling Assimilation Office, Pawson S (2015). “MERRA-2 inst3_3d_ asm_ Np: 3d,3-Hourly,Instantaneous,Pressure-Level,Assimilation,Assimilated Meteorological Fields V5.12.4.” doi:10.5067/QBZ6MG944HW0 , https://disc.gsfc.nasa.gov/datasets/M2I3NPASM_5.12.4/summary.  Global Modeling Assimilation Office, Pawson S (2015). “MERRA-2 inst3_3d_ aer_ Nv: 3d,3-Hourly,Instantaneous,Model-Level,Assimilation,Aerosol Mixing Ratio V5.12.4.” doi:10.5067/LTVB4GPCOTK2 , https://disc.gsfc.nasa.gov/datasets/M2I3NVAER_5.12.4/summary.  Global Modeling Assimilation Office, Pawson S (2015). “MERRA-2 inst3_3d_ asm_ Nv: 3d,3-Hourly,Instantaneous,Model-Level,Assimilation,Assimilated Meteorological Fields V5.12.4.” doi:10.5067/WWQSXQ8IVFW8 , https://disc.gsfc.nasa.gov/datasets/M2I3NVASM_5.12.4/summary.  Global Modeling Assimilation Office, Pawson S (2015). “MERRA-2 inst3_3d_ chm_ Nv: 3d,3-Hourly,Instantaneous,Model-Level,Assimilation,Carbon Monoxide Ozone Mixing Ratio V5.12.4.” doi:10.5067/HO9OVZWF3KW2 , https://disc.gsfc.nasa.gov/datasets/M2I3NVCHM_5.12.4/summary.  Global Modeling Assimilation Office, Pawson S (2015). “MERRA-2 inst3_3d_ gas_ Nv: 3d,3-Hourly,Instantaneous,Model-Level,Assimilation,Aerosol Mixing Ratio Analysis Increments V5.12.4.” doi:10.5067/96BUID8HGGX5 , https://disc.gsfc.nasa.gov/datasets/M2I3NVGAS_5.12.4/summary.  Global Modeling Assimilation Office, Pawson S (2015). “MERRA-2 inst3_2d_ gas_ Nx: 2d,3-Hourly,Instantaneous,Single-Level,Assimilation,Aerosol Optical Depth Analysis V5.12.4.” doi:10.5067/HNGA0EWW0R09 , https://disc.gsfc.nasa.gov/datasets/M2I3NXGAS_5.12.4/summary.  Global Modeling Assimilation Office, Pawson S (2015). “MERRA-2 inst6_3d_ ana_ Np: 3d,6-Hourly,Instantaneous,Pressure-Level,Analysis,Analyzed Meteorological Fields V5.12.4.” doi:10.5067/A7S6XP56VZWS , https://disc.gsfc.nasa.gov/datasets/M2I6NPANA_5.12.4/summary.  Global Modeling Assimilation Office, Pawson S (2015). “MERRA-2 inst6_3d_ ana_ Nv: 3d,6-Hourly,Instantaneous,Model-Level,Analysis,Analyzed Meteorological Fields V5.12.4.” doi:10.5067/IUUF4WB9FT4W , https://disc.gsfc.nasa.gov/datasets/M2I6NVANA_5.12.4/summary.  Global Modeling Assimilation Office, Pawson S (2015). “MERRA-2 statD_2d_ slv_ Nx: 2d,Monthly,Aggregated Statistics,Single-Level,Assimilation,Single-Level Diagnostics V5.12.4.” doi:10.5067/KVIMOMCUO83U , https://disc.gsfc.nasa.gov/datasets/M2SMNXSLV_5.12.4/summary.  Global Modeling Assimilation Office, Pawson S (2015). “MERRA-2 statD_2d_ slv_ Nx: 2d,Daily,Aggregated Statistics,Single-Level,Assimilation,Single-Level Diagnostics V5.12.4.” doi:10.5067/9SC1VNTWGWV3 , https://disc.gsfc.nasa.gov/datasets/M2SDNXSLV_5.12.4/summary.  Global Modeling Assimilation Office, Pawson S (2015). “MERRA-2 tavg1_2d_ adg_ Nx: 2d,3-Hourly,Time-averaged,Single-Level,Assimilation,Aerosol Diagnostics (extended) V5.12.4.” doi:10.5067/HM00OHQBHKTP , https://disc.gsfc.nasa.gov/datasets/M2T1NXADG_5.12.4/summary.  Global Modeling Assimilation Office, Pawson S (2015). “MERRA-2 tavg1_2d_ aer_ Nx: 2d,1-Hourly,Time-averaged,Single-Level,Assimilation,Aerosol Diagnostics V5.12.4.” doi:10.5067/KLICLTZ8EM9D , https://disc.gsfc.nasa.gov/datasets/M2T1NXAER_5.12.4/summary.  Global Modeling Assimilation Office, Pawson S (2015). “MERRA-2 tavg1_2d_ chm_ Nx: 2d,3-Hourly,Time-Averaged,Single-Level,Assimilation,Carbon Monoxide Ozone Diagnostics V5.12.4.” doi:10.5067/3RQ5YS674DGQ , https://disc.gsfc.nasa.gov/datasets/M2T1NXCHM_5.12.4/summary.  Global Modeling Assimilation Office, Pawson S (2015). “MERRA-2 tavg1_2d_ csp_ Nx: 2d,1-Hourly,Time-averaged,Single-Level,Assimilation,COSP Satellite Simulator V5.12.4.” doi:10.5067/H0VVAD8F6MX5 , https://disc.gsfc.nasa.gov/datasets/M2T1NXCSP_5.12.4/summary.  Global Modeling Assimilation Office, Pawson S (2015). “MERRA-2 tavg1_2d_ flx_ Nx: 2d,1-Hourly,Time-Averaged,Single-Level,Assimilation,Surface Flux Diagnostics V5.12.4.” doi:10.5067/7MCPBJ41Y0K6 , https://disc.gsfc.nasa.gov/datasets/M2T1NXFLX_5.12.4/summary.  Global Modeling Assimilation Office, Pawson S (2015). “MERRA-2 tavg1_2d_ int_ Nx: 2d,1-Hourly,Time-averaged,Single-Level,Assimilation,Vertically Integrated Diagnostics V5.12.4.” doi:10.5067/Q5GVUVUIVGO7 , https://disc.gsfc.nasa.gov/datasets/M2T1NXINT_5.12.4/summary.  Pawson S (2020). “MERRA-2 tavg1_2d_ lfo_ Nx: 2d,1-Hourly,Time-Averaged,Single-Level,Assimilation,Land Surface Forcings V5.12.4.” doi:10.5067/L0T5GEG1NYFA , https://disc.gsfc.nasa.gov/datasets/M2T1NXLFO_5.12.4/summary.  Global Modeling Assimilation Office, Pawson S (2015). “MERRA-2 tavg1_2d_ lnd_ Nx: 2d,1-Hourly,Time-Averaged,Single-Level,Assimilation,Land Surface Diagnostics V5.12.4.” doi:10.5067/RKPHT8KC1Y1T , https://disc.gsfc.nasa.gov/datasets/M2T1NXLND_5.12.4/summary.  Global Modeling Assimilation Office, Pawson S (2015). “MERRA-2 tavg1_2d_ ocn_ Nx: 2d,1-Hourly,Time-Averaged,Single-Level,Assimilation,Ocean Surface Diagnostics V5.12.4.” doi:10.5067/Y67YQ1L3ZZ4R , https://disc.gsfc.nasa.gov/datasets/M2T1NXOCN_5.12.4/summary.  Global Modeling Assimilation Office, Pawson S (2015). “MERRA-2 tavg1_2d_ rad_ Nx: 2d,1-Hourly,Time-Averaged,Single-Level,Assimilation,Radiation Diagnostics V5.12.4.” doi:10.5067/Q9QMY5PBNV1T , https://disc.gsfc.nasa.gov/datasets/M2T1NXRAD_5.12.4/summary.  Global Modeling Assimilation Office, Pawson S (2015). “MERRA-2 tavg1_2d_ slv_ Nx: 2d,1-Hourly,Time-Averaged,Single-Level,Assimilation,Single-Level Diagnostics V5.12.4.” doi:10.5067/VJAFPLI1CSIV , https://disc.gsfc.nasa.gov/datasets/M2T1NXSLV_5.12.4/summary.  Global Modeling Assimilation Office, Pawson S (2015). “MERRA-2 tavg3_3d_ mst_ Ne: 3d,3-Hourly,Time-Averaged,Model-Level Edge,Assimilation,Moist Processes Diagnostics V5.12.4.” doi:10.5067/JRUZ3SJ3ZJ72 , https://disc.gsfc.nasa.gov/datasets/M2T3NEMST_5.12.4/summary.  Global Modeling Assimilation Office, Pawson S (2015). “MERRA-2 tavg3_3d_ trb_ Ne: 3d,3-Hourly,Time-Averaged,Model-Level Edge,Assimilation,Turbulence Diagnostics V5.12.4.” doi:10.5067/4I7ZI35QRH8K , https://disc.gsfc.nasa.gov/datasets/M2T3NETRB_5.12.4/summary.  Global Modeling Assimilation Office, Pawson S (2015). “MERRA-2 tavg3_3d_ nav_ Ne: 3d,3-Hourly,Time-Averaged, Vertical Coordinates V5.12.4.” doi:10.5067/N5WAKNS1UYQN , https://disc.gsfc.nasa.gov/datasets/M2T3NENAV_5.12.4/summary.  Global Modeling Assimilation Office, Pawson S (2015). “MERRA-2 tavg3_3d_ cld_ Np: 3d,3-Hourly,Time-Averaged,Pressure-Level,Assimilation,Cloud Diagnostics V5.12.4.” doi:10.5067/TX10URJSKT53 , https://disc.gsfc.nasa.gov/datasets/M2T3NPCLD_5.12.4/summary.  Global Modeling Assimilation Office, Pawson S (2015). “MERRA-2 tavg3_3d_ mst_ Np: 3d,3-Hourly,Time-Averaged,Pressure-Level,Assimilation,Moist Processes Diagnostics V5.12.4.” doi:10.5067/0TUFO90Q2PMS , https://disc.gsfc.nasa.gov/datasets/M2T3NPMST_5.12.4/summary.  Global Modeling Assimilation Office, Pawson S (2015). “MERRA-2 tavg3_3d_ rad_ Np: 3d,3-Hourly,Time-Averaged,Pressure-Level,Assimilation,Radiation Diagnostics V5.12.4.” doi:10.5067/3UGE8WQXZAOK , https://disc.gsfc.nasa.gov/datasets/M2T3NPRAD_5.12.4/summary.  Global Modeling Assimilation Office, Pawson S (2015). “MERRA-2 tavg3_3d_ tdt_ Np: 3d,3-Hourly,Time-Averaged,Pressure-Level,Assimilation,Temperature Tendencies V5.12.4.” doi:10.5067/9NCR9DDDOPFI , https://disc.gsfc.nasa.gov/datasets/M2T3NPTDT_5.12.4/summary.  Global Modeling Assimilation Office, Pawson S (2015). “MERRA-2 tavg3_3d_ trb_ Np: 3d,3-Hourly,Time-Averaged,Pressure-Level,Assimilation,Turbulence Diagnostics V5.12.4.” doi:10.5067/ZRRJPGWL8AVL , https://disc.gsfc.nasa.gov/datasets/M2T3NPTRB_5.12.4/summary.  Global Modeling Assimilation Office, Pawson S (2015). “MERRA-2 tavg3_3d_ udt_ Np: 3d,3-Hourly,Time-Averaged,Pressure-Level,Assimilation,Wind Tendencies V5.12.4.” doi:10.5067/CWV0G3PPPWFW , https://disc.gsfc.nasa.gov/datasets/M2T3NPUDT_5.12.4/summary.  Global Modeling Assimilation Office, Pawson S (2015). “MERRA-2 tavg3_3d_ odt_ Np: 3d,3-Hourly,Time-Averaged,Pressure-Level,Assimilation,Ozone Tendencies V5.12.4.” doi:10.5067/S0LYTK57786Z , https://disc.gsfc.nasa.gov/datasets/M2T3NPODT_5.12.4/summary.  Global Modeling Assimilation Office, Pawson S (2015). “MERRA-2 tavg3_3d_ qdt_ Np: 3d,3-Hourly,Time-Averaged,Pressure-Level,Assimilation,Moist Tendencies V5.12.4.” doi:10.5067/A9KWADY78YHQ , https://disc.gsfc.nasa.gov/datasets/M2T3NPQDT_5.12.4/summary.  Global Modeling Assimilation Office, Pawson S (2015). “MERRA-2 tavg3_3d_ asm_ Nv: 3d,3-Hourly,Time-Averaged,Model-Level,Assimilation,Assimilated Meteorological Fields V5.12.4.” doi:10.5067/SUOQESM06LPK , https://disc.gsfc.nasa.gov/datasets/M2T3NVASM_5.12.4/summary.  Global Modeling Assimilation Office, Pawson S (2015). “MERRA-2 tavg3_3d_ cld_ Nv: 3d,3-Hourly,Time-Averaged,Model-Level,Assimilation,Cloud Diagnostics V5.12.4.” doi:10.5067/F9353J0FAHIH , https://disc.gsfc.nasa.gov/datasets/M2T3NVCLD_5.12.4/summary.  Global Modeling Assimilation Office, Pawson S (2015). “MERRA-2 tavg3_3d_ mst_ Nv: 3d,3-Hourly,Time-Averaged,Model-Level,Assimilation,Moist Processes Diagnostics V5.12.4.” doi:10.5067/ZXTJ28TQR1TR , https://disc.gsfc.nasa.gov/datasets/M2T3NVMST_5.12.4/summary.  Global Modeling Assimilation Office, Pawson S (2015). “MERRA-2 tavg3_3d_ rad_ Nv: 3d,3-Hourly,Time-Averaged,Model-Level,Assimilation,Radiation Diagnostics V5.12.4.” doi:10.5067/7GFQKO1T43RW , https://disc.gsfc.nasa.gov/datasets/M2T3NVRAD_5.12.4/summary.  Global Modeling Assimilation Office, Pawson S (2015). “MERRA-2 tavg3_2d_ glc_ Nx: 2d,3-Hourly,Time-Averaged,Single-Level,Assimilation,Land Ice Surface Diagnostics V5.12.4.” doi:10.5067/9ETB4TT5J6US , https://disc.gsfc.nasa.gov/datasets/M2T3NXGLC_5.12.4/summary.  Global Modeling Assimilation Office, Pawson S (2015). “MERRA-2 instM_2d_ asm_ Nx: 2d,Monthly mean,Single-Level,Assimilation,Single-Level Diagnostics V5.12.4.” doi:10.5067/5ESKGQTZG7FO , https://disc.gsfc.nasa.gov/datasets/M2IMNXASM_5.12.4/summary.  Global Modeling Assimilation Office, Pawson S (2015). “MERRA-2 instM_2d_ int_ Nx: 2d,Monthly mean,Instantaneous,Single-Level,Assimilation,Vertically Integrated Diagnostics V5.12.4.” doi:10.5067/KVTU1A8BWFSJ , https://disc.gsfc.nasa.gov/datasets/M2IMNXINT_5.12.4/summary.  Global Modeling Assimilation Office, Pawson S (2015). “MERRA-2 instM_2d_ lfo_ Nx: 2d,Monthly mean,Instantaneous,Single-Level,Assimilation,Land Surface Forcings V5.12.4.” doi:10.5067/11F99Y6TXN99 , https://disc.gsfc.nasa.gov/datasets/M2IMNXLFO_5.12.4/summary.  Global Modeling Assimilation Office, Pawson S (2015). “MERRA-2 instM_2d_ gas_ Nx: 2d,Monthly mean,Instantaneous,Single-Level,Assimilation,Aerosol Optical Depth Analysis V5.12.4.” doi:10.5067/XOGNBQEPLUC5 , https://disc.gsfc.nasa.gov/datasets/M2IMNXGAS_5.12.4/summary.  Global Modeling Assimilation Office, Pawson S (2015). “MERRA-2 instM_3d_ asm_ Np: 3d,Monthly mean,Instantaneous,Pressure-Level,Assimilation,Assimilated Meteorological Fields V5.12.4.” doi:10.5067/2E096JV59PK7 , https://disc.gsfc.nasa.gov/datasets/M2IMNPASM_5.12.4/summary.  Global Modeling Assimilation Office, Pawson S (2015). “MERRA-2 instM_3d_ ana_ Np: 3d,Monthly mean,Instantaneous,Pressure-Level,Analysis,Analyzed Meteorological Fields V5.12.4.” doi:10.5067/V92O8XZ30XBI , https://disc.gsfc.nasa.gov/datasets/M2IMNPANA_5.12.4/summary.  Global Modeling Assimilation Office, Pawson S (2015). “MERRA-2 tavgM_2d_ adg_ Nx: 2d,Monthly mean,Time-averaged,Single-Level,Assimilation,Aerosol Diagnostics (extended) V5.12.4.” doi:10.5067/RZIK2TV7PP38 , https://disc.gsfc.nasa.gov/datasets/M2TMNXADG_5.12.4/summary.  Global Modeling Assimilation Office, Pawson S (2015). “MERRA-2 tavgM_2d_ aer_ Nx: 2d,Monthly mean,Time-averaged,Single-Level,Assimilation,Aerosol Diagnostics V5.12.4.” doi:10.5067/FH9A0MLJPC7N , https://disc.gsfc.nasa.gov/datasets/M2TMNXAER_5.12.4/summary.  Global Modeling Assimilation Office, Pawson S (2015). “MERRA-2 tavgM_2d_ chm_ Nx: 2d,Monthly mean,Time-Averaged,Single-Level,Assimilation,Carbon Monoxide Ozone Diagnostics V5.12.4.” doi:10.5067/WMT31RKEXK8I , https://disc.gsfc.nasa.gov/datasets/M2TMNXCHM_5.12.4/summary.  Global Modeling Assimilation Office, Pawson S (2015). “MERRA-2 tavgM_2d_ csp_ Nx: 2d,Monthly mean,Time-averaged,Single-Level,Assimilation,COSP Satellite Simulator V5.12.4.” doi:10.5067/BZPOTGJOQKLU , https://disc.gsfc.nasa.gov/datasets/M2TMNXCSP_5.12.4/summary.  Global Modeling Assimilation Office, Pawson S (2015). “MERRA-2 tavgM_2d_ flx_ Nx: 2d,Monthly mean,Time-Averaged,Single-Level,Assimilation,Surface Flux Diagnostics V5.12.4.” doi:10.5067/0JRLVL8YV2Y4 , https://disc.gsfc.nasa.gov/datasets/M2TMNXFLX_5.12.4/summary.  Global Modeling Assimilation Office, Pawson S (2015). “MERRA-2 tavgM_2d_ int_ Nx: 2d,Monthly mean,Time-Averaged,Single-Level,Assimilation,Vertically Integrated Diagnostics V5.12.4.” doi:10.5067/FQPTQ4OJ22TL , https://disc.gsfc.nasa.gov/datasets/M2TMNXINT_5.12.4/summary.  Global Modeling Assimilation Office, Pawson S (2015). “MERRA-2 tavgM_2d_ lfo_ Nx: 2d,Monthly mean,Time-Averaged,Single-Level,Assimilation,Land Surface Forcings V5.12.4.” doi:10.5067/5V7K6LJD44SY , https://disc.gsfc.nasa.gov/datasets/M2TMNXLFO_5.12.4/summary.  Global Modeling Assimilation Office, Pawson S (2015). “MERRA-2 tavgM_2d_ lnd_ Nx: 2d,Monthly mean,Time-Averaged,Single-Level,Assimilation,Land Surface Diagnostics V5.12.4.” doi:10.5067/8S35XF81C28F , https://disc.gsfc.nasa.gov/datasets/M2TMNXLND_5.12.4/summary.  Global Modeling Assimilation Office, Pawson S (2015). “MERRA-2 tavgM_2d_ ocn_ Nx: 2d,Monthly mean,Time-Averaged,Single-Level,Assimilation,Ocean Surface Diagnostics V5.12.4.” doi:10.5067/4IASLIDL8EEC , https://disc.gsfc.nasa.gov/datasets/M2TMNXOCN_5.12.4/summary.  Global Modeling Assimilation Office, Pawson S (2015). “MERRA-2 tavgM_2d_ rad_ Nx: 2d,Monthly mean,Time-Averaged,Single-Level,Assimilation,Radiation Diagnostics V5.12.4.” doi:10.5067/OU3HJDS973O0 , https://disc.gsfc.nasa.gov/datasets/M2TMNXRAD_5.12.4/summary.  Global Modeling Assimilation Office, Pawson S (2015). “MERRA-2 tavgM_2d_ slv_ Nx: 2d,Monthly mean,Time-Averaged,Single-Level,Assimilation,Single-Level Diagnostics V5.12.4.” doi:10.5067/AP1B0BA5PD2K , https://disc.gsfc.nasa.gov/datasets/M2TMNXSLV_5.12.4/summary.  Global Modeling Assimilation Office, Pawson S (2015). “MERRA-2 tavgM_2d_ glc_ Nx: 2d,Monthly mean,Time-Averaged,Single-Level,Assimilation,Land Ice Surface Diagnostics V5.12.4.” doi:10.5067/5W8Q3I9WUFGX , https://disc.gsfc.nasa.gov/datasets/M2TMNXGLC_5.12.4/summary.  Global Modeling Assimilation Office, Pawson S (2015). “MERRA-2 tavgM_3d_ cld_ Np: 3d,Monthly mean,Time-Averaged,Pressure-Level,Assimilation,Cloud Diagnostics V5.12.4.” doi:10.5067/J9R0LXGH48JR , https://disc.gsfc.nasa.gov/datasets/M2TMNPCLD_5.12.4/summary.  Global Modeling Assimilation Office, Pawson S (2015). “MERRA-2 tavgM_3d_ mst_ Np: 3d,Monthly mean,Time-Averaged,Pressure-Level,Assimilation,Moist Processes Diagnostics V5.12.4.” doi:10.5067/ZRZGD0DCK1CG , https://disc.gsfc.nasa.gov/datasets/M2TMNPMST_5.12.4/summary.  Global Modeling Assimilation Office, Pawson S (2015). “MERRA-2 tavgM_3d_ rad_ Np: 3d,Monthly mean,Time-Averaged,Pressure-Level,Assimilation,Radiation Diagnostics V5.12.4.” doi:10.5067/H3YGROBVBGFJ , https://disc.gsfc.nasa.gov/datasets/M2TMNPRAD_5.12.4/summary.  Global Modeling Assimilation Office, Pawson S (2015). “MERRA-2 tavgM_3d_ tdt_ Np: 3d,Monthly mean,Time-Averaged,Pressure-Level,Assimilation,Temperature Tendencies V5.12.4.” doi:10.5067/VILT59HI2MOY , https://disc.gsfc.nasa.gov/datasets/M2TMNPTDT_5.12.4/summary.  Global Modeling Assimilation Office, Pawson S (2015). “MERRA-2 tavgM_3d_ trb_ Np: 3d,Monthly mean,Time-Averaged,Pressure-Level,Assimilation,Turbulence Diagnostics V5.12.4.” doi:10.5067/2YOIQB5C3ACN , https://disc.gsfc.nasa.gov/datasets/M2TMNPTRB_5.12.4/summary.  Global Modeling Assimilation Office, Pawson S (2015). “MERRA-2 tavgM_3d_ udt_ Np: 3d,Monthly mean,Time-Averaged,Pressure-Level,Assimilation,Wind Tendencies V5.12.4.” doi:10.5067/YSR6IA5057XX , https://disc.gsfc.nasa.gov/datasets/M2TMNPUDT_5.12.4/summary.  Global Modeling Assimilation Office, Pawson S (2015). “MERRA-2 tavgM_3d_ odt_ Np: 3d,Monthly mean,Time-Averaged,Pressure-Level,Assimilation,Ozone Tendencies V5.12.4.” doi:10.5067/Z2KCWAV4GPD2 , https://disc.gsfc.nasa.gov/datasets/M2TMNPODT_5.12.4/summary.  Global Modeling Assimilation Office, Pawson S (2015). “MERRA-2 tavgM_3d_ qdt_ Np: 3d,Monthly mean,Time-Averaged,Pressure-Level,Assimilation,Moist Tendencies V5.12.4.” doi:10.5067/2ZTU87V69ATP , https://disc.gsfc.nasa.gov/datasets/M2TMNPQDT_5.12.4/summary.  Global Modeling Assimilation Office, Pawson S (2015). “MERRA-2 const_2d_ asm_ Nx: 2d, constants.” doi:10.5067/ME5QX6Q5IGGU , https://disc.gsfc.nasa.gov/datasets/M2C0NXASM_5.12.4/summary.  Global Modeling Assimilation Office, Pawson S (2015). “MERRA-2 instU_2d_ asm_ Nx: 2d,Diurnal,Instantaneous,Single-Level,Assimilation,Single-Level Diagnostics V5.12.4.” doi:10.5067/BOJSTZAO2L8R , https://disc.gsfc.nasa.gov/datasets/M2IUNXASM_5.12.4/summary.  Global Modeling Assimilation Office, Pawson S (2015). “MERRA-2 instU_2d_ int_ Nx: 2d,Diurnal,Instantaneous,Single-Level,Assimilation,Vertically Integrated Diagnostics V5.12.4.” doi:10.5067/DGAB3HFEYMLY , https://disc.gsfc.nasa.gov/datasets/M2IUNXINT_5.12.4/summary.  Global Modeling Assimilation Office, Pawson S (2015). “MERRA-2 instU_2d_ lfo_ Nx: 2d,Diurnal,Instantaneous,Single-Level,Assimilation,Land Surface Forcings V5.12.4.” doi:10.5067/FC3BVJ88Y8A2 , https://disc.gsfc.nasa.gov/datasets/M2IUNXLFO_5.12.4/summary.  Global Modeling Assimilation Office, Pawson S (2015). “MERRA-2 instU_2d_ gas_ Nx: 2d,Diurnal,Instantaneous,Single-Level,Assimilation,Aerosol Optical Depth Analysis V5.12.4.” doi:10.5067/TVJ4MHBED39L , https://disc.gsfc.nasa.gov/datasets/M2IUNXGAS_5.12.4/summary.  Global Modeling Assimilation Office, Pawson S (2015). “MERRA-2 instU_3d_ asm_ Np: 3d,Diurnal,Instantaneous,Pressure-Level,Assimilation,Assimilated Meteorological Fields V5.12.4.” doi:10.5067/6EGRBNEBMIYS , https://disc.gsfc.nasa.gov/datasets/M2IUNPASM_5.12.4/summary.  Global Modeling Assimilation Office, Pawson S (2015). “MERRA-2 instU_3d_ ana_ Np: 3d,Diurnal,Instantaneous,Pressure-Level,Analysis,Analyzed Meteorological Fields V5.12.4.” doi:10.5067/TRD91YO9S6E7 , https://disc.gsfc.nasa.gov/datasets/M2IUNPANA_5.12.4/summary.  Global Modeling Assimilation Office, Pawson S (2015). “MERRA-2 tavgU_2d_ adg_ Nx: 2d,Diurnal,Time-averaged,Single-Level,Assimilation,Aerosol Diagnostics (extended) V5.12.4.” doi:10.5067/YZJJXZTFCX6B , https://disc.gsfc.nasa.gov/datasets/M2TUNXADG_5.12.4/summary.  Global Modeling Assimilation Office, Pawson S (2015). “MERRA-2 tavgU_2d_ aer_ Nx: 2d,Diurnal,Time-averaged,Single-Level,Assimilation,Aerosol Diagnostics V5.12.4.” doi:10.5067/KPUMVXFEQLA1 , https://disc.gsfc.nasa.gov/datasets/M2TUNXAER_5.12.4/summary.  Global Modeling Assimilation Office, Pawson S (2015). “MERRA-2 tavgU_2d_ chm_ Nx: 2d,Diurnal,Time-Averaged,Single-Level,Assimilation,Carbon Monoxide Ozone Diagnostics V5.12.4.” doi:10.5067/5KFZ6GXRHZKN , https://disc.gsfc.nasa.gov/datasets/M2TUNXCHM_5.12.4/summary.  Global Modeling Assimilation Office, Pawson S (2015). “MERRA-2 tavgU_2d_ csp_ Nx: 2d,Diurnal,Time-averaged,Single-Level,Assimilation,COSP Satellite Simulator V5.12.4.” doi:10.5067/9PH5QU4CL9E8 , https://disc.gsfc.nasa.gov/datasets/M2TUNXCSP_5.12.4/summary.  Global Modeling Assimilation Office, Pawson S (2015). “MERRA-2 tavgU_2d_ flx_ Nx: 2d,Diurnal,Time-Averaged,Single-Level,Assimilation,Surface Flux Diagnostics V5.12.4.” doi:10.5067/LUHPNWAKYIO3 , https://disc.gsfc.nasa.gov/datasets/M2TUNXFLX_5.12.4/summary.  Global Modeling Assimilation Office, Pawson S (2015). “MERRA-2 tavgU_2d_ int_ Nx: 2d,Diurnal,Time-Averaged,Single-Level,Assimilation,Vertically Integrated Diagnostics V5.12.4.” doi:10.5067/R2MPVU4EOSWT , https://disc.gsfc.nasa.gov/datasets/M2TUNXINT_5.12.4/summary.  Global Modeling Assimilation Office, Pawson S (2015). “MERRA-2 tavgU_2d_ lfo_ Nx: 2d,Diurnal,Time-Averaged,Single-Level,Assimilation,Land Surface Forcings V5.12.4.” doi:10.5067/BTSNKAJND3ME , https://disc.gsfc.nasa.gov/datasets/M2TUNXLFO_5.12.4/summary.  Global Modeling Assimilation Office, Pawson S (2015). “MERRA-2 tavgU_2d_ lnd_ Nx: 2d,Diurnal,Time-Averaged,Single-Level,Assimilation,Land Surface Diagnostics V5.12.4.” doi:10.5067/W0J15047CF6N , https://disc.gsfc.nasa.gov/datasets/M2TUNXLND_5.12.4/summary.  Global Modeling Assimilation Office, Pawson S (2015). “MERRA-2 tavgU_2d_ ocn_ Nx: 2d,Diurnal,Time-Averaged,Single-Level,Assimilation,Ocean Surface Diagnostics V5.12.4.” doi:10.5067/KLNAVGAX7J66 , https://disc.gsfc.nasa.gov/datasets/M2TUNXOCN_5.12.4/summary.  Global Modeling Assimilation Office, Pawson S (2015). “MERRA-2 tavgU_2d_ rad_ Nx: 2d,Diurnal,Time-Averaged,Single-Level,Assimilation,Radiation Diagnostics V5.12.4.” doi:10.5067/4SDCJYK8P9QU , https://disc.gsfc.nasa.gov/datasets/M2TUNXRAD_5.12.4/summary.  Global Modeling Assimilation Office, Pawson S (2015). “MERRA-2 tavgU_2d_ slv_ Nx: 2d,Diurnal,Time-Averaged,Single-Level,Assimilation,Single-Level Diagnostics V5.12.4.” doi:10.5067/AFOK0TPEVQEK , https://disc.gsfc.nasa.gov/datasets/M2TUNXSLV_5.12.4/summary.  Global Modeling Assimilation Office, Pawson S (2015). “MERRA-2 tavgU_2d_ glc_ Nx: 2d,Diurnal,Time-Averaged,Single-Level,Assimilation,Land Ice Surface Diagnostics V5.12.4.” doi:10.5067/7VUPQC736SWX , https://disc.gsfc.nasa.gov/datasets/M2TUNXGLC_5.12.4/summary.  Global Modeling Assimilation Office, Pawson S (2015). “MERRA-2 tavgU_3d_ cld_ Np: 3d,Diurnal,Time-Averaged,Pressure-Level,Assimilation,Cloud Diagnostics V5.12.4.” doi:10.5067/EPW7T5UO0C0N , https://disc.gsfc.nasa.gov/datasets/M2TUNPCLD_5.12.4/summary.  Global Modeling Assimilation Office, Pawson S (2015). “MERRA-2 tavgU_3d_ mst_ Np: 3d,Diurnal,Time-Averaged,Pressure-Level,Assimilation,Moist Processes Diagnostics V5.12.4.” doi:10.5067/ZRSN0JU27DK2 , https://disc.gsfc.nasa.gov/datasets/M2TUNPMST_5.12.4/summary.  Global Modeling Assimilation Office, Pawson S (2015). “MERRA-2 tavgU_3d_ rad_ Np: 3d,Diurnal,Time-Averaged,Pressure-Level,Assimilation,Radiation Diagnostics V5.12.4.” doi:10.5067/H140JMDOWB0Y , https://disc.gsfc.nasa.gov/datasets/M2TUNPRAD_5.12.4/summary.  Global Modeling Assimilation Office, Pawson S (2015). “MERRA-2 tavgU_3d_ tdt_ Np: 3d,Diurnal,Time-Averaged,Pressure-Level,Assimilation,Temperature Tendencies V5.12.4.” doi:10.5067/QPO9E5TPZ8OF , https://disc.gsfc.nasa.gov/datasets/M2TUNPTDT_5.12.4/summary.  Global Modeling Assimilation Office, Pawson S (2015). “MERRA-2 tavgU_3d_ trb_ Np: 3d,Diurnal,Time-Averaged,Pressure-Level,Assimilation,Turbulence Diagnostics V5.12.4.” doi:10.5067/2A99C60CG7WC , https://disc.gsfc.nasa.gov/datasets/M2TUNPTRB_5.12.4/summary.  Global Modeling Assimilation Office, Pawson S (2015). “MERRA-2 tavgU_3d_ udt_ Np: 3d,Diurnal,Time-Averaged,Pressure-Level,Assimilation,Wind Tendencies V5.12.4.” doi:10.5067/DO715T7T5PG8 , https://disc.gsfc.nasa.gov/datasets/M2TUNPUDT_5.12.4/summary.  Global Modeling Assimilation Office, Pawson S (2015). “MERRA-2 tavgU_3d_ odt_ Np: 3d,Diurnal,Time-Averaged,Pressure-Level,Assimilation,Ozone Tendencies V5.12.4.” doi:10.5067/M8OJ09GZP23E , https://disc.gsfc.nasa.gov/datasets/M2TUNPODT_5.12.4/summary.  Global Modeling Assimilation Office, Pawson S (2015). “MERRA-2 tavgU_3d_ qdt_ Np: 3d,Diurnal,Time-Averaged,Pressure-Level,Assimilation,Moist Tendencies V5.12.4.” doi:10.5067/S8HJXIR0BFTS , https://disc.gsfc.nasa.gov/datasets/M2TUNPQDT_5.12.4/summary.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_merra2.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Download meteorological and atmospheric data — download_merra2","text":"Mitchell Manware, Insang Song","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_merra2.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Download meteorological and atmospheric data — download_merra2","text":"","code":"if (FALSE) { # \\dontrun{ download_merra2(   collection = \"inst1_2d_int_Nx\",   date = c(\"2024-01-01\", \"2024-01-05\"),   directory_to_save = \"./data\",   acknowledgement = TRUE,   download = TRUE,   remove_command = TRUE ) } # }"},{"path":"https://niehs.github.io/amadeus/reference/download_modis.html","id":null,"dir":"Reference","previous_headings":"","what":"Download MODIS product files — download_modis","title":"Download MODIS product files — download_modis","text":"Need maintenance directory path change NASA EOSDIS. function first retrieves hdf download links certain day, selects relevant tiles retrieved links. Download done queried horizontal-vertical tile number combinations. exception MOD06_L2 product, produced every five minutes every day.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_modis.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Download MODIS product files — download_modis","text":"","code":"download_modis(   product = c(\"MOD09GA\", \"MOD11A1\", \"MOD06_L2\", \"MCD19A2\", \"MOD13A2\", \"VNP46A2\"),   version = \"61\",   horizontal_tiles = c(7, 13),   vertical_tiles = c(3, 6),   mod06_links = NULL,   nasa_earth_data_token = NULL,   date = c(\"2023-09-01\", \"2023-09-01\"),   directory_to_save = NULL,   acknowledgement = FALSE,   download = FALSE,   remove_command = FALSE )"},{"path":"https://niehs.github.io/amadeus/reference/download_modis.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Download MODIS product files — download_modis","text":"product character(1). One c(\"MOD09GA\", \"MOD11A1\", \"MOD06_L2\", \"MCD19A2\", \"MOD13A2\", \"VNP46A2\") version character(1). Default \"61\", meaning v061. horizontal_tiles integer(2). Horizontal tile numbers c({start}, {end}). Default c(7, 13). vertical_tiles integer(2). Vertical tile numbers c({start}, {end}). Default c(3, 6). mod06_links character(1). CSV file path MOD06_L2 download links NASA LPDAAC. Default NULL. nasa_earth_data_token character(1). Token downloading data NASA. set trying running function. date character(2). length 10 . Start/end date downloading data. Format \"YYYY-MM-DD\" (ex. January 1, 2018 = \"2018-01-01\"). Note: ignored product == \"MOD06_L2\". directory_to_save character(1). Directory save data. acknowledgement logical(1). setting TRUE user acknowledges data downloaded using function may large use lots machine storage memory. download logical(1). Download data save wget commands. remove_command logical(1). Remove (TRUE) keep (FALSE) text file containing download commands.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_modis.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Download MODIS product files — download_modis","text":"NULL; HDF (.hdf) files stored directory_to_save.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_modis.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Download MODIS product files — download_modis","text":"dates date year. Directory structure looks like input/modis/raw/{version}/{product}/{year}/{day_of_year}.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_modis.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Download MODIS product files — download_modis","text":"Lyapustin , Wang Y (2022). “MODIS/Terra+Aqua Land Aerosol Optical Depth Daily L2G Global 1km SIN Grid V061.” doi:10.5067/MODIS/MCD19A2.061 , https://lpdaac.usgs.gov/products/mcd19a2v061/.  MODIS Atmosphere Science Team (2017). “MODIS/Terra Clouds 5-Min L2 Swath 1km 5km.” doi:10.5067/MODIS/MOD06_L2.061 , https://ladsweb.modaps.eosdis.nasa.gov/missions--measurements/products/MOD06_L2.  Vermote E, Wolfe R (2021). “MODIS/Terra Surface Reflectance Daily L2G Global 1km 500m SIN Grid V061.” doi:10.5067/MODIS/MOD09GA.061 , https://lpdaac.usgs.gov/products/mod09gav061/.  Wan Z, Hook S, Hulley G (2021). “MODIS/Terra Land Surface Temperature/Emissivity Daily L3 Global 1km SIN Grid V061.” doi:10.5067/MODIS/MOD11A1.061 , https://lpdaac.usgs.gov/products/mod11a1v061/.  Didan K (2021). “MODIS/Terra Vegetation Indices 16-Day L3 Global 1km SIN Grid V061.” doi:10.5067/MODIS/MOD13A2.061 , https://lpdaac.usgs.gov/products/mod13a2v061/.  Román MO, Wang Z, Sun Q, Kalb V, Miller SD, Molthan , Schultz L, Bell J, Stokes EC, Pandey B, Seto KC, Hall D, Oda T, Wolfe RE, Lin G, Golpayegani N, Devadiga S, Davidson C, Sarkar S, Praderas C, Schmaltz J, Boller R, Stevens J, Ramos González OM, Padilla E, Alonso J, Detrés Y, Armstrong R, Miranda , Conte Y, Marrero N, MacManus K, Esch T, Masuoka EJ (2018). “NASA's Black Marble nighttime lights product suite.” Remote Sensing Environment, 210, 113–143. ISSN 00344257, doi:10.1016/j.rse.2018.03.017 , https://linkinghub.elsevier.com/retrieve/pii/S003442571830110X.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_modis.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Download MODIS product files — download_modis","text":"Mitchell Manware, Insang Song","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_modis.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Download MODIS product files — download_modis","text":"","code":"if (FALSE) { # \\dontrun{ # example with MOD0GA product download_modis(   product = \"MOD09GA\",   version = \"61\",   horizontal_tiles = c(8, 10),   vertical_tiles = c(4, 5),   date = c(\"2024-01-01\", \"2024-01-10\"),   nasa_earth_data_token = readLines(\"~/pre_generated_token.txt\"),   directory_to_save = \"./data/mod09ga\",   acknowledgement = TRUE,   download = TRUE,   remove_command = TRUE ) # example with MOD06_L2 product download_modis(   product = \"MOD06_L2\",   version = \"61\",   horizontal_tiles = c(8, 10),   vertical_tiles = c(4, 5),   mod06_links = \"~/LAADS_query.2024-07-15T12_17.csv\",   date = c(\"2024-01-01\", \"2024-01-10\"),   nasa_earth_data_token = readLines(\"~/pre_generated_token.txt\"),   directory_to_save = \"./data/mod06l2\",   acknowledgement = TRUE,   download = TRUE,   remove_command = TRUE ) # example with VNP46A2 product download_modis(   product = \"VNP46A2\",   version = \"61\",   horizontal_tiles = c(8, 10),   vertical_tiles = c(4, 5),   date = c(\"2024-01-01\", \"2024-01-10\"),   nasa_earth_data_token = readLines(\"~/pre_generated_token.txt\"),   directory_to_save = \"./data/vnp46a2\",   acknowledgement = TRUE,   download = TRUE,   remove_command = TRUE ) } # }"},{"path":"https://niehs.github.io/amadeus/reference/download_narr.html","id":null,"dir":"Reference","previous_headings":"","what":"Download meteorological data — download_narr","title":"Download meteorological data — download_narr","text":"download_narr function accesses downloads daily meteorological data NOAA's North American Regional Reanalysis (NARR) model.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_narr.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Download meteorological data — download_narr","text":"","code":"download_narr(   variables = NULL,   year = c(2018, 2022),   directory_to_save = NULL,   acknowledgement = FALSE,   download = FALSE,   remove_command = FALSE )"},{"path":"https://niehs.github.io/amadeus/reference/download_narr.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Download meteorological data — download_narr","text":"variables character. Variable(s) name acronym. See List Variables NARR Files variable names acronym codes. year character(2). length 4 . Start/end years downloading data. directory_to_save character(1). Directory(s) save downloaded data files. acknowledgement logical(1). setting TRUE user acknowledges data downloaded using function may large use lots machine storage memory. download logical(1). FALSE generate *.txt file containing download commands. setting TRUE function download requested data files. remove_command logical(1). Remove (TRUE) keep (FALSE) text file containing download commands.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_narr.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Download meteorological data — download_narr","text":"NULL; netCDF (.nc) files stored directory_to_save.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_narr.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Download meteorological data — download_narr","text":"\"Pressure levels\" variables contain variable values 29 atmospheric levels, ranging 1000 hPa 100 hPa. pressure levels data downloaded variable.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_narr.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Download meteorological data — download_narr","text":"Mesinger F, DiMego G, Kalnay E, Mitchell K, Shafran PC, Ebisuzaki W, Jović D, Woollen J, Rogers E, Berbery EH, Ek MB, Fan Y, Grumbine R, Higgins W, Li H, Lin Y, Manikin G, Parrish D, Shi W (2006). “North American Regional Reanalysis.” Bulletin American Meteorological Society, 87(3), 343–360. ISSN 0003-0007, 1520-0477, doi:10.1175/BAMS-87-3-343 , 2024-06-24.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_narr.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Download meteorological data — download_narr","text":"Mitchell Manware, Insang Song","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_narr.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Download meteorological data — download_narr","text":"","code":"if (FALSE) { # \\dontrun{ download_narr(   variables = c(\"weasd\", \"omega\"),   year = c(2022, 2023),   directory_to_save = \"./data\",   acknowledgement = TRUE,   download = TRUE,   remove_command = TRUE ) } # }"},{"path":"https://niehs.github.io/amadeus/reference/download_nei.html","id":null,"dir":"Reference","previous_headings":"","what":"Download road emissions data — download_nei","title":"Download road emissions data — download_nei","text":"download_nei() function accesses downloads road emissions data U.S Environmental Protection Agency's (EPA) National Emissions Inventory (NEI).","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_nei.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Download road emissions data — download_nei","text":"","code":"download_nei(   epa_certificate_path = system.file(\"extdata/cacert_gaftp_epa.pem\", package = \"amadeus\"),   certificate_url =     \"http://cacerts.digicert.com/DigiCertGlobalG2TLSRSASHA2562020CA1-1.crt\",   year = c(2017L, 2020L),   directory_to_save = NULL,   acknowledgement = FALSE,   download = FALSE,   remove_command = FALSE,   unzip = TRUE )"},{"path":"https://niehs.github.io/amadeus/reference/download_nei.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Download road emissions data — download_nei","text":"epa_certificate_path character(1). Path certificate file EPA DataCommons. Default 'extdata/cacert_gaftp_epa.pem' package installation path. certificate_url character(1). URL certificate file. See notes details. year Available years NEI data. Default c(2017L, 2020L). directory_to_save character(1). Directory save data. Two sub-directories created downloaded zip files (\"/zip_files\") unzipped data files (\"/data_files\"). acknowledgement logical(1). setting TRUE user acknowledges data downloaded using function may large use lots machine storage memory. download logical(1). FALSE generate *.txt file containing download commands. setting TRUE function download requested data files. remove_command logical(1). Remove (TRUE) keep (FALSE) text file containing download commands. unzip logical(1). Unzip downloaded zip files. Default FALSE.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_nei.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Download road emissions data — download_nei","text":"NULL; Zip /data files downloaded stored respective sub-directories within directory_to_save.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_nei.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Download road emissions data — download_nei","text":"EPA Data Commons certificate errors, follow steps : Click Lock icon address bar https://gaftp.epa.gov Click Show Certificate Access Details Find URL *.crt extension Currently bundle pre-downloaded crt PEM (accepted wget command) file ./inst/extdata. instruction certificate updates future.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_nei.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Download road emissions data — download_nei","text":"United States Environmental Protection Agency (2024). “Air Emissions Inventories.” https://www.epa.gov/air-emissions-inventories.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_nei.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Download road emissions data — download_nei","text":"Ranadeep Daw, Insang Song","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_nei.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Download road emissions data — download_nei","text":"","code":"if (FALSE) { # \\dontrun{ download_nei(   year = c(2017L, 2020L),   directory_to_save = \"./data\",   acknowledgement = TRUE,   download = TRUE,   remove_command = TRUE ) } # }"},{"path":"https://niehs.github.io/amadeus/reference/download_nlcd.html","id":null,"dir":"Reference","previous_headings":"","what":"Download land cover data — download_nlcd","title":"Download land cover data — download_nlcd","text":"download_nlcd() function accesses downloads land cover data Multi-Resolution Land Characteristics (MRLC) Consortium's National Land Cover Database (NLCD) products data base.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_nlcd.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Download land cover data — download_nlcd","text":"","code":"download_nlcd(   collection = \"Coterminous United States\",   year = 2021,   directory_to_save = NULL,   acknowledgement = FALSE,   download = FALSE,   remove_command = FALSE,   unzip = TRUE,   remove_zip = FALSE )"},{"path":"https://niehs.github.io/amadeus/reference/download_nlcd.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Download land cover data — download_nlcd","text":"collection character(1). \"Coterminous United States\" \"Alaska\". year integer(1). Available years Coterminous United States include 2001, 2004, 2006, 2008, 2011, 2013, 2016, 2019, 2021. Available years Alaska include 2001, 2011, 2016. directory_to_save character(1). Directory save data. Two sub-directories created downloaded zip files (\"/zip_files\") unzipped shapefiles (\"/data_files\"). acknowledgement logical(1). setting TRUE user acknowledges data downloaded using function may large use lots machine storage memory. download logical(1). FALSE generate *.txt file containing download commands. setting TRUE function download requested data files. remove_command logical(1). Remove (TRUE) keep (FALSE) text file containing download commands. unzip logical(1). Unzip zip files. Default TRUE. remove_zip logical(1). Remove zip files directory_to_download. Default FALSE.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_nlcd.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Download land cover data — download_nlcd","text":"NULL; Zip /data files downloaded stored respective sub-directories within directory_to_save.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_nlcd.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Download land cover data — download_nlcd","text":"Dewitz J (2023). “National Land Cover Database (NLCD) 2021 Products.” doi:10.5066/P9JZ7AO3 , https://www.sciencebase.gov/catalog/item/647626cbd34e4e58932d9d4e.  Dewitz J (2024). “National Land Cover Database (NLCD) 2019 Products (ver. 3.0, February 2024).” doi:10.5066/P9KZCM54 , https://www.sciencebase.gov/catalog/item/5f21cef582cef313ed940043.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_nlcd.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Download land cover data — download_nlcd","text":"Mitchell Manware, Insang Song","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_nlcd.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Download land cover data — download_nlcd","text":"","code":"if (FALSE) { # \\dontrun{ download_nlcd(   collection = \"Coterminous United States\",   year = 2021,   directory_to_save = \"./data\",   acknowledgement = TRUE,   download = TRUE,   remove_command = TRUE ) } # }"},{"path":"https://niehs.github.io/amadeus/reference/download_olm.html","id":null,"dir":"Reference","previous_headings":"","what":"Download OpenLandMap data — download_olm","title":"Download OpenLandMap data — download_olm","text":"Accesses downloads OpenLandMap data OpenLandMap website.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_olm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Download OpenLandMap data — download_olm","text":"","code":"download_olm(   product = NULL,   format = \"tif\",   directory_to_save = NULL,   acknowledgement = FALSE,   download = FALSE,   remove_command = FALSE )"},{"path":"https://niehs.github.io/amadeus/reference/download_olm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Download OpenLandMap data — download_olm","text":"product character(1). Available collection name OpenLandMap STAC Catalog. list_stac_files id_only = TRUE see available collections. \"no2_s5p.l3.trop.tmwm\" \"no2_s5p.l3.trop.tmwm.ltm\" \"log.oc_iso.10694\" \"evi_mod13q1.stl.trend.logit.ols.beta\" \"land.cover_esacci.lc.l4\" \"evi_mod13q1.tmwm.inpaint\" \"dtm.bareearth_ensemble\" \"fapar_essd.lstm\" \"fapar_essd.lstm.p95.beta\" \"pot.fapar_fapar.p95.eml.m\" \"pot.fapar_fapar.p95.eml\" \"snow.cover_esa.modis\" \"snow.cover_esa.modis.ltm\" \"wilderness_li2022.human.footprint\" \"wv_mcd19a2v061.seasconv\" \"wv_mcd19a2v061.seasconv.m_p50\" \"wv_mcd19a2v061.seasconv.m_p25\" \"wv_mcd19a2v061.seasconv.m_p75\" \"wv_mcd19a2v061.seasconv.m_std\" \"wv_mcd19a2v061.seasconv.m.yearly\" \"bulkdens.fineearth_usda.4a1h\" \"geom_merit.dem\" \"fapar_proba.v\" \"forest.cover_esacci.ifl\" \"grtgroup_usda.soiltax\" \"land.cover_copernicus\" \"organic.carbon.stock_msa.kgm2\" \"organic.carbon_usda.6a1c\" \"pft.landcover_esa.cci.lc\" \"precipitation_sm2rain.ltm\" \"ph.h2o_usda.4c1a2a\" \"pop.count_ghs.jrc\" \"sand.wfraction_usda.3a1a1a\" \"lc_mcd12q1v061.p1\" \"texture.class_usda.tt\" \"water.occurrence_jrc.surfacewater\" \"watercontent.33kPa_usda.4b1c\" \"dsm_glo30\" \"lc_glad.glcluc\" \"lc_glad.glcluc.change\" \"landuse.cropland_hyde\" \"landuse.pasture_hyde\" \"land.use.land.cover_hilda.plus\" \"lst_mod11a2.daytime.trend.logit.ols.beta\" \"lst_mod11a2.nighttime.trend.logit.ols.beta\" \"lst_mod11a2.daytime.annual\" \"lst_mod11a2.nighttime.annual\" \"lst_mod11a2.daytime\" \"lst_mod11a2.nighttime\" \"landform_usgs.ecotapestry\" \"lithology_usgs.ecotapestry\" \"grtgroup_usda.soiltax.hapludalfs\" \"biome.type_biome00k\" \"biomes_biome6k.tropical.evergreen.broadleaf.forest\" \"biomes_biome6k.tropical.evergreen.broadleaf.forest.rcp26\" \"biomes_biome6k.tropical.evergreen.broadleaf.forest.rcp45\" \"biomes_biome6k.tropical.evergreen.broadleaf.forest.rcp85\" \"biomes_biome6k.tropical.savanna\" \"biomes_biome6k.tropical.savanna.rcp26\" \"biomes_biome6k.tropical.savanna.rcp45\" \"biomes_biome6k.tropical.savanna.rcp85\" \"lc_glc.fcs30d\" \"nightlights.average_viirs.v21\" \"nightlights.difference_viirs.v21\" \"l2a.gedi\" \"fluxnet\" \"gbov\" \"geowiki.lc\" \"geowiki.forest.loss\" \"veg.plot\" \"obis\" \"fapar.eml\" format character(1). File format query. Default \"tif\". used pattern search file names. directory_to_save character(1). Directory download files. acknowledgement logical(1). setting TRUE user acknowledges data downloaded using function may large use lots machine storage memory. download logical(1). FALSE generate *.txt file containing download commands. setting TRUE function download requested data files. remove_command logical(1). Remove (TRUE) keep (FALSE) text file containing download commands.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_olm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Download OpenLandMap data — download_olm","text":"NULL; GeoTIFF (.tif) files stored directory_to_save.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_olm.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Download OpenLandMap data — download_olm","text":"extdata/openlandmap_assets.rds contains available assets OpenLandMap. Users may want check available assets download data directly. developers: JSON files found STAC catalog OpenLandMap updated.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_olm.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Download OpenLandMap data — download_olm","text":"Hengl T, Parente L, Ho Y, Simoes R, contributors (2023). OpenLandMap Open Land Data services. OpenGeoHub foundation, Wageningen. doi:10.5281/zenodo.10522799 , https://openlandmap.github.io/book/.","code":""},{"path":[]},{"path":"https://niehs.github.io/amadeus/reference/download_olm.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Download OpenLandMap data — download_olm","text":"Insang Song","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_olm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Download OpenLandMap data — download_olm","text":"","code":"if (FALSE) { # \\dontrun{ download_olm(   product = \"no2_s5p.l3.trop.tmwm\",   format = \"tif\",   directory_to_save = \"./data\",   acknowledgement = TRUE,   download = TRUE,   remove_command = TRUE ) } # }"},{"path":"https://niehs.github.io/amadeus/reference/download_permit.html","id":null,"dir":"Reference","previous_headings":"","what":"Check data download acknowledgement — download_permit","title":"Check data download acknowledgement — download_permit","text":"Return error acknowledgement = FALSE.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_permit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check data download acknowledgement — download_permit","text":"","code":"download_permit(acknowledgement)"},{"path":"https://niehs.github.io/amadeus/reference/download_permit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check data download acknowledgement — download_permit","text":"acknowledgement logical(1). Whether start downloading","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_permit.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Check data download acknowledgement — download_permit","text":"acknowledgement parameter designed help users avoid accidentally initiating large data download may take long time run exceed machine capabilities.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_prism.html","id":null,"dir":"Reference","previous_headings":"","what":"Download PRISM data — download_prism","title":"Download PRISM data — download_prism","text":"Accesses downloads Oregon State University's PRISM data PRISM Climate Group Web Service","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_prism.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Download PRISM data — download_prism","text":"","code":"download_prism(   time,   element = c(\"ppt\", \"tmin\", \"tmax\", \"tmean\", \"tdmean\", \"vpdmin\", \"vpdmax\", \"solslope\",     \"soltotal\", \"solclear\", \"soltrans\"),   data_type = c(\"ts\", \"normals_800\", \"normals\"),   format = c(\"nc\", \"asc\", \"grib2\"),   directory_to_save = NULL,   acknowledgement = FALSE,   download = FALSE,   remove_command = FALSE )"},{"path":"https://niehs.github.io/amadeus/reference/download_prism.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Download PRISM data — download_prism","text":"time character(1). Length 2, 4, 6, 8. Time period time series normals. According PRISM Web Service Guide, acceptable formats include (disclaimer: following direct quote; minimal formatting applied): Time Series: YYYYMMDD daily data (yesterday January 1st, 1981) – returns single grid .zip file YYYYMM monthly data (last month January 1981) – returns single grid .zip file YYYY annual data (last year 1981) - returns single grid .zip file YYYY historical data (1980 1895) - returns single zip file containing 12 monthly grids YYYY plus annual. Normals: Monthly normal: date MM (.e., 04 April) value 14, returns annual normal Daily normal: date MMDD (.e., 0430 April 30) element character(1). Data element. One c(\"ppt\", \"tmin\", \"tmax\", \"tmean\", \"tdmean\", \"vpdmin\", \"vpdmax\") normals, c(\"solslope\", \"soltotal\", \"solclear\", \"soltrans\") also accepted. data_type character(1). Data type. \"ts\": 4km resolution time series. \"normals_800\": 800m resolution normals. \"normals\": 4km resolution normals. format character(1). Data format. applicable data_type = \"ts\". directory_to_save character(1). Directory download files. acknowledgement logical(1). setting TRUE user acknowledges data downloaded using function may large use lots machine storage memory. download logical(1). FALSE generate *.txt file containing download commands. setting TRUE function download requested data files. remove_command logical(1). Remove (TRUE) keep (FALSE) text file containing download commands.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_prism.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Download PRISM data — download_prism","text":"NULL; .bil (normals) single grid files depending format choice stored directory_to_save.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_prism.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Download PRISM data — download_prism","text":"Daly C, Taylor GH, Gibson WP, Parzybok TW, Johnson GL, Pasteris PA (2000). “HIGH-QUALITY SPATIAL CLIMATE DATA SETS UNITED STATES BEYOND.” Transactions ASAE, 43(6), 1957–1962. ISSN 2151-0059, doi:10.13031/2013.3101 , http://elibrary.asabe.org/abstract.asp??JID=3&AID=3101&CID=t2000&v=43&=6&T=1. PRISM Climate Group PRISM Web Service Guide","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_prism.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Download PRISM data — download_prism","text":"Insang Song","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_prism.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Download PRISM data — download_prism","text":"","code":"if (FALSE) { # \\dontrun{ download_prism(   time = \"202104\",   element = \"ppt\",   data_type = \"ts\",   format = \"nc\",   directory_to_save = \"./data\",   acknowledgement = TRUE,   download = TRUE,   remove_command = TRUE ) } # }"},{"path":"https://niehs.github.io/amadeus/reference/download_remove_command.html","id":null,"dir":"Reference","previous_headings":"","what":"Remove download commands — download_remove_command","title":"Remove download commands — download_remove_command","text":"Remove retain .txt file storing download commands.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_remove_command.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Remove download commands — download_remove_command","text":"","code":"download_remove_command(commands_txt = NULL, remove = FALSE)"},{"path":"https://niehs.github.io/amadeus/reference/download_remove_command.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Remove download commands — download_remove_command","text":"commands_txt character(1). Path download commands remove logical(1). Remove (TRUE) keep (FALSE) commands","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_remove_zips.html","id":null,"dir":"Reference","previous_headings":"","what":"Remove zip files — download_remove_zips","title":"Remove zip files — download_remove_zips","text":"Remove downloaded \".zip\" files.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_remove_zips.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Remove zip files — download_remove_zips","text":"","code":"download_remove_zips(remove = FALSE, download_name)"},{"path":"https://niehs.github.io/amadeus/reference/download_remove_zips.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Remove zip files — download_remove_zips","text":"remove logical(1). Confirm removal. Default FALSE. download_name character. Full zip file path","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_remove_zips.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Remove zip files — download_remove_zips","text":"!!! USE FUNCTION CAUTION !!! remove = TRUE, ensure unzip = TRUE. Choosing remove \".zip\" files without unzipping retain none downloaded data. remove files second higher level directory.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_run.html","id":null,"dir":"Reference","previous_headings":"","what":"Run download commands — download_run","title":"Run download commands — download_run","text":"Execute skip commands listed ...wget/curl_commands.txt file produced one data download functions.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_run.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Run download commands — download_run","text":"","code":"download_run(download = FALSE, system_command = NULL)"},{"path":"https://niehs.github.io/amadeus/reference/download_run.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Run download commands — download_run","text":"download logical(1). Execute (TRUE) skip (FALSE) download. system_command character(1). Linux command execute downloads. Inherited data download function.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_sanitize_path.html","id":null,"dir":"Reference","previous_headings":"","what":"Sanitize directory — download_sanitize_path","title":"Sanitize directory — download_sanitize_path","text":"Append forward slash end directory already end one.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_sanitize_path.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sanitize directory — download_sanitize_path","text":"","code":"download_sanitize_path(directory)"},{"path":"https://niehs.github.io/amadeus/reference/download_sanitize_path.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sanitize directory — download_sanitize_path","text":"directory character(1). Path","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_sanitize_path.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sanitize directory — download_sanitize_path","text":"character ending forward slash.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_sedac_groads.html","id":null,"dir":"Reference","previous_headings":"","what":"Download roads data — download_sedac_groads","title":"Download roads data — download_sedac_groads","text":"download_sedac_groads() function accesses downloads roads data NASA's Global Roads Open Access Data Set (gROADS), v1 (1980-2010).","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_sedac_groads.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Download roads data — download_sedac_groads","text":"","code":"download_sedac_groads(   data_region = c(\"Americas\", \"Global\", \"Africa\", \"Asia\", \"Europe\", \"Oceania East\",     \"Oceania West\"),   data_format = c(\"Shapefile\", \"Geodatabase\"),   directory_to_save = NULL,   acknowledgement = FALSE,   download = FALSE,   remove_command = FALSE,   unzip = TRUE,   remove_zip = FALSE )"},{"path":"https://niehs.github.io/amadeus/reference/download_sedac_groads.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Download roads data — download_sedac_groads","text":"data_region character(1). Data can downloaded \"Global\", \"Africa\", \"Asia\", \"Europe\", \"Americas\", \"Oceania East\", \"Oceania West\". data_format character(1). Data can downloaded \"Shapefile\" \"Geodatabase\". (\"Geodatabase\" available \"Global\" region). directory_to_save character(1). Directory save data. Two sub-directories created downloaded zip files (\"/zip_files\") unzipped shapefiles (\"/data_files\"). acknowledgement logical(1). setting TRUE user acknowledges data downloaded using function may large use lots machine storage memory. download logical(1). FALSE generate *.txt file containing download commands. setting TRUE function download requested data files. remove_command logical(1). Remove (TRUE) keep (FALSE) text file containing download commands. unzip logical(1). Unzip zip files. Default TRUE. remove_zip logical(1). Remove zip files directory_to_download. Default FALSE.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_sedac_groads.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Download roads data — download_sedac_groads","text":"NULL; Zip /data files downloaded stored respective sub-directories within directory_to_save.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_sedac_groads.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Download roads data — download_sedac_groads","text":"Center International Earth Science Information Network-CIESIN-Columbia University, Information Technology Outreach Services-ITOS-University Georgia (2013). “Global Roads Open Access Data Set, Version 1 (gROADSv1).” doi:10.7927/H4VD6WCT , https://sedac.ciesin.columbia.edu/data/set/groads-global-roads-open-access-v1.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_sedac_groads.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Download roads data — download_sedac_groads","text":"Mitchell Manware, Insang Song","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_sedac_groads.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Download roads data — download_sedac_groads","text":"","code":"if (FALSE) { # \\dontrun{ download_sedac_groads(   data_region = \"Americas\",   data_format = \"Shapefile\",   directory_to_save = \"./data\",   acknowledgement = TRUE,   download = TRUE,   remove_command = TRUE ) } # }"},{"path":"https://niehs.github.io/amadeus/reference/download_sedac_population.html","id":null,"dir":"Reference","previous_headings":"","what":"Download population density data — download_sedac_population","title":"Download population density data — download_sedac_population","text":"download_sedac_population() function accesses downloads population density data NASA's UN WPP-Adjusted Population Density, v4.11.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_sedac_population.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Download population density data — download_sedac_population","text":"","code":"download_sedac_population(   data_resolution = \"60 minute\",   data_format = c(\"GeoTIFF\", \"ASCII\", \"netCDF\"),   year = \"2020\",   directory_to_save = NULL,   acknowledgement = FALSE,   download = FALSE,   remove_command = FALSE,   unzip = TRUE,   remove_zip = FALSE )"},{"path":"https://niehs.github.io/amadeus/reference/download_sedac_population.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Download population density data — download_sedac_population","text":"data_resolution character(1). Available resolutions 30 second (approx. 1 km), 2.5 minute (approx. 5 km), 15 minute (approx. 30 km), 30 minute (approx. 55 km), 60 minute (approx. 110 km). data_format character(1). Individual year data can downloaded \"ASCII\" \"GeoTIFF\". \"\" years downloaded \"netCDF\". year character(1). Available years 2000, 2005, 2010, 2015, 2020, \"\" years. directory_to_save character(1). Directory save data. Two sub-directories created downloaded zip files (\"/zip_files\") unzipped shapefiles (\"/data_files\"). acknowledgement logical(1). setting TRUE user acknowledges data downloaded using function may large use lots machine storage memory. download logical(1). FALSE generate *.txt file containing download commands. setting TRUE function download requested data files. remove_command logical(1). Remove (TRUE) keep (FALSE) text file containing download commands. unzip logical(1). Unzip zip files. Default TRUE. remove_zip logical(1). Remove zip files directory_to_download. Default FALSE.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_sedac_population.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Download population density data — download_sedac_population","text":"NULL; Zip /data files downloaded stored respective sub-directories within directory_to_save.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_sedac_population.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Download population density data — download_sedac_population","text":"Center International Earth Science Information Network-CIESIN-Columbia University (2017). “Gridded Population World, Version 4 (GPWv4): Population Density, Revision 11.” doi:10.7927/H49C6VHW , https://sedac.ciesin.columbia.edu/data/set/gpw-v4-population-density-rev11.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_sedac_population.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Download population density data — download_sedac_population","text":"Mitchell Manware, Insang Song","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_sedac_population.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Download population density data — download_sedac_population","text":"","code":"if (FALSE) { # \\dontrun{ download_sedac_population(   data_resolution = \"30 second\",   data_format = \"GeoTIFF\",   year = \"2020\",   directory_to_save = \"./data\",   acknowledgement = TRUE,   download = TRUE,   remove_command = TRUE ) } # }"},{"path":"https://niehs.github.io/amadeus/reference/download_setup_dir.html","id":null,"dir":"Reference","previous_headings":"","what":"Setup directory — download_setup_dir","title":"Setup directory — download_setup_dir","text":"Create directory already exist. directory exist, directory created.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_setup_dir.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Setup directory — download_setup_dir","text":"","code":"download_setup_dir(directory, zip = FALSE)"},{"path":"https://niehs.github.io/amadeus/reference/download_setup_dir.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Setup directory — download_setup_dir","text":"directory character(1) directory path zip logical(1). sub-directories created zip files data files? TRUE, vector sub-directoy names returned.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_setup_dir.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Setup directory — download_setup_dir","text":"NULL; zip = TRUE vector directories zip files data files","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_sink.html","id":null,"dir":"Reference","previous_headings":"","what":"Sink download commands — download_sink","title":"Sink download commands — download_sink","text":"Open connection command_txt file store download commands.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_sink.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sink download commands — download_sink","text":"","code":"download_sink(command_txt)"},{"path":"https://niehs.github.io/amadeus/reference/download_sink.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sink download commands — download_sink","text":"command_txt character(1). file path export commands.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_terraclimate.html","id":null,"dir":"Reference","previous_headings":"","what":"Download TerraClimate data — download_terraclimate","title":"Download TerraClimate data — download_terraclimate","text":"download_terraclimate function accesses downloads climate water balance data University California Merced Climatology Lab's TerraClimate dataset.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_terraclimate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Download TerraClimate data — download_terraclimate","text":"","code":"download_terraclimate(   variables = NULL,   year = c(2018, 2022),   directory_to_save = NULL,   acknowledgement = FALSE,   download = FALSE,   remove_command = FALSE )"},{"path":"https://niehs.github.io/amadeus/reference/download_terraclimate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Download TerraClimate data — download_terraclimate","text":"variables character(1). Variable(s) name(s). See TerraClimate Direct Downloads variable names acronym codes. year character(2). length 4 . Start/end years downloading data. directory_to_save character(1). Directory(s) save downloaded data files. acknowledgement logical(1). setting TRUE user acknowledges data downloaded using function may large use lots machine storage memory. download logical(1). FALSE generate *.txt file containing download commands. setting TRUE function download requested data files. remove_command logical(1). Remove (TRUE) keep (FALSE) text file containing download commands.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_terraclimate.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Download TerraClimate data — download_terraclimate","text":"NULL; netCDF (.nc) files stored variable-specific folder within directory_to_save.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_terraclimate.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Download TerraClimate data — download_terraclimate","text":"Abatzoglou JT, Dobrowski SZ, Parks SA, Hegewisch KC (2018). “TerraClimate, high-resolution global dataset monthly climate climatic water balance 1958–2015.” Scientific data, 5(1), 1–12.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_terraclimate.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Download TerraClimate data — download_terraclimate","text":"Mitchell Manware, Insang Song","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_terraclimate.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Download TerraClimate data — download_terraclimate","text":"","code":"if (FALSE) { # \\dontrun{ download_terraclimate(   variables = \"Precipitation\",   year = c(2023, 2024),   directory_to_save = \"./data\",   acknowledgement = TRUE,   download = TRUE,   remove_command = TRUE ) } # }"},{"path":"https://niehs.github.io/amadeus/reference/download_tri.html","id":null,"dir":"Reference","previous_headings":"","what":"Download toxic release data — download_tri","title":"Download toxic release data — download_tri","text":"download_tri() function accesses downloads toxic release data U.S. Environmental Protection Agency's (EPA) Toxic Release Inventory (TRI) Program.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_tri.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Download toxic release data — download_tri","text":"","code":"download_tri(   year = c(2018L, 2022L),   directory_to_save = NULL,   acknowledgement = FALSE,   download = FALSE,   remove_command = FALSE )"},{"path":"https://niehs.github.io/amadeus/reference/download_tri.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Download toxic release data — download_tri","text":"year character(2). length 4 . Start/end years downloading data. directory_to_save character(1). Directory download files. acknowledgement logical(1). setting TRUE user acknowledges data downloaded using function may large use lots machine storage memory. download logical(1). FALSE generate *.txt file containing download commands. setting TRUE function download requested data files. remove_command logical(1). Remove (TRUE) keep (FALSE) text file containing download commands.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_tri.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Download toxic release data — download_tri","text":"NULL; Comma-separated value (CSV) files stored directory_to_save.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_tri.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Download toxic release data — download_tri","text":"United States Environmental Protection Agency (2024). “TRI Basic Data Files: Calendar Years 1987 – Present.” https://www.epa.gov/toxics-release-inventory-tri-program/tri-data-action-0.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_tri.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Download toxic release data — download_tri","text":"Mariana Kassien, Insang Song","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_tri.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Download toxic release data — download_tri","text":"","code":"if (FALSE) { # \\dontrun{ download_tri(   year = c(2020L, 2021L),   directory_to_save = \"./data\",   acknowledgement = TRUE,   download = TRUE,   remove_command = TRUE ) } # }"},{"path":"https://niehs.github.io/amadeus/reference/download_unzip.html","id":null,"dir":"Reference","previous_headings":"","what":"Unzip zip files — download_unzip","title":"Unzip zip files — download_unzip","text":"Unzip (inflate) downloaded \".zip\" files.","code":""},{"path":"https://niehs.github.io/amadeus/reference/download_unzip.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Unzip zip files — download_unzip","text":"","code":"download_unzip(file_name, directory_to_unzip, unzip = TRUE)"},{"path":"https://niehs.github.io/amadeus/reference/download_unzip.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Unzip zip files — download_unzip","text":"file_name character(1). Full zip file path directory_to_unzip character(1). Directory unzip data unzip logical(1). Unzip (TRUE) .","code":""},{"path":"https://niehs.github.io/amadeus/reference/dt_as_mysftime.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert a data.table to an sftime — dt_as_mysftime","title":"Convert a data.table to an sftime — dt_as_mysftime","text":"Convert data.table object sftime. x must data.table object \"lon\", \"lat\", \"time\" columns describe longitude, latitude, time-orientation, respectively, x.","code":""},{"path":"https://niehs.github.io/amadeus/reference/dt_as_mysftime.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert a data.table to an sftime — dt_as_mysftime","text":"","code":"dt_as_mysftime(x, lonname, latname, timename, crs)"},{"path":"https://niehs.github.io/amadeus/reference/dt_as_mysftime.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert a data.table to an sftime — dt_as_mysftime","text":"x data.table lonname character longitude column name latname character latitude column name timename character time column name crs coordinate reference system","code":""},{"path":"https://niehs.github.io/amadeus/reference/dt_as_mysftime.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert a data.table to an sftime — dt_as_mysftime","text":"sftime object","code":""},{"path":"https://niehs.github.io/amadeus/reference/dt_as_mysftime.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Convert a data.table to an sftime — dt_as_mysftime","text":"Eva Marques","code":""},{"path":"https://niehs.github.io/amadeus/reference/extract_urls.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract download URLs — extract_urls","title":"Extract download URLs — extract_urls","text":"Extract download URLs multi-argument download commands.","code":""},{"path":"https://niehs.github.io/amadeus/reference/extract_urls.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract download URLs — extract_urls","text":"","code":"extract_urls(commands = commands, position = NULL)"},{"path":"https://niehs.github.io/amadeus/reference/extract_urls.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract download URLs — extract_urls","text":"commands character vector containing download commands position URL position vector","code":""},{"path":"https://niehs.github.io/amadeus/reference/extract_urls.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract download URLs — extract_urls","text":"character vector containing download URLs","code":""},{"path":"https://niehs.github.io/amadeus/reference/generate_date_sequence.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate date sequence — generate_date_sequence","title":"Generate date sequence — generate_date_sequence","text":"Generate sequence dates date_start date_end.","code":""},{"path":"https://niehs.github.io/amadeus/reference/generate_date_sequence.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate date sequence — generate_date_sequence","text":"","code":"generate_date_sequence(date_start, date_end, sub_hyphen = TRUE)"},{"path":"https://niehs.github.io/amadeus/reference/generate_date_sequence.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate date sequence — generate_date_sequence","text":"date_start character(1). Beginning date sequence. date_end character(1). End date sequence. sub_hyphen logical(1). Substitute hyphen dates. TRUE, returns date sequence \"YYYYMMDD\". FALSE, returns date sequence \"YYYY-MM-DD\".","code":""},{"path":"https://niehs.github.io/amadeus/reference/generate_date_sequence.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate date sequence — generate_date_sequence","text":"vector","code":""},{"path":"https://niehs.github.io/amadeus/reference/generate_time_sequence.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate time sequence — generate_time_sequence","title":"Generate time sequence — generate_time_sequence","text":"Generate sequence time values based GEOS-CF collection.","code":""},{"path":"https://niehs.github.io/amadeus/reference/generate_time_sequence.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate time sequence — generate_time_sequence","text":"","code":"generate_time_sequence(collection)"},{"path":"https://niehs.github.io/amadeus/reference/generate_time_sequence.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate time sequence — generate_time_sequence","text":"collection character(1). GEOS-CF data collection","code":""},{"path":"https://niehs.github.io/amadeus/reference/generate_time_sequence.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate time sequence — generate_time_sequence","text":"vector","code":""},{"path":"https://niehs.github.io/amadeus/reference/generate_time_sequence.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Generate time sequence — generate_time_sequence","text":"GEOS-CF hourly values observed hour (ie. 0000 = 12:00:00 , 0100 = 01:00:00 ) half hour (ie. 0030 = 12:30:00 , 0130 = 01:30:00 ). Typically, 2-dimensional collections (latitude longitude ) utilize half hour, 3-dimensional collections (latitude, longitude, time) utilize hour.","code":""},{"path":"https://niehs.github.io/amadeus/reference/is_date_proper.html","id":null,"dir":"Reference","previous_headings":"","what":"Check date format — is_date_proper","title":"Check date format — is_date_proper","text":"Check date input strings conform required format.","code":""},{"path":"https://niehs.github.io/amadeus/reference/is_date_proper.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check date format — is_date_proper","text":"","code":"is_date_proper(instr = NULL, format = \"%Y-%m-%d\")"},{"path":"https://niehs.github.io/amadeus/reference/is_date_proper.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check date format — is_date_proper","text":"instr character(1). String check. format character(1). Matching format checked. Default \"%Y-%m-%d\", can detect \"%Y/%m/%d. See strftime details formatting string.","code":""},{"path":"https://niehs.github.io/amadeus/reference/is_date_proper.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check date format — is_date_proper","text":"returning value. stops function instr conform format.","code":""},{"path":"https://niehs.github.io/amadeus/reference/is_date_proper.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Check date format — is_date_proper","text":"Insang Song","code":""},{"path":"https://niehs.github.io/amadeus/reference/list_stac_files.html","id":null,"dir":"Reference","previous_headings":"","what":"Retrieve file links from SpatioTemporal Assets Catalog (STAC) — list_stac_files","title":"Retrieve file links from SpatioTemporal Assets Catalog (STAC) — list_stac_files","text":"Read file links SpatioTemporal Assets Catalog (STAC) JSON file.","code":""},{"path":"https://niehs.github.io/amadeus/reference/list_stac_files.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Retrieve file links from SpatioTemporal Assets Catalog (STAC) — list_stac_files","text":"","code":"list_stac_files(   stac_json = \"https://s3.eu-central-1.wasabisys.com/stac/openlandmap/catalog.json\",   format = \"tif\",   which = NULL,   id_only = FALSE )"},{"path":"https://niehs.github.io/amadeus/reference/list_stac_files.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Retrieve file links from SpatioTemporal Assets Catalog (STAC) — list_stac_files","text":"stac_json character(1). Full path STAC JSON file. format character(1). Format target files. Default \"tif\". numeric/character. Index name collection retrieve. id_only logical(1). Return collection IDs .","code":""},{"path":"https://niehs.github.io/amadeus/reference/list_stac_files.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Retrieve file links from SpatioTemporal Assets Catalog (STAC) — list_stac_files","text":"character vector file links.","code":""},{"path":"https://niehs.github.io/amadeus/reference/list_stac_files.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Retrieve file links from SpatioTemporal Assets Catalog (STAC) — list_stac_files","text":"Retrieving URLs may take depending spatial tiling, temporal resolution, assets. Users encouraged use parameter select specific collection.","code":""},{"path":"https://niehs.github.io/amadeus/reference/list_stac_files.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Retrieve file links from SpatioTemporal Assets Catalog (STAC) — list_stac_files","text":"Insang Song","code":""},{"path":"https://niehs.github.io/amadeus/reference/list_stac_files.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Retrieve file links from SpatioTemporal Assets Catalog (STAC) — list_stac_files","text":"","code":"if (FALSE) { # \\dontrun{ read_stac_json() } # }"},{"path":"https://niehs.github.io/amadeus/reference/narr_variable.html","id":null,"dir":"Reference","previous_headings":"","what":"Sort NOAA NARR variables — narr_variable","title":"Sort NOAA NARR variables — narr_variable","text":"Determine whether NOAA NARR variable selected download monolevel pressure level variable. Monolevel variables derived https://downloads.psl.noaa.gov/Datasets/NARR/Dailies/monolevel/, pressure level variables derived https://downloads.psl.noaa.gov//Datasets/NARR/Dailies/pressure/.","code":""},{"path":"https://niehs.github.io/amadeus/reference/narr_variable.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sort NOAA NARR variables — narr_variable","text":"","code":"narr_variable(variable)"},{"path":"https://niehs.github.io/amadeus/reference/narr_variable.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sort NOAA NARR variables — narr_variable","text":"variable character(1). User-selected NARR variable","code":""},{"path":"https://niehs.github.io/amadeus/reference/narr_variable.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sort NOAA NARR variables — narr_variable","text":"list URL base vector months (blank monolevel)","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_aqs.html","id":null,"dir":"Reference","previous_headings":"","what":"Process U.S. EPA AQS daily CSV data — process_aqs","title":"Process U.S. EPA AQS daily CSV data — process_aqs","text":"process_aqs() function cleans imports raw air quality monitoring sites pre-generated daily CSV files, returning single SpatVector sf object. date used filter raw data read csv files. Filtered rows processed according mode argument. sites report multiple measurements per day without exceptional events internal procedure function keeps \"Included\" multiple event types per site-time.","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_aqs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Process U.S. EPA AQS daily CSV data — process_aqs","text":"","code":"process_aqs(   path = NULL,   date = c(\"2018-01-01\", \"2022-12-31\"),   mode = c(\"date-location\", \"available-data\", \"location\"),   data_field = \"Arithmetic.Mean\",   return_format = c(\"terra\", \"sf\", \"data.table\"),   extent = NULL,   ... )"},{"path":"https://niehs.github.io/amadeus/reference/process_aqs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Process U.S. EPA AQS daily CSV data — process_aqs","text":"path character(1). Directory path daily measurement data. date character(2). Start end date. \"YYYY-MM-DD\" format sorted. mode character(1). One \"date-location\" (dates * locations) \"available-data\" (date-location pairs available data) \"location\" (unique locations). data_field character(1). Data field extract. return_format character(1). \"terra\" \"sf\" \"data.table\". extent numeric(4). Spatial extent resulting object. order c(xmin, xmax, ymin, ymax). coordinate system WGS84 (EPSG:4326). ... Placeholders.","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_aqs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Process U.S. EPA AQS daily CSV data — process_aqs","text":"SpatVector, sf, data.table object depending return_format","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_aqs.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Process U.S. EPA AQS daily CSV data — process_aqs","text":"Choose date mode values caution. function may return massive data.table depending time range, resulting long processing time even crash data large computing environment process.","code":""},{"path":[]},{"path":"https://niehs.github.io/amadeus/reference/process_aqs.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Process U.S. EPA AQS daily CSV data — process_aqs","text":"","code":"if (FALSE) { # \\dontrun{ aqs <- process_aqs(   path = \"./data/aqs_daily_example.csv\",   date = c(\"2022-12-01\", \"2023-01-31\"),   mode = \"full\",   return_format = \"terra\" ) } # }"},{"path":"https://niehs.github.io/amadeus/reference/process_blackmarble.html","id":null,"dir":"Reference","previous_headings":"","what":"Assign VIIRS Black Marble products corner coordinates to retrieve a merged raster — process_blackmarble","title":"Assign VIIRS Black Marble products corner coordinates to retrieve a merged raster — process_blackmarble","text":"function return SpatRaster object georeferenced h5 files Black Marble product. Referencing corner coordinates necessary original h5 data include information.","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_blackmarble.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Assign VIIRS Black Marble products corner coordinates to retrieve a merged raster — process_blackmarble","text":"","code":"process_blackmarble(   path = NULL,   date = NULL,   tile_df = process_blackmarble_corners(),   subdataset = 3L,   crs = \"EPSG:4326\",   ... )"},{"path":"https://niehs.github.io/amadeus/reference/process_blackmarble.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Assign VIIRS Black Marble products corner coordinates to retrieve a merged raster — process_blackmarble","text":"path character. Full paths h5 files. date character(1). Date query. tile_df data.frame. Contains four corner coordinates fields named c(\"xmin\", \"xmax\", \"ymin\", \"ymax\"). See process_blackmarble_corners generate valid object argument. subdataset integer(1). Subdataset number process. Default 3L. crs character(1). terra::crs compatible CRS. Default \"EPSG:4326\" ... internal use.","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_blackmarble.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Assign VIIRS Black Marble products corner coordinates to retrieve a merged raster — process_blackmarble","text":"SpatRaster object","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_blackmarble.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Assign VIIRS Black Marble products corner coordinates to retrieve a merged raster — process_blackmarble","text":"Wang, Z. (2022). Black Marble User Guide (Version 1.3). NASA.","code":""},{"path":[]},{"path":"https://niehs.github.io/amadeus/reference/process_blackmarble.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Assign VIIRS Black Marble products corner coordinates to retrieve a merged raster — process_blackmarble","text":"Insang Song","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_blackmarble.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Assign VIIRS Black Marble products corner coordinates to retrieve a merged raster — process_blackmarble","text":"","code":"if (FALSE) { # \\dontrun{ vnp46a2 <- process_blackmarble(   path =     list.files(\"./data\", pattern = \"VNP46A2.\", full.names = TRUE),   date = \"2024-01-01\",   tile_df =     process_blackmarble_corners(hrange = c(8, 10), vrange = c(4, 5)),   subdataset = 3L,   crs = \"EPSG:4326\" ) } # }"},{"path":"https://niehs.github.io/amadeus/reference/process_blackmarble_corners.html","id":null,"dir":"Reference","previous_headings":"","what":"Process Black Marble corners — process_blackmarble_corners","title":"Process Black Marble corners — process_blackmarble_corners","text":"Tile corner generator Black Marble products. Black Marble products HDF5 format read without georeference typical R geospatial packages. function generates data.frame corner coordinates assignment.","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_blackmarble_corners.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Process Black Marble corners — process_blackmarble_corners","text":"","code":"process_blackmarble_corners(hrange = c(5, 11), vrange = c(3, 6))"},{"path":"https://niehs.github.io/amadeus/reference/process_blackmarble_corners.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Process Black Marble corners — process_blackmarble_corners","text":"hrange integer(2). 0-35. vrange integer(2). 0-17.","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_blackmarble_corners.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Process Black Marble corners — process_blackmarble_corners","text":"data.frame xmin, xmax, ymin, ymax fields","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_blackmarble_corners.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Process Black Marble corners — process_blackmarble_corners","text":"Wang, Z. (2022). Black Marble User Guide (Version 1.3). NASA.","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_blackmarble_corners.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Process Black Marble corners — process_blackmarble_corners","text":"Insang Song","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_blackmarble_corners.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Process Black Marble corners — process_blackmarble_corners","text":"","code":"process_blackmarble_corners(hrange = c(1, 2), vrange = c(1, 2)) #>     tile xmin xmax ymin ymax #> 1 h01v01 -170 -160   70   80 #> 2 h01v02 -170 -160   60   70 #> 3 h02v01 -160 -150   70   80 #> 4 h02v02 -160 -150   60   70"},{"path":"https://niehs.github.io/amadeus/reference/process_collection.html","id":null,"dir":"Reference","previous_headings":"","what":"Process GEOS-CF and MERRA2 collection codes — process_collection","title":"Process GEOS-CF and MERRA2 collection codes — process_collection","text":"Identify GEOS-CF MERRA2 collection based file path.","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_collection.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Process GEOS-CF and MERRA2 collection codes — process_collection","text":"","code":"process_collection(   path,   source,   collection = FALSE,   date = FALSE,   datetime = FALSE )"},{"path":"https://niehs.github.io/amadeus/reference/process_collection.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Process GEOS-CF and MERRA2 collection codes — process_collection","text":"path character(1). File path data file. source character(1). \"geos\" GEOS-CF \"merra2\" MERRA2 collection logical(1). Identifies returns collection name(s) based provided file path(s). date logical(1). Identifies returns date sequence (YYYYMMDD) based provided file path(s). datetime logical(1). Identifies returns date time sequence (YYYYMoMoDDHHMiMi) based provided file path(s).","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_collection.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Process GEOS-CF and MERRA2 collection codes — process_collection","text":"character","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_conformity.html","id":null,"dir":"Reference","previous_headings":"","what":"Check input assumptions — process_conformity","title":"Check input assumptions — process_conformity","text":"Check \"lon\", \"lat\", \"time\" (check_time = TRUE) convert inputs SpatVector object.","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_conformity.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check input assumptions — process_conformity","text":"","code":"process_conformity(locs = NULL, check_time = FALSE, locs_epsg = \"EPSG:4326\")"},{"path":"https://niehs.github.io/amadeus/reference/process_conformity.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check input assumptions — process_conformity","text":"locs Data. sf, SpatVector, data.frame check_time logical(1). Whether \"time\" exists column names. locs_epsg character(1). \"{authority}:{code}\" Well-Known Text format coordinate reference system definition.","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_conformity.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check input assumptions — process_conformity","text":"SpatVector object","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_conformity.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Check input assumptions — process_conformity","text":"Insang Song","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_covariates.html","id":null,"dir":"Reference","previous_headings":"","what":"Process raw data wrapper function — process_covariates","title":"Process raw data wrapper function — process_covariates","text":"function processes raw data files downloaded download_data. process_covariates underlying source-specific processing functions designed operate raw data files. avoid errors, edit raw data files passing process_covariates.","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_covariates.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Process raw data wrapper function — process_covariates","text":"","code":"process_covariates(   covariate = c(\"modis_swath\", \"modis_merge\", \"koppen-geiger\", \"blackmarble\",     \"koeppen-geiger\", \"koppen\", \"koeppen\", \"geos\", \"dummies\", \"gmted\", \"hms\", \"smoke\",     \"sedac_population\", \"population\", \"sedac_groads\", \"groads\", \"roads\", \"nlcd\", \"tri\",     \"narr\", \"nei\", \"ecoregions\", \"ecoregion\", \"merra\", \"merra2\", \"gridmet\",     \"terraclimate\", \"huc\", \"cropscape\", \"cdl\", \"prism\", \"olm\", \"openlandmap\"),   path = NULL,   ... )"},{"path":"https://niehs.github.io/amadeus/reference/process_covariates.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Process raw data wrapper function — process_covariates","text":"covariate character(1). Covariate type. path character(1). Directory file path raw data depending covariate value. ... Arguments passed raw data processing function.","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_covariates.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Process raw data wrapper function — process_covariates","text":"SpatVector, SpatRaster, sf, character depending covariate type selections.","code":""},{"path":[]},{"path":"https://niehs.github.io/amadeus/reference/process_covariates.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Process raw data wrapper function — process_covariates","text":"Insang Song","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_covariates.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Process raw data wrapper function — process_covariates","text":"","code":"if (FALSE) { # \\dontrun{ narr <- process_covariates(   covariate = \"narr\",   date = c(\"2023-01-01\", \"2023-01-10\"),   variable = \"weasd\",   path = \"./data/weasd\" ) } # }"},{"path":"https://niehs.github.io/amadeus/reference/process_cropscape.html","id":null,"dir":"Reference","previous_headings":"","what":"Process CropScape data — process_cropscape","title":"Process CropScape data — process_cropscape","text":"function imports cleans raw CropScape data, returning single SpatRaster object. Reads CropScape file selected year.","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_cropscape.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Process CropScape data — process_cropscape","text":"","code":"process_cropscape(path = NULL, year = 2021, extent = NULL, ...)"},{"path":"https://niehs.github.io/amadeus/reference/process_cropscape.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Process CropScape data — process_cropscape","text":"path character giving CropScape data path year numeric giving year CropScape data used extent numeric(4) SpatExtent giving extent raster NULL (default), entire raster loaded ... Placeholders.","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_cropscape.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Process CropScape data — process_cropscape","text":"SpatRaster object","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_cropscape.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Process CropScape data — process_cropscape","text":"Insang Song","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_cropscape.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Process CropScape data — process_cropscape","text":"","code":"if (FALSE) { # \\dontrun{ cropscape <- process_cropscape(   path = \"./data/cropscape_example.tif\",   year = 2020 ) } # }"},{"path":"https://niehs.github.io/amadeus/reference/process_ecoregion.html","id":null,"dir":"Reference","previous_headings":"","what":"Process ecoregion data — process_ecoregion","title":"Process ecoregion data — process_ecoregion","text":"process_ecoregion function imports cleans raw ecoregion data, returning SpatVector object.","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_ecoregion.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Process ecoregion data — process_ecoregion","text":"","code":"process_ecoregion(path = NULL, extent = NULL, ...)"},{"path":"https://niehs.github.io/amadeus/reference/process_ecoregion.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Process ecoregion data — process_ecoregion","text":"path character(1). Path Ecoregion Shapefiles extent numeric(4) SpatExtent giving extent raster NULL (default), entire raster loaded ... Placeholders.","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_ecoregion.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Process ecoregion data — process_ecoregion","text":"SpatVector object","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_ecoregion.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Process ecoregion data — process_ecoregion","text":"function fix Tukey's bridge Portland, . fix ensure EPA air quality monitoring sites located within ecoregion.","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_ecoregion.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Process ecoregion data — process_ecoregion","text":"Insang Song","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_ecoregion.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Process ecoregion data — process_ecoregion","text":"","code":"if (FALSE) { # \\dontrun{ ecoregion <- process_ecoregion(   path = \"./data/epa_ecoregion.gpkg\" ) } # }"},{"path":"https://niehs.github.io/amadeus/reference/process_flatten_sds.html","id":null,"dir":"Reference","previous_headings":"","what":"Process MODIS layers — process_flatten_sds","title":"Process MODIS layers — process_flatten_sds","text":"Aggregate layers sub-dataset sinusoidal MODIS products. MODIS products consist multi-layer subdatasets. function aggregates multiple layers single layer SpatRaster. fun_agg applied overlapping cells.","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_flatten_sds.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Process MODIS layers — process_flatten_sds","text":"","code":"process_flatten_sds(path = NULL, subdataset = NULL, fun_agg = \"mean\", ...)"},{"path":"https://niehs.github.io/amadeus/reference/process_flatten_sds.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Process MODIS layers — process_flatten_sds","text":"path character(1). Full path MODIS HDF4/HDF5 file. Direct sub-dataset access supported, example, HDF4_EOS:EOS_GRID:{filename}:{base_grid_information}:{sub-dataset} subdataset character(1). Exact regular expression filter sub-dataset. See process_modis_sds details. fun_agg character(1). Function name aggregate layers. acceptable terra::tapp. ... Placeholders.","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_flatten_sds.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Process MODIS layers — process_flatten_sds","text":"SpatRaster object","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_flatten_sds.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Process MODIS layers — process_flatten_sds","text":"HDF values read original without scaling. Users consult MODIS product documentation apply proper scaling factor post-hoc adjustment. users preliminary information MODIS sub-datasets, consider running terra::describe(__filename__, sds = TRUE) navigate full list sub-datasets input file consult documentation MODIS product.","code":""},{"path":[]},{"path":"https://niehs.github.io/amadeus/reference/process_flatten_sds.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Process MODIS layers — process_flatten_sds","text":"Insang Song","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_flatten_sds.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Process MODIS layers — process_flatten_sds","text":"","code":"if (FALSE) { # \\dontrun{ mod09ga_flatten <- process_flatten_sds(   path =     list.files(\"./data\", pattern = \"MOD09GA.\", full.names = TRUE)[1],   subdataset = process_modis_sds(\"MOD09GA\"),   fun_agg = \"mean\" ) } # }"},{"path":"https://niehs.github.io/amadeus/reference/process_geos.html","id":null,"dir":"Reference","previous_headings":"","what":"Process atmospheric composition data — process_geos","title":"Process atmospheric composition data — process_geos","text":"process_geos() function imports cleans raw atmospheric composition data, returning single SpatRaster object.","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_geos.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Process atmospheric composition data — process_geos","text":"","code":"process_geos(   date = c(\"2018-01-01\", \"2018-01-01\"),   variable = NULL,   path = NULL,   extent = NULL,   ... )"},{"path":"https://niehs.github.io/amadeus/reference/process_geos.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Process atmospheric composition data — process_geos","text":"date character(2). length 10. Format \"YYYY-MM-DD\". variable character(1). GEOS-CF variable name(s). path character(1). Directory downloaded netCDF (.nc4) files. extent numeric(4) SpatExtent giving extent raster NULL (default), entire raster loaded ... Placeholders.","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_geos.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Process atmospheric composition data — process_geos","text":"SpatRaster object;","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_geos.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Process atmospheric composition data — process_geos","text":"Layer names returned SpatRaster object contain variable, pressure level, date, hour.","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_geos.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Process atmospheric composition data — process_geos","text":"Mitchell Manware","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_geos.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Process atmospheric composition data — process_geos","text":"","code":"if (FALSE) { # \\dontrun{ geos <- process_geos(   date = c(\"2024-01-01\", \"2024-01-10\"),   variable = \"O3\",   path = \"./data/aqc_tavg_1hr_g1440x721_v1\" ) } # }"},{"path":"https://niehs.github.io/amadeus/reference/process_gmted.html","id":null,"dir":"Reference","previous_headings":"","what":"Process elevation data — process_gmted","title":"Process elevation data — process_gmted","text":"process_gmted() function imports cleans raw elevation data, returning single SpatRaster object.","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_gmted.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Process elevation data — process_gmted","text":"","code":"process_gmted(variable = NULL, path = NULL, extent = NULL, ...)"},{"path":"https://niehs.github.io/amadeus/reference/process_gmted.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Process elevation data — process_gmted","text":"variable vector(1). Vector containing GMTED statistic first resolution second. (Example: variable = c(\"Breakline Emphasis\", \"7.5 arc-seconds\")). Statistic options: \"Breakline Emphasis\", \"Systematic Subsample\", \"Median Statistic\", \"Minimum Statistic\", \"Mean Statistic\", \"Maximum Statistic\", \"Standard Deviation Statistic\" Resolution options: \"30 arc-seconds\", \"15 arc-seconds\", \"7.5 arc-seconds\" path character(1). Directory downloaded GMTED  \"*_grd\" folder containing .adf files. extent numeric(4) SpatExtent giving extent raster NULL (default), entire raster loaded ... Placeholders.","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_gmted.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Process elevation data — process_gmted","text":"SpatRaster object","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_gmted.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Process elevation data — process_gmted","text":"SpatRaster layer name indicates selected variable resolution, year release (2010).","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_gmted.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Process elevation data — process_gmted","text":"Mitchell Manware","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_gmted.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Process elevation data — process_gmted","text":"","code":"if (FALSE) { # \\dontrun{ gmted <- process_gmted(   variable = c(\"Breakline Emphasis\", \"7.5 arc-seconds\"),   path = \"./data/be75_grd\" ) } # }"},{"path":"https://niehs.github.io/amadeus/reference/process_gmted_codes.html","id":null,"dir":"Reference","previous_headings":"","what":"Process elevation statistic and resolution codes — process_gmted_codes","title":"Process elevation statistic and resolution codes — process_gmted_codes","text":"Identify GMTED statistic resolution based file path. Convert statistic resolution /full string /statistic resolution code.","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_gmted_codes.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Process elevation statistic and resolution codes — process_gmted_codes","text":"","code":"process_gmted_codes(   string,   statistic = FALSE,   resolution = FALSE,   invert = FALSE )"},{"path":"https://niehs.github.io/amadeus/reference/process_gmted_codes.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Process elevation statistic and resolution codes — process_gmted_codes","text":"string character(1). File path GMTED data file. statistic logical(1). Matches statistic statistic code. resolution logical(1). Matches resolution resolution code. invert logical(1). Default = FALSE. invert = TRUE assumes string provides statistic resolution code, returns full length statistic resolution.","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_gmted_codes.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Process elevation statistic and resolution codes — process_gmted_codes","text":"character","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_gridmet.html","id":null,"dir":"Reference","previous_headings":"","what":"Process gridMET data — process_gridmet","title":"Process gridMET data — process_gridmet","text":"process_gridmet() function imports cleans raw gridded surface meteorological data, returning single SpatRaster object.","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_gridmet.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Process gridMET data — process_gridmet","text":"","code":"process_gridmet(   date = c(\"2023-09-01\", \"2023-09-01\"),   variable = NULL,   path = NULL,   extent = NULL,   ... )"},{"path":"https://niehs.github.io/amadeus/reference/process_gridmet.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Process gridMET data — process_gridmet","text":"date character(2). length 10 . Start/end date downloaded data. Format YYYY-MM-DD (ex. September 1, 2023 = \"2023-09-01\"). variable character(1). Variable name acronym code. See gridMET Generate Wget File variable names acronym codes. (Note: variable \"Burning Index\" code \"bi\" variable \"Energy Release Component\" code \"erc\"). path character(1). Directory downloaded netCDF (.nc) files. extent numeric(4) SpatExtent giving extent raster NULL (default), entire raster loaded ... Placeholders.","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_gridmet.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Process gridMET data — process_gridmet","text":"SpatRaster object","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_gridmet.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Process gridMET data — process_gridmet","text":"Layer names returned SpatRaster object contain variable acronym, date.","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_gridmet.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Process gridMET data — process_gridmet","text":"Mitchell Manware","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_gridmet.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Process gridMET data — process_gridmet","text":"","code":"if (FALSE) { # \\dontrun{ gridmet <- process_gridmet(   date = c(\"2023-01-01\", \"2023-01-10\"),   variable = \"Precipitation\",   path = \"./data/pr\" ) } # }"},{"path":"https://niehs.github.io/amadeus/reference/process_gridmet_codes.html","id":null,"dir":"Reference","previous_headings":"","what":"Process gridMET variable codes — process_gridmet_codes","title":"Process gridMET variable codes — process_gridmet_codes","text":"Convert gridMET variable names /variable codes.","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_gridmet_codes.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Process gridMET variable codes — process_gridmet_codes","text":"","code":"process_gridmet_codes(string, invert = FALSE)"},{"path":"https://niehs.github.io/amadeus/reference/process_gridmet_codes.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Process gridMET variable codes — process_gridmet_codes","text":"string character(1). gridMET variable name variable code. invert logical(1). Default = FALSE. invert = TRUE assumes string provides variable code returns full length variable name.","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_gridmet_codes.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Process gridMET variable codes — process_gridmet_codes","text":"character","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_hms.html","id":null,"dir":"Reference","previous_headings":"","what":"Process wildfire smoke data — process_hms","title":"Process wildfire smoke data — process_hms","text":"process_hms() function imports cleans raw wildfire smoke plume coverage data, returning single SpatVector object.","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_hms.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Process wildfire smoke data — process_hms","text":"","code":"process_hms(   date = c(\"2018-01-01\", \"2018-01-01\"),   path = NULL,   extent = NULL,   ... )"},{"path":"https://niehs.github.io/amadeus/reference/process_hms.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Process wildfire smoke data — process_hms","text":"date character(2). length 10 . Start/end date downloaded data. Format YYYY-MM-DD (ex. September 1, 2023 = \"2023-09-01\"). path character(1). Directory downloaded NOAA HMS data files. extent numeric(4) SpatExtent giving extent output NULL (default), entire data returned ... Placeholders.","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_hms.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Process wildfire smoke data — process_hms","text":"SpatVector character object","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_hms.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Process wildfire smoke data — process_hms","text":"process_hms() return character object wildfire smoke plumes present selected dates density. returned character contain density value sequence dates wildfire smoke plumes detected (see \"Examples\"). multiple density polygons overlap, function return highest density value.","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_hms.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Process wildfire smoke data — process_hms","text":"Mitchell Manware","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_hms.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Process wildfire smoke data — process_hms","text":"","code":"hms <- process_hms(   date = c(\"2018-12-30\", \"2019-01-01\"),   path = \"../tests/testdata/hms/\" ) #> Smoke plume polygons absent from 2018-12-30 to 2019-01-01. Returning vector of dates."},{"path":"https://niehs.github.io/amadeus/reference/process_huc.html","id":null,"dir":"Reference","previous_headings":"","what":"Retrieve Hydrologic Unit Code (HUC) data — process_huc","title":"Retrieve Hydrologic Unit Code (HUC) data — process_huc","text":"Retrieve Hydrologic Unit Code (HUC) data","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_huc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Retrieve Hydrologic Unit Code (HUC) data — process_huc","text":"","code":"process_huc(   path,   layer_name = NULL,   huc_level = NULL,   huc_header = NULL,   extent = NULL,   ... )"},{"path":"https://niehs.github.io/amadeus/reference/process_huc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Retrieve Hydrologic Unit Code (HUC) data — process_huc","text":"path character. Path file directory containing HUC data. layer_name character(1). Layer name path huc_level character(1). Field name HUC level huc_header character(1). upper level HUC code header extract lower level HUCs. extent numeric(4) SpatExtent giving extent raster NULL (default), entire raster loaded ... Arguments passed nhdplusTools::get_huc()","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_huc.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Retrieve Hydrologic Unit Code (HUC) data — process_huc","text":"SpatVector object","code":""},{"path":[]},{"path":"https://niehs.github.io/amadeus/reference/process_huc.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Retrieve Hydrologic Unit Code (HUC) data — process_huc","text":"Insang Song","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_huc.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Retrieve Hydrologic Unit Code (HUC) data — process_huc","text":"","code":"if (FALSE) { # \\dontrun{ library(terra) getf <- \"WBD_National_GDB.gdb\" # check the layer name to read terra::vector_layers(getf) test1 <- process_huc(   getf,   layer_name = \"WBDHU8\",   huc_level = \"huc8\" ) test2 <- process_huc(   getf,   layer_name = \"WBDHU8\",   huc_level = \"huc8\" ) test3 <- process_huc(   \"\",   layer_name = NULL,   huc_level = NULL,   huc_header = NULL,   id = \"030202\",   type = \"huc06\" ) } # }"},{"path":"https://niehs.github.io/amadeus/reference/process_koppen_geiger.html","id":null,"dir":"Reference","previous_headings":"","what":"Process climate classification data — process_koppen_geiger","title":"Process climate classification data — process_koppen_geiger","text":"process_koppen_geiger() function imports cleans raw climate classification data, returning single SpatRaster object.","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_koppen_geiger.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Process climate classification data — process_koppen_geiger","text":"","code":"process_koppen_geiger(path = NULL, extent = NULL, ...)"},{"path":"https://niehs.github.io/amadeus/reference/process_koppen_geiger.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Process climate classification data — process_koppen_geiger","text":"path character(1). Path Koppen-Geiger climate zone raster file extent numeric(4) SpatExtent giving extent raster NULL (default), entire raster loaded ... Placeholders.","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_koppen_geiger.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Process climate classification data — process_koppen_geiger","text":"SpatRaster object","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_koppen_geiger.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Process climate classification data — process_koppen_geiger","text":"Insang Song","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_koppen_geiger.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Process climate classification data — process_koppen_geiger","text":"","code":"if (FALSE) { # \\dontrun{ kg <- process_koppen_geiger(   path = \"./data/koppen_geiger_data.tif\" ) } # }"},{"path":"https://niehs.github.io/amadeus/reference/process_locs_radius.html","id":null,"dir":"Reference","previous_headings":"","what":"Process locations buffer — process_locs_radius","title":"Process locations buffer — process_locs_radius","text":"Create circular buffer around locations based user defined radius. Creates circular buffer around points radius > 0. Returns points radius 0.","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_locs_radius.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Process locations buffer — process_locs_radius","text":"","code":"process_locs_radius(locs, radius)"},{"path":"https://niehs.github.io/amadeus/reference/process_locs_radius.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Process locations buffer — process_locs_radius","text":"locs SpatVector(1). SpatVector object point geometry radius integer(1). Circular buffer size (meters).","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_locs_radius.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Process locations buffer — process_locs_radius","text":"SpatVector object","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_locs_vector.html","id":null,"dir":"Reference","previous_headings":"","what":"Process locations as SpatVector — process_locs_vector","title":"Process locations as SpatVector — process_locs_vector","text":"Detect SpatVector object, convert locations class sf, data.frame data.table SpatVector object, project coordinate reference system, apply circular buffer.","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_locs_vector.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Process locations as SpatVector — process_locs_vector","text":"","code":"process_locs_vector(locs, crs, radius)"},{"path":"https://niehs.github.io/amadeus/reference/process_locs_vector.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Process locations as SpatVector — process_locs_vector","text":"locs data.frame(1). Data frame containing columns unique identifier, latitude, longitude. Latitude longitude columns must named \"lat\" \"lon\", respectively. crs Coordinate reference system (CRS) description utilizing terra::crs(). radius integer(1). Circular buffer size (meters).","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_locs_vector.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Process locations as SpatVector — process_locs_vector","text":"SpatVector object","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_merra2.html","id":null,"dir":"Reference","previous_headings":"","what":"Process meteorological and atmospheric data — process_merra2","title":"Process meteorological and atmospheric data — process_merra2","text":"process_merra2() function imports cleans raw atmospheric composition data, returning single SpatRaster object.","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_merra2.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Process meteorological and atmospheric data — process_merra2","text":"","code":"process_merra2(   date = c(\"2018-01-01\", \"2018-01-01\"),   variable = NULL,   path = NULL,   extent = NULL,   ... )"},{"path":"https://niehs.github.io/amadeus/reference/process_merra2.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Process meteorological and atmospheric data — process_merra2","text":"date character(2). length 10. Format \"YYYY-MM-DD\". variable character(1). MERRA2 variable name(s). path character(1). Directory downloaded netCDF (.nc4) files. extent numeric(4) SpatExtent giving extent raster NULL (default), entire raster loaded ... Placeholders.","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_merra2.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Process meteorological and atmospheric data — process_merra2","text":"SpatRaster object;","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_merra2.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Process meteorological and atmospheric data — process_merra2","text":"Layer names returned SpatRaster object contain variable, pressure level, date, hour. Pressure level values utilized layer names taken directly raw data edited retain pressure level information.","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_merra2.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Process meteorological and atmospheric data — process_merra2","text":"Mitchell Manware","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_merra2.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Process meteorological and atmospheric data — process_merra2","text":"","code":"if (FALSE) { # \\dontrun{ merra2 <- process_merra2(   date = c(\"2024-01-01\", \"2024-01-10\"),   variable = \"CPT\",   path = \"./data/inst1_2d_int_Nx\" ) } # }"},{"path":"https://niehs.github.io/amadeus/reference/process_merra2_time.html","id":null,"dir":"Reference","previous_headings":"","what":"Process MERRA2 time steps — process_merra2_time","title":"Process MERRA2 time steps — process_merra2_time","text":"Identify time step data observations based MERRA2 collection filter time values .","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_merra2_time.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Process MERRA2 time steps — process_merra2_time","text":"","code":"process_merra2_time(collection, from)"},{"path":"https://niehs.github.io/amadeus/reference/process_merra2_time.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Process MERRA2 time steps — process_merra2_time","text":"collection character(1). MERRA2 collection name. SpatRaster(1). Object extract time values .","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_merra2_time.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Process MERRA2 time steps — process_merra2_time","text":"character","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_modis_merge.html","id":null,"dir":"Reference","previous_headings":"","what":"Process MODIS .hdf files — process_modis_merge","title":"Process MODIS .hdf files — process_modis_merge","text":"Get mosaicked merged raster multiple MODIS hdf files.","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_modis_merge.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Process MODIS .hdf files — process_modis_merge","text":"","code":"process_modis_merge(   path = NULL,   date = NULL,   subdataset = NULL,   fun_agg = \"mean\",   ... )"},{"path":"https://niehs.github.io/amadeus/reference/process_modis_merge.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Process MODIS .hdf files — process_modis_merge","text":"path character. Full list hdf file paths. preferably recursive search result base::list.files. date character(1). date query. \"YYYY-MM-DD\" format. subdataset character(1). subdataset names extract. conform regular expression. See base::regex details. Default NULL, result errors. Users specify subdatasets imported. fun_agg Function name custom function aggregate overlapping cell values. See fun description terra::tapp details. ... internal use.","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_modis_merge.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Process MODIS .hdf files — process_modis_merge","text":"SpatRaster object","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_modis_merge.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Process MODIS .hdf files — process_modis_merge","text":"Curvilinear products (.e., swaths) accepted. MODIS products downloaded functions amadeus, MODISTools, luna accepted.","code":""},{"path":[]},{"path":"https://niehs.github.io/amadeus/reference/process_modis_merge.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Process MODIS .hdf files — process_modis_merge","text":"Insang Song","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_modis_merge.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Process MODIS .hdf files — process_modis_merge","text":"","code":"if (FALSE) { # \\dontrun{ mod09ga_merge <- process_modis_merge(   path =     list.files(\"./data\", pattern = \"MOD09GA.\", full.names = TRUE),   date = \"2024-01-01\",   subdataset = \"sur_refl_b01_1\",   fun_agg = \"mean\" ) } # }"},{"path":"https://niehs.github.io/amadeus/reference/process_modis_sds.html","id":null,"dir":"Reference","previous_headings":"","what":"Process MODIS sub-datasets — process_modis_sds","title":"Process MODIS sub-datasets — process_modis_sds","text":"Selected MODIS sinusoidal grid product subdataset name selector. Four presets supported. custom_sel supersedes presets product values.","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_modis_sds.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Process MODIS sub-datasets — process_modis_sds","text":"","code":"process_modis_sds(   product = c(\"MOD11A1\", \"MOD13A2\", \"MOD09GA\", \"MCD19A2\"),   custom_sel = NULL,   ... )"},{"path":"https://niehs.github.io/amadeus/reference/process_modis_sds.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Process MODIS sub-datasets — process_modis_sds","text":"product character(1). Product code. custom_sel character(1). Custom filter. value NULL, preset filter overridden. ... Placeholders.","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_modis_sds.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Process MODIS sub-datasets — process_modis_sds","text":"character object conforms regular expression. Details regular expression R can found regexp.","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_modis_sds.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Process MODIS sub-datasets — process_modis_sds","text":"Preset product codes associated variables include \"MOD11A1\" - Land surface temperature (LST) \"MOD13A2\" - Normalized Difference Vegetation Index (NDVI) \"MOD09GA\" - Surface reflectance, \"MCD19A2\" - Aerosol optical depth (AOD). full list available MODIS product codes, see \"Short Name\" column NASA LP DAAC Search Data Catalog. utilizing product code \"Short Name\" column, include version number following period. example, \"Short Name\" = MCD12C1.006, product = \"MCD12C1\".","code":""},{"path":[]},{"path":"https://niehs.github.io/amadeus/reference/process_modis_sds.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Process MODIS sub-datasets — process_modis_sds","text":"Insang Song","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_modis_sds.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Process MODIS sub-datasets — process_modis_sds","text":"","code":"process_modis_sds(product = \"MOD09GA\") #> [1] \"(sur_refl_b0)\""},{"path":"https://niehs.github.io/amadeus/reference/process_modis_swath.html","id":null,"dir":"Reference","previous_headings":"","what":"Mosaic MODIS swaths — process_modis_swath","title":"Mosaic MODIS swaths — process_modis_swath","text":"function return SpatRaster object values selected subdatasets. Swath data include curvilinear grids, require warping/rectifying original curvilinear grids rectilinear grids. function internally warps inputs mosaic warped images one large SpatRaster object. Users need select subdataset process. full path looks like \"HDF4_EOS:EOS_SWATH:{file_path}:mod06:subdataset\", file_path full path hdf file.","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_modis_swath.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Mosaic MODIS swaths — process_modis_swath","text":"","code":"process_modis_swath(   path = NULL,   date = NULL,   subdataset = NULL,   suffix = \":mod06:\",   resolution = 0.05,   ... )"},{"path":"https://niehs.github.io/amadeus/reference/process_modis_swath.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Mosaic MODIS swaths — process_modis_swath","text":"path character. Full paths hdf files. date character(1). Date query. subdataset character. Subdatasets process. Unlike preprocessing functions, argument specify exact subdataset name. example, using MOD06_L2 product, one may specify c(\"Cloud_Fraction\", \"Cloud_Optical_Thickness\"), etc. subdataset names can found terra::describe() output. suffix character(1). formatted :{product}:, e.g., :mod06: resolution numeric(1). Resolution output raster. Unit degree (decimal degree WGS84). ... internal use.","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_modis_swath.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Mosaic MODIS swaths — process_modis_swath","text":"SpatRaster object (crs = \"EPSG:4326\"): path single file full specification subdataset. SpatRaster object (crs = \"EPSG:4326\"): path list files. case, returned object maximal extent multiple warped layers","code":""},{"path":[]},{"path":"https://niehs.github.io/amadeus/reference/process_modis_swath.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Mosaic MODIS swaths — process_modis_swath","text":"Insang Song","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_modis_swath.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Mosaic MODIS swaths — process_modis_swath","text":"","code":"if (FALSE) { # \\dontrun{ mod06l2_swath <- process_modis_swath(   path = list.files(     \"./data/mod06l2\",     full.names = TRUE,     pattern = \".hdf\"   ),   date = \"2024-01-01\",   subdataset = \"Cloud_Fraction\",   suffix = \":mod06:\",   resolution = 0.05 ) } # }"},{"path":"https://niehs.github.io/amadeus/reference/process_modis_warp.html","id":null,"dir":"Reference","previous_headings":"","what":"Warp MODIS swath data into rectilinear grid raster — process_modis_warp","title":"Warp MODIS swath data into rectilinear grid raster — process_modis_warp","text":"Swath data type MODIS data, curvilinear points stored varying resolution depending relative position sensor axis. type data typically work well planar spatial data, users warp rectify data rectilinear raster. Main procedure done stars::st_warp, users able customize threshold fill potential gaps appear target resolution finer local resolution curvilinear grid points.","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_modis_warp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Warp MODIS swath data into rectilinear grid raster — process_modis_warp","text":"","code":"process_modis_warp(   path = NULL,   cellsize = 0.1,   threshold = cellsize * 4,   crs = 4326,   ... )"},{"path":"https://niehs.github.io/amadeus/reference/process_modis_warp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Warp MODIS swath data into rectilinear grid raster — process_modis_warp","text":"path File path MODIS swath exact sub-dataset specification. cellsize numeric(1). Cell size (spatial resolution) output rectilinear grid raster. threshold numeric(1). Maximum distance fill gaps occur. crs integer(1)/character(1). Coordinate system definition. compatible EPSG codes WKT2. See terra::crs sf::st_crs / EPSG ... internal use.","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_modis_warp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Warp MODIS swath data into rectilinear grid raster — process_modis_warp","text":"stars object","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_modis_warp.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Warp MODIS swath data into rectilinear grid raster — process_modis_warp","text":"function handles one file time.","code":""},{"path":[]},{"path":"https://niehs.github.io/amadeus/reference/process_modis_warp.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Warp MODIS swath data into rectilinear grid raster — process_modis_warp","text":"Insang Song","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_modis_warp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Warp MODIS swath data into rectilinear grid raster — process_modis_warp","text":"","code":"if (FALSE) { # \\dontrun{ mod06l2_warp <- process_modis_warp(   path = paste0(     \"HDF4_EOS:EOS_SWATH:\",     list.files(       \"./data/mod06l2\",       full.names = TRUE,       pattern = \".hdf\"     )[1],     \":mod06:Cloud_Fraction\"   ),   cellsize = 0.1,   threshold = 0.4,   crs = 4326 ) } # }"},{"path":"https://niehs.github.io/amadeus/reference/process_narr.html","id":null,"dir":"Reference","previous_headings":"","what":"Process meteorological data — process_narr","title":"Process meteorological data — process_narr","text":"process_narr() function imports cleans raw meteorological data, returning single SpatRaster object.","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_narr.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Process meteorological data — process_narr","text":"","code":"process_narr(   date = c(\"2023-09-01\", \"2023-09-01\"),   variable = NULL,   path = NULL,   extent = NULL,   ... )"},{"path":"https://niehs.github.io/amadeus/reference/process_narr.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Process meteorological data — process_narr","text":"date character(2). length 10 . Start/end date downloaded data. Format YYYY-MM-DD (ex. September 1, 2023 = \"2023-09-01\"). variable character(1). Variable name acronym. See List Variables NARR Files variable names acronym codes. path character(1). Directory downloaded netCDF (.nc) files. extent numeric(4) SpatExtent giving extent raster NULL (default), entire raster loaded ... Placeholders.","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_narr.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Process meteorological data — process_narr","text":"SpatRaster object","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_narr.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Process meteorological data — process_narr","text":"Layer names returned SpatRaster object contain variable acronym, pressure level, date.","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_narr.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Process meteorological data — process_narr","text":"Mitchell Manware","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_narr.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Process meteorological data — process_narr","text":"","code":"if (FALSE) { # \\dontrun{ narr <- process_narr(   date = c(\"2022-01-01\", \"2022-01-10\"),   variable = \"weasd\",   path = \"./data/weasd\" ) } # }"},{"path":"https://niehs.github.io/amadeus/reference/process_nei.html","id":null,"dir":"Reference","previous_headings":"","what":"Process road emissions data — process_nei","title":"Process road emissions data — process_nei","text":"process_nei() function imports cleans raw road emissions data, returning single SpatVector object. NEI data comprises multiple csv files emissions 50+ pollutants recorded county level. raw data files, function join combined table NEI data county boundary, perform spatial join target locations.","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_nei.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Process road emissions data — process_nei","text":"","code":"process_nei(path = NULL, county = NULL, year = c(2017, 2020), ...)"},{"path":"https://niehs.github.io/amadeus/reference/process_nei.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Process road emissions data — process_nei","text":"path character(1). Directory NEI csv files. county SpatVector/sf. County boundaries. year integer(1) Year use. Currently 2017 2020 accepted. ... Placeholders.","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_nei.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Process road emissions data — process_nei","text":"SpatVector object","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_nei.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Process road emissions data — process_nei","text":"Base files county argument can downloaded directly U.S. Census Bureau using tigris package. function reproject census boundaries. Users aware coordinate system census boundary data analyses.","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_nei.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Process road emissions data — process_nei","text":"Insang Song","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_nei.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Process road emissions data — process_nei","text":"","code":"if (FALSE) { # \\dontrun{ nei <- process_nei(   path = \"./data\",   county = system.file(\"gpkg/nc.gpkg\", package = \"sf\"),   year = 2017 ) } # }"},{"path":"https://niehs.github.io/amadeus/reference/process_nlcd.html","id":null,"dir":"Reference","previous_headings":"","what":"Process land cover data — process_nlcd","title":"Process land cover data — process_nlcd","text":"process_nlcd() function imports cleans raw land cover data, returning single SpatRaster object. Reads NLCD file selected year.","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_nlcd.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Process land cover data — process_nlcd","text":"","code":"process_nlcd(path = NULL, year = 2021, extent = NULL, ...)"},{"path":"https://niehs.github.io/amadeus/reference/process_nlcd.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Process land cover data — process_nlcd","text":"path character giving nlcd data path year numeric giving year NLCD data used extent numeric(4) SpatExtent giving extent raster NULL (default), entire raster loaded ... Placeholders.","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_nlcd.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Process land cover data — process_nlcd","text":"SpatRaster object","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_nlcd.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Process land cover data — process_nlcd","text":"Eva Marques, Insang Song","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_nlcd.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Process land cover data — process_nlcd","text":"","code":"if (FALSE) { # \\dontrun{ nlcd <- process_nlcd(   path = \"./data/\",   year = 2021 ) } # }"},{"path":"https://niehs.github.io/amadeus/reference/process_olm.html","id":null,"dir":"Reference","previous_headings":"","what":"Process OpenLandMap data — process_olm","title":"Process OpenLandMap data — process_olm","text":"Process OpenLandMap data","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_olm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Process OpenLandMap data — process_olm","text":"","code":"process_olm(path = NULL, extent = NULL, ...)"},{"path":"https://niehs.github.io/amadeus/reference/process_olm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Process OpenLandMap data — process_olm","text":"path character giving OpenLandMap data path extent numeric(4) SpatExtent giving extent raster NULL (default), entire raster loaded ... Placeholders.","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_olm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Process OpenLandMap data — process_olm","text":"SpatRaster object","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_olm.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Process OpenLandMap data — process_olm","text":"Insang Song","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_olm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Process OpenLandMap data — process_olm","text":"","code":"if (FALSE) { # \\dontrun{ olm <- process_olm(   path = paste0(     \"./data/no2_s5p.l3.trop.tmwm.p50_p90_2km_a_\",     \"20180501_20221130_go_epsg.4326_v20221219.tif\"  ) ) } # }"},{"path":"https://niehs.github.io/amadeus/reference/process_prism.html","id":null,"dir":"Reference","previous_headings":"","what":"Process PRISM data — process_prism","title":"Process PRISM data — process_prism","text":"function imports cleans raw PRISM data, returning single SpatRaster object. Reads time series 30-year normal PRISM data.","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_prism.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Process PRISM data — process_prism","text":"","code":"process_prism(path = NULL, element = NULL, time = NULL, extent = NULL, ...)"},{"path":"https://niehs.github.io/amadeus/reference/process_prism.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Process PRISM data — process_prism","text":"path character giving PRISM data path file directory path acceptable. element character(1). PRISM element name time character(1). PRISM time name. character length 2, 4, 6, 8. \"annual\" acceptable. extent numeric(4) SpatExtent giving extent raster NULL (default), entire raster loaded ... Placeholders.","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_prism.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Process PRISM data — process_prism","text":"SpatRaster object metadata time element.","code":""},{"path":[]},{"path":"https://niehs.github.io/amadeus/reference/process_prism.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Process PRISM data — process_prism","text":"Insang Song","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_prism.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Process PRISM data — process_prism","text":"","code":"if (FALSE) { # \\dontrun{ prism <- process_prism(   path = \"./data/PRISM_ppt_stable_4kmM3_202104_nc.nc\",   element = \"ppt\",   time = \"202104\" ) } # }"},{"path":"https://niehs.github.io/amadeus/reference/process_sedac_codes.html","id":null,"dir":"Reference","previous_headings":"","what":"Process population resolution code — process_sedac_codes","title":"Process population resolution code — process_sedac_codes","text":"Convert full length resolution name /resolution code.","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_sedac_codes.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Process population resolution code — process_sedac_codes","text":"","code":"process_sedac_codes(string, invert = FALSE)"},{"path":"https://niehs.github.io/amadeus/reference/process_sedac_codes.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Process population resolution code — process_sedac_codes","text":"string character(1). Resolution name code. invert logical(1). Default = FALSE. invert = TRUE assumes string provides resolution code, returns full length resolution.","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_sedac_codes.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Process population resolution code — process_sedac_codes","text":"character","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_sedac_groads.html","id":null,"dir":"Reference","previous_headings":"","what":"Process roads data — process_sedac_groads","title":"Process roads data — process_sedac_groads","text":"process_sedac_groads() function imports cleans raw road data, returning single SpatVector object.","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_sedac_groads.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Process roads data — process_sedac_groads","text":"","code":"process_sedac_groads(path = NULL, extent = NULL, ...)"},{"path":"https://niehs.github.io/amadeus/reference/process_sedac_groads.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Process roads data — process_sedac_groads","text":"path character(1). Path geodatabase shapefiles. extent numeric(4) SpatExtent giving extent raster NULL (default), entire raster loaded ... Placeholders.","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_sedac_groads.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Process roads data — process_sedac_groads","text":"SpatVector object","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_sedac_groads.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Process roads data — process_sedac_groads","text":"U.S. context. returned SpatVector object contains $description column represent temporal range covered dataset. information, see https://sedac.ciesin.columbia.edu/data/set/groads-global-roads-open-access-v1/metadata.","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_sedac_groads.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Process roads data — process_sedac_groads","text":"Insang Song","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_sedac_groads.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Process roads data — process_sedac_groads","text":"","code":"if (FALSE) { # \\dontrun{ groads <- process_sedac_groads(   path = \"./data/groads_example.shp\" ) } # }"},{"path":"https://niehs.github.io/amadeus/reference/process_sedac_population.html","id":null,"dir":"Reference","previous_headings":"","what":"Process population density data — process_sedac_population","title":"Process population density data — process_sedac_population","text":"process_secac_population() function imports cleans raw population density data, returning single SpatRaster object.","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_sedac_population.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Process population density data — process_sedac_population","text":"","code":"process_sedac_population(path = NULL, extent = NULL, ...)"},{"path":"https://niehs.github.io/amadeus/reference/process_sedac_population.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Process population density data — process_sedac_population","text":"path character(1). Path GeoTIFF (.tif) netCDF (.nc) file. extent numeric(4) SpatExtent giving extent raster NULL (default), entire raster loaded ... Placeholders.","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_sedac_population.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Process population density data — process_sedac_population","text":"SpatRaster object","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_sedac_population.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Process population density data — process_sedac_population","text":"Mitchell Manware","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_sedac_population.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Process population density data — process_sedac_population","text":"","code":"if (FALSE) { # \\dontrun{ pop <- process_sedac_population(   path = \"./data/sedac_population_example.tif\" ) } # }"},{"path":"https://niehs.github.io/amadeus/reference/process_terraclimate.html","id":null,"dir":"Reference","previous_headings":"","what":"Process TerraClimate data — process_terraclimate","title":"Process TerraClimate data — process_terraclimate","text":"process_terraclimate() function imports cleans climate water balance data, returning single SpatRaster object.","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_terraclimate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Process TerraClimate data — process_terraclimate","text":"","code":"process_terraclimate(   date = c(\"2023-09-01\", \"2023-09-01\"),   variable = NULL,   path = NULL,   extent = NULL,   ... )"},{"path":"https://niehs.github.io/amadeus/reference/process_terraclimate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Process TerraClimate data — process_terraclimate","text":"date character(2). length 10 . Start/end date downloaded data. Format YYYY-MM-DD (ex. September 1, 2023 = \"2023-09-01\"). variable character(1). Variable name acronym code. See TerraClimate Direct Downloads variable names acronym codes. path character(1). Directory downloaded netCDF (.nc) files. extent numeric(4) SpatExtent giving extent raster NULL (default), entire raster loaded ... Placeholders.","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_terraclimate.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Process TerraClimate data — process_terraclimate","text":"SpatRaster object","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_terraclimate.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Process TerraClimate data — process_terraclimate","text":"Layer names returned SpatRaster object contain variable acronym, year, month. TerraClimate data monthly temporal resolution, first day month used placeholder temporal value.","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_terraclimate.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Process TerraClimate data — process_terraclimate","text":"Mitchell Manware","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_terraclimate.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Process TerraClimate data — process_terraclimate","text":"","code":"if (FALSE) { # \\dontrun{ terraclimate <- process_terraclimate(   date = c(\"2023-01-01\", \"2023-01-10\"),   variable = \"Precipitation\",   path = \"./data/ppt\" ) } # }"},{"path":"https://niehs.github.io/amadeus/reference/process_terraclimate_codes.html","id":null,"dir":"Reference","previous_headings":"","what":"Process terraClimate variable codes — process_terraclimate_codes","title":"Process terraClimate variable codes — process_terraclimate_codes","text":"Convert terraClimate variable names /variable codes.","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_terraclimate_codes.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Process terraClimate variable codes — process_terraclimate_codes","text":"","code":"process_terraclimate_codes(string, invert = FALSE)"},{"path":"https://niehs.github.io/amadeus/reference/process_terraclimate_codes.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Process terraClimate variable codes — process_terraclimate_codes","text":"string character(1). terraClimate variable name variable code. invert logical(1). Default = FALSE. invert = TRUE assumes string provides variable code returns full length variable name.","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_terraclimate_codes.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Process terraClimate variable codes — process_terraclimate_codes","text":"character","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_tri.html","id":null,"dir":"Reference","previous_headings":"","what":"Process toxic release data — process_tri","title":"Process toxic release data — process_tri","text":"function imports cleans raw toxic release data, returning single SpatVector (points) object selected year.","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_tri.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Process toxic release data — process_tri","text":"","code":"process_tri(   path = NULL,   year = 2018,   variables = c(1, 13, 12, 14, 20, 34, 36, 47, 48, 49),   extent = NULL,   ... )"},{"path":"https://niehs.github.io/amadeus/reference/process_tri.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Process toxic release data — process_tri","text":"path character(1). Path directory TRI CSV files year integer(1). Single year select. variables integer. Column index TRI data. extent numeric(4) SpatExtent giving extent raster NULL (default), entire raster loaded ... Placeholders.","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_tri.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Process toxic release data — process_tri","text":"SpatVector object (points) year year stored field named \"year\".","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_tri.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Process toxic release data — process_tri","text":"Visit TRI Data Tools view available years variables.","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_tri.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Process toxic release data — process_tri","text":"https://www.epa.gov/toxics-release-inventory-tri-program/tri-data--tools","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_tri.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Process toxic release data — process_tri","text":"Insang Song, Mariana Kassien","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_tri.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Process toxic release data — process_tri","text":"","code":"if (FALSE) { # \\dontrun{ tri <- process_tri(   path = \"./data\",   year = 2020,   variables = c(1, 13, 12, 14, 20, 34, 36, 47, 48, 49) ) } # }"},{"path":"https://niehs.github.io/amadeus/reference/process_variable_codes.html","id":null,"dir":"Reference","previous_headings":"","what":"Filter gridMET and terraClimate variable names and variable codes — process_variable_codes","title":"Filter gridMET and terraClimate variable names and variable codes — process_variable_codes","text":"Check user defined variables gridMET TerraClimate functions.","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_variable_codes.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Filter gridMET and terraClimate variable names and variable codes — process_variable_codes","text":"","code":"process_variable_codes(variables, source = c(\"gridmet\", \"terraclimate\"))"},{"path":"https://niehs.github.io/amadeus/reference/process_variable_codes.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Filter gridMET and terraClimate variable names and variable codes — process_variable_codes","text":"variables character(1). Data variables. (Passed download_* process_*). source character(1). Data source selected variables (\"gridMET\" \"TerraClimate\").","code":""},{"path":"https://niehs.github.io/amadeus/reference/process_variable_codes.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Filter gridMET and terraClimate variable names and variable codes — process_variable_codes","text":"character","code":""},{"path":"https://niehs.github.io/amadeus/reference/read_commands.html","id":null,"dir":"Reference","previous_headings":"","what":"Import download commands — read_commands","title":"Import download commands — read_commands","text":"Read download commands .txt file convert character vector.","code":""},{"path":"https://niehs.github.io/amadeus/reference/read_commands.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Import download commands — read_commands","text":"","code":"read_commands(commands_path = commands_path)"},{"path":"https://niehs.github.io/amadeus/reference/read_commands.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Import download commands — read_commands","text":"commands_path file path wget/curl commands","code":""},{"path":"https://niehs.github.io/amadeus/reference/read_commands.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Import download commands — read_commands","text":"character vector containing download commands","code":""},{"path":"https://niehs.github.io/amadeus/reference/rename_time.html","id":null,"dir":"Reference","previous_headings":"","what":"Rename $time — rename_time","title":"Rename $time — rename_time","text":"Rename $time column sftime object.","code":""},{"path":"https://niehs.github.io/amadeus/reference/rename_time.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Rename $time — rename_time","text":"","code":"rename_time(x, newname)"},{"path":"https://niehs.github.io/amadeus/reference/rename_time.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Rename $time — rename_time","text":"x sftime object newname character new time column name","code":""},{"path":"https://niehs.github.io/amadeus/reference/rename_time.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Rename $time — rename_time","text":"sftime object","code":""},{"path":"https://niehs.github.io/amadeus/reference/rename_time.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Rename $time — rename_time","text":"Eva Marques","code":""},{"path":"https://niehs.github.io/amadeus/reference/sf_as_mysftime.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert an sf to an sftime — sf_as_mysftime","title":"Convert an sf to an sftime — sf_as_mysftime","text":"Convert sf object sftime object. x must contain time-defining column, identified timename.","code":""},{"path":"https://niehs.github.io/amadeus/reference/sf_as_mysftime.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert an sf to an sftime — sf_as_mysftime","text":"","code":"sf_as_mysftime(x, timename)"},{"path":"https://niehs.github.io/amadeus/reference/sf_as_mysftime.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert an sf to an sftime — sf_as_mysftime","text":"x sf object timename character: name time column x","code":""},{"path":"https://niehs.github.io/amadeus/reference/sf_as_mysftime.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert an sf to an sftime — sf_as_mysftime","text":"sftime object","code":""},{"path":"https://niehs.github.io/amadeus/reference/sf_as_mysftime.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Convert an sf to an sftime — sf_as_mysftime","text":"Eva Marques","code":""},{"path":"https://niehs.github.io/amadeus/reference/sftime_as_mysftime.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert an sftime to a mysftime — sftime_as_mysftime","title":"Convert an sftime to a mysftime — sftime_as_mysftime","text":"Convert sftime object mysftime object. x must contain time-defining column, identified timename.","code":""},{"path":"https://niehs.github.io/amadeus/reference/sftime_as_mysftime.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert an sftime to a mysftime — sftime_as_mysftime","text":"","code":"sftime_as_mysftime(x, timename)"},{"path":"https://niehs.github.io/amadeus/reference/sftime_as_mysftime.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert an sftime to a mysftime — sftime_as_mysftime","text":"x sftime object timename character: name time column x","code":""},{"path":"https://niehs.github.io/amadeus/reference/sftime_as_mysftime.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert an sftime to a mysftime — sftime_as_mysftime","text":"sftime object specific format","code":""},{"path":[]},{"path":"https://niehs.github.io/amadeus/reference/sftime_as_mysftime.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Convert an sftime to a mysftime — sftime_as_mysftime","text":"Eva Marques","code":""},{"path":"https://niehs.github.io/amadeus/reference/sftime_as_sf.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert an sftime to an sf — sftime_as_sf","title":"Convert an sftime to an sf — sftime_as_sf","text":"Convert sftime object sf object. x must contain time-defining column, identified timename.","code":""},{"path":"https://niehs.github.io/amadeus/reference/sftime_as_sf.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert an sftime to an sf — sftime_as_sf","text":"","code":"sftime_as_sf(x, keeptime = TRUE)"},{"path":"https://niehs.github.io/amadeus/reference/sftime_as_sf.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert an sftime to an sf — sftime_as_sf","text":"x sftime object keeptime boolean: TRUE user wants keep time column simple column (default = TRUE)","code":""},{"path":"https://niehs.github.io/amadeus/reference/sftime_as_sf.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert an sftime to an sf — sftime_as_sf","text":"sf object","code":""},{"path":"https://niehs.github.io/amadeus/reference/sftime_as_sf.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Convert an sftime to an sf — sftime_as_sf","text":"Eva Marques","code":""},{"path":"https://niehs.github.io/amadeus/reference/sftime_as_spatraster.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert an sftime to a SpatRaster — sftime_as_spatraster","title":"Convert an sftime to a SpatRaster — sftime_as_spatraster","text":"Convert sftime object SpatRaster object. Returns SpatRatser one layer time step x.","code":""},{"path":"https://niehs.github.io/amadeus/reference/sftime_as_spatraster.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert an sftime to a SpatRaster — sftime_as_spatraster","text":"","code":"sftime_as_spatraster(x, varname)"},{"path":"https://niehs.github.io/amadeus/reference/sftime_as_spatraster.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert an sftime to a SpatRaster — sftime_as_spatraster","text":"x sftime object varname variable rasterize","code":""},{"path":"https://niehs.github.io/amadeus/reference/sftime_as_spatraster.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert an sftime to a SpatRaster — sftime_as_spatraster","text":"SpatRaster object","code":""},{"path":"https://niehs.github.io/amadeus/reference/sftime_as_spatraster.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Convert an sftime to a SpatRaster — sftime_as_spatraster","text":"Running sftime_as_spatraster can take long time x spatially structured.","code":""},{"path":[]},{"path":"https://niehs.github.io/amadeus/reference/sftime_as_spatraster.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Convert an sftime to a SpatRaster — sftime_as_spatraster","text":"Eva Marques","code":""},{"path":"https://niehs.github.io/amadeus/reference/sftime_as_spatrds.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert an sftime to a SpatRasterDataset — sftime_as_spatrds","title":"Convert an sftime to a SpatRasterDataset — sftime_as_spatrds","text":"Convert sftime object SpatRasterDataset object.","code":""},{"path":"https://niehs.github.io/amadeus/reference/sftime_as_spatrds.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert an sftime to a SpatRasterDataset — sftime_as_spatrds","text":"","code":"sftime_as_spatrds(x)"},{"path":"https://niehs.github.io/amadeus/reference/sftime_as_spatrds.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert an sftime to a SpatRasterDataset — sftime_as_spatrds","text":"x sftime object","code":""},{"path":"https://niehs.github.io/amadeus/reference/sftime_as_spatrds.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert an sftime to a SpatRasterDataset — sftime_as_spatrds","text":"SpatRasterDataset object","code":""},{"path":"https://niehs.github.io/amadeus/reference/sftime_as_spatrds.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Convert an sftime to a SpatRasterDataset — sftime_as_spatrds","text":"Running sftime_as_spatrds can take long time x spatially temporally structured.","code":""},{"path":[]},{"path":"https://niehs.github.io/amadeus/reference/sftime_as_spatrds.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Convert an sftime to a SpatRasterDataset — sftime_as_spatrds","text":"Eva Marques","code":""},{"path":"https://niehs.github.io/amadeus/reference/sftime_as_spatvector.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert an sftime to a SpatVector — sftime_as_spatvector","title":"Convert an sftime to a SpatVector — sftime_as_spatvector","text":"Convert sftime object SpatVector object.","code":""},{"path":"https://niehs.github.io/amadeus/reference/sftime_as_spatvector.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert an sftime to a SpatVector — sftime_as_spatvector","text":"","code":"sftime_as_spatvector(x)"},{"path":"https://niehs.github.io/amadeus/reference/sftime_as_spatvector.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert an sftime to a SpatVector — sftime_as_spatvector","text":"x sftime object","code":""},{"path":"https://niehs.github.io/amadeus/reference/sftime_as_spatvector.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert an sftime to a SpatVector — sftime_as_spatvector","text":"SpatVector object","code":""},{"path":[]},{"path":"https://niehs.github.io/amadeus/reference/sftime_as_spatvector.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Convert an sftime to a SpatVector — sftime_as_spatvector","text":"Eva Marques","code":""},{"path":"https://niehs.github.io/amadeus/reference/spatraster_as_sftime.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert a SpatRaster to an sftime — spatraster_as_sftime","title":"Convert a SpatRaster to an sftime — spatraster_as_sftime","text":"Convert SpatRaster object sftime object. x must contain time-defining column, identified timename.","code":""},{"path":"https://niehs.github.io/amadeus/reference/spatraster_as_sftime.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert a SpatRaster to an sftime — spatraster_as_sftime","text":"","code":"spatraster_as_sftime(x, varname, timename = \"time\")"},{"path":"https://niehs.github.io/amadeus/reference/spatraster_as_sftime.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert a SpatRaster to an sftime — spatraster_as_sftime","text":"x SpatRaster object varname character variable column name sftime timename character time column name sftime (default: \"time\")","code":""},{"path":"https://niehs.github.io/amadeus/reference/spatraster_as_sftime.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert a SpatRaster to an sftime — spatraster_as_sftime","text":"sftime object","code":""},{"path":[]},{"path":"https://niehs.github.io/amadeus/reference/spatraster_as_sftime.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Convert a SpatRaster to an sftime — spatraster_as_sftime","text":"Eva Marques","code":""},{"path":"https://niehs.github.io/amadeus/reference/spatrds_as_sftime.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert a SpatRasterDataset to an sftime — spatrds_as_sftime","title":"Convert a SpatRasterDataset to an sftime — spatrds_as_sftime","text":"Convert SpatRasterDataset object sftime object. x must contain time-defining column, identified timename.","code":""},{"path":"https://niehs.github.io/amadeus/reference/spatrds_as_sftime.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert a SpatRasterDataset to an sftime — spatrds_as_sftime","text":"","code":"spatrds_as_sftime(x, timename = \"time\")"},{"path":"https://niehs.github.io/amadeus/reference/spatrds_as_sftime.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert a SpatRasterDataset to an sftime — spatrds_as_sftime","text":"x SpatRasterDataset object (~ list named SpatRasters) timename character time column name sftime (default: \"time\")","code":""},{"path":"https://niehs.github.io/amadeus/reference/spatrds_as_sftime.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert a SpatRasterDataset to an sftime — spatrds_as_sftime","text":"sftime object","code":""},{"path":[]},{"path":"https://niehs.github.io/amadeus/reference/spatrds_as_sftime.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Convert a SpatRasterDataset to an sftime — spatrds_as_sftime","text":"Eva Marques","code":""},{"path":"https://niehs.github.io/amadeus/reference/spatvector_as_sftime.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert a SpatVector to an sftime — spatvector_as_sftime","title":"Convert a SpatVector to an sftime — spatvector_as_sftime","text":"Convert SpatVector object sftime object. x must contain time-defining column, identified timename.","code":""},{"path":"https://niehs.github.io/amadeus/reference/spatvector_as_sftime.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert a SpatVector to an sftime — spatvector_as_sftime","text":"","code":"spatvector_as_sftime(x, timename = \"time\")"},{"path":"https://niehs.github.io/amadeus/reference/spatvector_as_sftime.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert a SpatVector to an sftime — spatvector_as_sftime","text":"x SpatVector object timename character time column name x (default: \"time\")","code":""},{"path":"https://niehs.github.io/amadeus/reference/spatvector_as_sftime.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert a SpatVector to an sftime — spatvector_as_sftime","text":"sftime object","code":""},{"path":[]},{"path":"https://niehs.github.io/amadeus/reference/spatvector_as_sftime.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Convert a SpatVector to an sftime — spatvector_as_sftime","text":"Eva Marques","code":""},{"path":"https://niehs.github.io/amadeus/reference/test_download_functions.html","id":null,"dir":"Reference","previous_headings":"","what":"Download unit tests — test_download_functions","title":"Download unit tests — test_download_functions","text":"Implement directory, file, download URL unit tests.","code":""},{"path":"https://niehs.github.io/amadeus/reference/test_download_functions.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Download unit tests — test_download_functions","text":"","code":"test_download_functions(   directory_to_save = directory_to_save,   commands_path = commands_path,   url_status = url_status )"},{"path":"https://niehs.github.io/amadeus/reference/test_download_functions.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Download unit tests — test_download_functions","text":"directory_to_save directory test saving commands_path file path download commands url_status logical vector URL status = 200","code":""}]
